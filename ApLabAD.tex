% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\usepackage[table]{xcolor}
\usepackage[most]{tcolorbox}
\tcbuselibrary{skins,breakable}
\usepackage{fontawesome5}

\definecolor{calloutdef}{HTML}{E6F4EA}
\definecolor{calloutteo}{HTML}{E3E8FC}
\definecolor{calloutprop}{HTML}{FDF4E3}
\definecolor{calloutejem}{HTML}{F3E8FD}
\definecolor{calloutejer}{HTML}{EAF5FC}
\definecolor{calloutnota}{HTML}{FFF3CD}
\definecolor{calloutadv}{HTML}{FDECEA}
\definecolor{calloutcur}{HTML}{F1F8FF}

\definecolor{accdef}{HTML}{00563F}
\definecolor{accte}{HTML}{1F3A93}
\definecolor{accpr}{HTML}{8A5A00}
\definecolor{accex}{HTML}{5B2A86}
\definecolor{accEj}{HTML}{0B5A7A}
\definecolor{accno}{HTML}{7A5A00}
\definecolor{accad}{HTML}{8A1F17}
\definecolor{acccu}{HTML}{0B4A8B}

\tcbset{
  htmlcallout/.style 2 args={
    enhanced, breakable,
    arc=3.5mm,
    boxrule=0.4pt,
    colframe=black!12,
    colback=#2,
    borderline west={6pt}{0pt}{#1},
    left=2mm,right=2mm,top=1mm,bottom=1mm,
    before skip=10pt, after skip=12pt,
    drop shadow={black!10},
  }
}

\newtcolorbox{Definicion}{htmlcallout={accdef}{calloutdef}}
\newtcolorbox{Teorema}{htmlcallout={accte}{calloutteo}}
\newtcolorbox{Proposicion}{htmlcallout={accpr}{calloutprop}}
\newtcolorbox{Ejemplo}{htmlcallout={accex}{calloutejem}}
\newtcolorbox{Ejercicio}{htmlcallout={accEj}{calloutejer}}
\newtcolorbox{Nota}{htmlcallout={accno}{calloutnota}}
\newtcolorbox{Advertencia}{htmlcallout={accad}{calloutadv}}
\newtcolorbox{Curiosidad}{htmlcallout={acccu}{calloutcur}}
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Tabla de contenidos}
\else
  \newcommand\contentsname{Tabla de contenidos}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{Listado de Figuras}
\else
  \newcommand\listfigurename{Listado de Figuras}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{Listado de Tablas}
\else
  \newcommand\listtablename{Listado de Tablas}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figura}
\else
  \newcommand\figurename{Figura}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Tabla}
\else
  \newcommand\tablename{Tabla}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listado}
\newcommand*\listoflistings{\listof{codelisting}{Listado de Listados}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{spanish}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={ApLabAD},
  pdfauthor={RICUIB},
  pdflang={es},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{ApLabAD}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Apuntes de Laboratorio de Análisis de Datos}
\author{RICUIB}
\date{2025-02-01}

\begin{document}
\maketitle

\renewcommand*\contentsname{Tabla de contenidos}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Prefacio}\label{prefacio}
\addcontentsline{toc}{chapter}{Prefacio}

\markboth{Prefacio}{Prefacio}

Este libro en la web es una versión de las notas de clase de asignaturas
introductorias al análisis de datos.

\begin{description}
\item[Ha sido elaborado con \href{https://quarto.org/}{Quarto}]
RStudio, PBC. (2022). Quarto (Version 1.0). Hemos utilizado el formato
formato book.
\end{description}

¿Quarto book o bookdown?
\url{https://yihui.org/en/2022/04/quarto-r-markdown/}

\part{Parte 1: Probabilidad y variables aleatorias}

En esta sección, veremos la teoría básica de la probabilidad y de las
variables aleatorias. Resolveremos problemas prácticos para comprender
mejor los conceptos y utilizaremos R para realizar cálculos y gráficos.

También exploraremos los modelos de probabilidad discretos y continuos
más conocidos.

En ocasiones, trabajaremos con problemas de cálculo más complejos.

Además, introduciremos problemas sencillos de modelización con
probabilidades. Estos consistirán en un enunciado, real o inventado, en
el que se pedirá modelizar el problema mediante una variable aleatoria y
responder a una serie de preguntas.

\chapter{Preliminares: conjuntos y
combinatoria}\label{preliminares-conjuntos-y-combinatoria}

Para aprender cálculo de probabilidades son necesarios conocimientos de:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Cálculo}: derivadas, integrales, límites, sumas de
  series\ldots{}
\item
  \textbf{Geometría básica y álgebra lineal}: rectas, hiperplanos,
  volúmenes\ldots{} matrices, valores propios\ldots{}
\item
  \textbf{Teoría de conjuntos y combinatoria} (matemática discreta).
\end{enumerate}

Por experiencia sabemos que la mayoría de estudiantes tienen más
conocimientos de cálculo, geometría y matrices. Sin embargo, muchos
presentan carencias en teoría básica de conjuntos y combinatoria, que
será necesaria en este curso.

\section{Teoría de conjuntos}\label{teoruxeda-de-conjuntos}

La definición de conjunto es una
\href{https://es.wikipedia.org/wiki/Concepto_primitivo}{idea o noción
primitiva}. Es decir, es una idea básica del pensamiento humano: un
conjunto es una colección de objetos (números, imágenes, palabras,
jugadores de fútbol, colores, etc.).

La teoría de conjuntos \textbf{básica} es simple y natural, y es la que
necesitamos para este curso.

La teoría de conjuntos \textbf{axiomática} es más compleja y presenta
varias paradojas si no se formaliza adecuadamente, como la
\href{https://es.wikipedia.org/wiki/Paradoja_de_Russell}{paradoja de
Russell}.

La idea práctica de conjunto es la de una colección de objetos de un
cierto tipo. Estas colecciones o conjuntos se pueden definir por:

\begin{itemize}
\tightlist
\item
  \textbf{Comprensión}: reuniendo los objetos que cumplen una propiedad
  \(p\).
\item
  \textbf{Extensión}: dando una lista exhaustiva de los miembros del
  conjunto.
\end{itemize}

\subsection{Conjuntos básicos}\label{conjuntos-buxe1sicos}

A menudo trabajaremos dentro de un conjunto base (o ``universo'').
Ejemplos habituales son:

\begin{itemize}
\item
  \(\mathbb{N}=\{0,1,2,\ldots\}\)
\item
  \(\mathbb{Z}=\{\ldots,-2,-1,0,1,2,\ldots\}\)
\item
  \(\mathbb{Q}=\left\{\frac{p}{q}\ \Big|\ p,q\in \mathbb{Z} \text{ y } q \neq 0\right\}\)
\item
  \(\mathbb{R}\): conjunto de los números reales (puntos de una recta).
\item
  \(\mathbb{C}= \left\{a+b\, i\ \big|\ a,b\in \mathbb{R}\right\}\),
  conjunto de los números complejos.
\item
  Alfabeto \(=\{a,b,c,\ldots, A,B,C,\ldots\}\).
\item
  Palabras \(=\{\text{paz, guerra, amor, probabilidad},\ldots\}\).
\end{itemize}

Recordemos que \(i\) es la unidad imaginaria y cumple \(i^2=-1\)
(equivalentemente, \(i=\sqrt{-1}\)).

\subsection{Características y propiedades básicas de los
conjuntos}\label{caracteruxedsticas-y-propiedades-buxe1sicas-de-los-conjuntos}

Si \(x\) es un objeto de \(\Omega\), diremos que \(x\) es
\textbf{elemento} del conjunto \(\Omega\) y que \(x\) \textbf{pertenece}
a \(\Omega\). Lo denotaremos por \(x\in \Omega\).

Un \textbf{conjunto con un solo elemento}, por ejemplo \(\{1\}\), recibe
el nombre de \textbf{conjunto unitario} (o \emph{singleton}).

Sean \(A\) y \(B\) dos conjuntos. Diremos que \(A\) \textbf{es igual a}
\(B\) si todos los elementos de \(A\) están en \(B\) y todos los
elementos de \(B\) están en \(A\). Por ejemplo, \(A=\{1,2,3\}\) es igual
a \(B=\{3,1,2\}\).

Diremos que \(A\) es un \textbf{subconjunto} de \(B\) (o que está
contenido en \(B\)) si se cumple que, para todo \(x\), si \(x\in A\)
entonces \(x\in B\). Lo denotaremos por \(A\subseteq B\).

El conjunto que no tiene elementos se denomina \textbf{conjunto vacío} y
se denota por \(\emptyset\). Dado un conjunto cualquiera \(A\), se
cumple \(\emptyset\subseteq A\).

\begin{Ejemplo}{Ejemplo}{}

Tomemos como conjunto base \(\Omega=\{1,2,3\}\).

\begin{itemize}
\tightlist
\item
  \(\Omega\) es un conjunto de cardinal 3; se denota por
  \(\#(\Omega)=3\) o por \(|\Omega|=3\).
\item
  El conjunto \(\Omega\) tiene \(2^3=8\) subconjuntos:

  \begin{itemize}
  \tightlist
  \item
    el vacío \(\emptyset\) y los unitarios \(\{1\}\),\{2\}\(,\{3\}\),
  \item
    los subconjuntos de dos elementos: \(\{1,2\}\),\{1,3\}\(,\{2,3\}\),
  \item
    el conjunto total: \(\Omega=\{1,2,3\}\).
  \end{itemize}
\end{itemize}

\end{Ejemplo}

Dado un conjunto \(\Omega\), podemos construir el \textbf{conjunto de
todas sus partes} (todos sus subconjuntos), que denotamos por
\(\mathcal{P}(\Omega)\).

\begin{Ejemplo}{Cardinal de las partes de un conjunto}{}

Por ejemplo para \(\Omega=\{1,2,3\}\), el conjunto de todas sus partes
es \(\mathcal{P}(\{1,2,3\})\) y tiene cardinal

\[
\#\big(\mathcal{P}(\{1,2,3\})\big)=2^{\#(\{1,2,3\})}=2^3=8.
\]

\end{Ejemplo}

En efecto,

\[
\mathcal{P}(\{1,2,3\})=\{\emptyset,\{1\},\{2\},\{3\},\{1,2\},\{1,3\},\{2,3\},\{1,2,3\}
\}.
\]

Dado un subconjunto \(A\subseteq \Omega\), podemos construir la función
característica de \(A\), \(\chi_A:\Omega \to \{0,1\}\), y para
\(\omega\in \Omega\) se define como

\[
\chi_A(\omega)=
\begin{cases}
1 & \text{si }\omega \in A,\\
0 & \text{si }\omega \notin A.
\end{cases}
\]

\subsection{Operaciones entre
conjuntos}\label{operaciones-entre-conjuntos}

\begin{Definicion}{Intersección}{}

Sea \(\Omega\) un conjunto y \(A\) y \(B\) dos subconjuntos de
\(\Omega\).

La \textbf{intersección} de \(A\) y \(B\) es el conjunto formado por
todos los elementos que \textbf{pertenecen} a \(A\) \textbf{y} a \(B\).
Se denota por \(A\cap B\).

Más formalmente, \[
A\cap B=\left\{x\in\Omega \,\big|\, x\in A \text{ y } x\in B\right\}.
\]

\end{Definicion}

\begin{Definicion}{Unión}{}

La \textbf{unión} de \(A\) y \(B\) es el conjunto formado por todos los
elementos que \textbf{pertenecen} a \(A\) \textbf{o} pertenecen a \(B\)
(o a ambos). Se denota por \(A\cup B\).

Más formalmente, \[
A\cup B=\left\{x\in\Omega \,\big|\, x\in A \text{ o } x\in B\right\}
\].

\end{Definicion}

\begin{Definicion}{Diferencia}{}

La \textbf{diferencia} de \(A\) y \(B\) es el conjunto formado por los
elementos que pertenecen a \(A\) \textbf{y no} pertenecen a \(B\). Se
denota por \(A\setminus B\).

Más formalmente,

\[
A\setminus B=\left\{x\in\Omega \,\big|\, x\in A \text{ y } x\notin B\right\}.
\]

\end{Definicion}

\begin{Definicion}{Complementario}{}

El \textbf{complementario} de un subconjunto \(A\) de \(\Omega\) es
\(\Omega\setminus A\) y se denota por \(A^c\) o \(\overline{A}\).

Más formalmente, \[
A^c=\left\{x\in\Omega \,\big|\, x\not\in A\right\}.
\]

\end{Definicion}

\subsection{Más propiedades}\label{muxe1s-propiedades}

Sea \(\Omega\) un conjunto y \(A\), \(B\), \(C\) tres subconjuntos de
\(\Omega\).

\begin{itemize}
\tightlist
\item
  Se dice que dos conjuntos \(A\) y \(B\) \textbf{son disjuntos} si
  \(A\cap B=\emptyset\).
\item
  \(\Omega^c=\emptyset\).
\item
  \(\emptyset^c=\Omega\).
\item
  \(A\cup B=B \cup A\), \(A\cap B=B\cap A\) (conmutativas).
\item
  \((A\cup B) \cup C = A \cup( B \cup C)\),
  \((A\cap B) \cap C = A \cap( B \cap C)\) (asociativas).
\item
  \(A\cup (B\cap C)=(A\cup B) \cap (A\cup C)\),
  \(A\cap (B\cup C)=(A\cap B) \cup (A\cap C)\) (distributivas).
\item
  \(\left(A^c\right)^c=A\) (doble complementario).
\item
  \(\left(A\cup B\right)^c=A^c \cap B^c\),
  \(\left(A\cap B\right)^c=A^c \cup B^c\)
  (\href{https://es.wikipedia.org/wiki/Leyes_de_De_Morgan}{leyes de De
  Morgan}).
\end{itemize}

\subsection{Con R: ejemplos}\label{con-r-ejemplos}

Con R los conjuntos se pueden representar como vectores:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Omega }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{10}\NormalTok{)}
\NormalTok{A }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\NormalTok{B }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\NormalTok{C }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{)}
\NormalTok{Omega}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 2 3 4 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 4 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{C}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4 6 7 8
\end{verbatim}

\(A\cap B\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{intersect}\NormalTok{(A,B)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 4 5
\end{verbatim}

\(A\cup B\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{union}\NormalTok{(A,B)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 2 3 4 5
\end{verbatim}

\(B\setminus C\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{setdiff}\NormalTok{(B,C)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 5
\end{verbatim}

\(A^c=\Omega\setminus A\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{setdiff}\NormalTok{(Omega,A)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]  6  7  8  9 10
\end{verbatim}

\subsection{Con Python}\label{con-python}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Omega}\OperatorTok{=}\BuiltInTok{set}\NormalTok{([}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{10}\NormalTok{])}
\NormalTok{A}\OperatorTok{=}\BuiltInTok{set}\NormalTok{([}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{])}
\NormalTok{B}\OperatorTok{=}\BuiltInTok{set}\NormalTok{([}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{])}
\NormalTok{C}\OperatorTok{=}\BuiltInTok{set}\NormalTok{([}\DecValTok{4}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{])}
\NormalTok{Omega}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{1, 2, 3, 4, 5}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{1, 4, 5}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{C}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{8, 4, 6, 7}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{\&}\NormalTok{ B   }\CommentTok{\# intersección}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{1, 4, 5}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{|}\NormalTok{ B   }\CommentTok{\# unión}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{1, 2, 3, 4, 5}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{{-}}\NormalTok{ C   }\CommentTok{\# diferencia}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{1, 2, 3, 5}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Omega }\OperatorTok{{-}}\NormalTok{ C }\CommentTok{\# complementario}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{1, 2, 3, 5, 9, 10}
\end{verbatim}

\section{Combinatoria}\label{combinatoria}

La combinatoria es una rama de la matemática discreta que, entre otras
cosas, cuenta configuraciones posibles de objetos de un conjunto.

Por ejemplo, si tenemos un equipo de baloncesto con 7 jugadores,
¿cuántos equipos distintos de 5 jugadores podemos formar?

\subsection{Número binomial}\label{nuxfamero-binomial}

\begin{Definicion}{Número combinatorio o número binomial}{}

Da el número de subconjuntos de tamaño \(k\) de un conjunto de tamaño
\(n\). Este número es: \[
C_n^k=\binom{n}{k} = \frac{n!}{k!\,(n-k)!}.
\]

Recordemos que

\[
n!=1\cdot 2\cdot 3\cdots n.
\]

\end{Definicion}

\begin{Ejemplo}{Ejemplo}{}

En nuestro caso, con 7 jugadores (\(n=7\)) y equipos de 5 (\(k=5\)):

\[
\binom{7}{5} = \frac{7!}{5!\,2!}
=\frac{6\cdot 7}{2}
=21.
\]

Por tanto, puedo formar 21 equipos distintos.

\end{Ejemplo}

\begin{Ejercicio}{Ejercicio: el paquete \texttt{gtools}}{}

Carga el paquete \texttt{gtools} de R e investiga la función
\texttt{combinations(n,\ r,\ v,\ set,\ repeats.allowed)} para calcular
todas las combinaciones anteriores.

\end{Ejercicio}

\subsection{Combinaciones con
repetición}\label{combinaciones-con-repeticiuxf3n}

En combinatoria, las combinaciones con repetición son selecciones en las
que se permite repetir elementos.

\begin{Definicion}{Combinaciones con repetición}{}

El número \(CR_n^k\) de multiconjuntos de tamaño \(k\) escogidos de un
conjunto con \(n\) elementos es: \[
CR_n^k = \binom{n+k-1}{k} = \frac{(n+k-1)!}{k!(n-1)!}.
\]

\end{Definicion}

\begin{Ejemplo}{Ejemplo: caramelos}{}

Repartimos 12 caramelos entre 4 personas (A, B, C, D). El número de
repartos posibles es: \[
CR_4^{12} = \binom{4+12-1}{12}=\binom{15}{12}=\texttt{455}.
\]

\end{Ejemplo}

\subsection{Variaciones (sin
repetición)}\label{variaciones-sin-repeticiuxf3n}

Con los números \(\{1,2,3\}\), ¿cuántos números de dos cifras distintas
podemos formar sin repetir ninguna cifra?

Se pueden escribir: \[
12,13,21,23,31,32.
\] Luego hay 6 casos: son las variaciones de orden \(k=2\) de un
conjunto de \(n=3\) elementos.

\begin{Definicion}{Variaciones (sin repetición)}{}

Denotaremos las variaciones (sin repetición) de \(k\) elementos de un
conjunto de \(n\) elementos por \(V_n^k\). Su valor es: \[
V_n^k=\frac{n!}{(n-k)!}.
\]

\end{Definicion}

\begin{Ejemplo}{Ejemplo}{}

En nuestro ejemplo, con \(n=3\) y \(k=2\): \[
V_3^2=\frac{3!}{(3-2)!}=6.
\]

\end{Ejemplo}

\begin{Definicion}{Ejercicio}{}

Carga el paquete \texttt{gtools} de R e investiga la función
\texttt{permutations(n,\ r,\ v,\ set,\ repeats.allowed)} para calcular
todas las variaciones anteriores.

\end{Definicion}

\subsection{Variaciones con
repetición}\label{variaciones-con-repeticiuxf3n}

¿Y si en el caso anterior permitimos que se repita algún dígito?

\begin{Definicion}{Variaciones con repetición}{}

Las variaciones de orden \(k\) de un conjunto de \(n\) elementos
permitiendo repeticiones se denotan por \(VR_n^k\) y valen: \[
VR_n^k=n^k.
\]

\end{Definicion}

\begin{Definicion}{Ejemplo}{}

En nuestro caso: \[
11,12,13,21,22,23,31,32,33,
\qquad
VR_3^2=3^2=9.
\]

\end{Definicion}

\subsection{Permutaciones}\label{permutaciones}

\begin{Definicion}{Permutaciones}{}

Las permutaciones de un conjunto de cardinal \(n\) son las variaciones
de orden máximo \(n\). Se denotan por \(P_n\) y valen: \[
P_n=V_n^n=n!.
\]

\end{Definicion}

\begin{Ejemplo}{Ejemplo (R)}{}

Por ejemplo, todas las permutaciones de \(\{1,2,3\}\) son:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(combinat)}
\ControlFlowTok{for}\NormalTok{(permutacion }\ControlFlowTok{in} \FunctionTok{permn}\NormalTok{(}\DecValTok{3}\NormalTok{)) }\FunctionTok{print}\NormalTok{(permutacion)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 2 3
[1] 1 3 2
[1] 3 1 2
[1] 3 2 1
[1] 2 3 1
[1] 2 1 3
\end{verbatim}

Efectivamente, \(P_3=3!=1\cdot 2\cdot 3\).

\end{Ejemplo}

\begin{Ejemplo}{Ejercicio}{}

En R, investiga la función \texttt{permn} del paquete \texttt{combinat}.

En Python, investiga el paquete \texttt{itertools} y la función
\texttt{comb} de \texttt{scipy.special} para las distintas formas de
contar vistas en este tema (evita \texttt{scipy.misc}, que está
deprecado).

\end{Ejemplo}

\begin{Ejemplo}{Ejercicio (función Gamma)}{}

La función Gamma de Euler cobrará mucha importancia en el curso de
estadística. Comprueba que \texttt{gamma(x+1)} da el mismo valor que
\texttt{factorial(x)} en R para todo \(x\in\{1,2,3,\ldots,10\}\).

\end{Ejemplo}

\subsection{Números multinomiales. Permutaciones con
repetición}\label{nuxfameros-multinomiales.-permutaciones-con-repeticiuxf3n}

\begin{Definicion}{Permutaciones con repetición (multinomial)}{}

Consideremos un conjunto de elementos \(\{a_1, a_2, \ldots, a_k\}\).

Si cada objeto \(a_i\) aparece repetido \(n_i\) veces (para
\(i=1,\ldots,k\)) y \(n=n_1+n_2+\cdots+n_k\), entonces el número de
permutaciones con repetición es:

\[
PR_n^{n_1,\ldots,n_k}
= \binom{n}{n_1\ n_2\ \cdots n_k}
= \frac{n!}{n_1!\,n_2!\cdots n_k!}.
\]

\end{Definicion}

\begin{Ejemplo}{Ejercicio}{}

¿Cuántas palabras diferentes se pueden formar con las letras de la
palabra \texttt{PROBABILIDAD}?

Las letras A, B, D e I aparecen 2 veces cada una; y L, O, P, R aparecen
1 vez cada una. Por tanto: \[
\frac{12!}{(2!)^4}=29\,937\,600.
\]

\end{Ejemplo}

\section{Para acabar}\label{para-acabar}

\subsection{Principios básicos para contar cardinales de
conjuntos}\label{principios-buxe1sicos-para-contar-cardinales-de-conjuntos}

\begin{Teorema}{El principio de la suma}{}

Sean \(A_1, A_2,\ldots, A_n\) conjuntos disjuntos dos a dos, es decir,
\(A_i\cap A_j=\emptyset\) para todo \(i\neq j\). Entonces \[
\#\left(\bigcup_{i=1}^n A_i\right)=\sum_{i=1}^n \#(A_i).
\]

\end{Teorema}

\begin{Teorema}{Principio de inclusión-exclusión (para 2 conjuntos)}{}

Para dos conjuntos cualesquiera \(A_1, A_2\), el cardinal de su unión
es: \[
\#(A_1\cup A_2)=\#(A_1)+\#(A_2)-\#(A_1\cap A_2).
\]

\end{Teorema}

\begin{Teorema}{El principio del producto}{}

Sean \(A_1,A_2,\ldots,A_n\). Entonces: \[
\#(A_1\times \cdots \times A_n)
=\prod_{i=1}^n \#(A_i).
\]

\end{Teorema}

\subsection{Otros aspectos a tener en
cuenta}\label{otros-aspectos-a-tener-en-cuenta}

Nos hemos dejado otras propiedades básicas de teoría de conjuntos y
combinatoria, como:

\begin{itemize}
\item
<<<<<<< HEAD
  Propiedades de los números binomiales:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    \(\binom{m}{0}=1\) y \(\binom{m}{m}=1\) para todo
    \(m\in \mathbb{N}\).
  \item
    \(\binom{m}{n}=\binom{m}{m-n}\).
  \item
    \(\binom{m}{n}=\binom{m-1}{n}+\binom{m-1}{n-1}\).
  \end{enumerate}
\item
  Binomio de Newton: \[
  (a+b)^n=\sum_{k=0}^n  \binom{n}{k}\, a^k\, b^{n-k}.
  \] En particular, \[
  (1+1)^n=\sum_{k=0}^n \binom{n}{k}=2^n,
  \qquad
  (1-1)^n=\sum_{k=0}^n \binom{n}{k}(-1)^{n-k}=0.
  \]
\item
  Número multinomial y multinomio:
\end{itemize}

\[
(a_1+\cdots + a_k)^n
=\sum_{n_1+\cdots + n_k=n}
\binom{n}{n_1\, \cdots\, n_k}\,
a_1^{n_1}\cdots a_k^{n_k},
\]

donde

\[
\binom{n}{n_1\, \cdots\. n_k}
= \frac{n!}{n_1!\cdots n_k!}.
\] Además, se cumple la siguiente identidad \[
\binom{n}{n_1\ \cdots\ n_k}
=  \binom{n}{n_1}\binom{n-n_1}{n_2}\cdots \binom{n-n_1-\cdots -n_{k-1}}{n_k}.
\]

Si nos son necesarias, las volveremos a utilizar a lo largo del curso o
=======
  Propiedades de los números combinatorios
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\binom{m}{n}=\binom{m}{m-n}\)
\item
  \(\binom{m}{n}=\binom{m-1}{n}+\binom{m-1}{n-1}\)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Binomio de Newton.
\end{itemize}

\[
(a+b)^n=\sum_{k=0}^n  \binom{n}{k} \cdot a^k \cdot  b^{n-k}     
\]

\[
  (1+1)^n=\sum_{k=0}^n  \binom{n}{k} \cdot 1^k \cdot  1^{n-k} =\sum_{k=0}^n  \binom{n}{k} =2^n.
  \]

\[(1-1)^n=\sum_{k=0}^n  \binom{n}{k} \cdot 1^k \cdot  (-1)^{n-k} =\sum_{k=0}^n  \binom{n}{k} \cdot (-1)^{n-k}=0.\]

\begin{itemize}
\tightlist
\item
  Número multinomial y Multinomio
\end{itemize}

\[(a_1+a_2+\cdots + a_k)^n=\sum_{n_1+n_2+\cdots + n_k=n} \binom{n}{n_1\quad n_2 \quad\ldots \quad n_k} \cdot a_1^{n_1}\cdot a_2^{n_2}\cdots a_k^{n_k}.\]

Donde
\[\binom{n}{n_1\quad n_2 \quad\ldots \quad n_k} = \frac{n!}{n_1!\cdot n_2!\cdot \ldots \cdot n_k!}\]
es el número multinomial.

Si nos son necesarias las volveremos a repetir a lo largo del curso o
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
bien daremos enlaces para que las podáis estudiar en paralelo.

\chapter{Teoría elemental de la
probabilidad}\label{teoruxeda-elemental-de-la-probabilidad}

\section{Definiciones básicas}\label{definiciones-buxe1sicas}

\begin{Definicion}{Definición: experimento aleatorio}{}

Un experimento que repetido en las mismas condiciones puede dar
resultados diferentes, pero que a largo plazo son predecibles recibe el
nombre de \textbf{experimento aleatorio}.

\end{Definicion}

Daremos nombres a distintos tipos de sucesos:

\begin{Definicion}{Definición: espacio muestral y tipos de sucesos}{}

\begin{itemize}
\tightlist
\item
  Llamaremos \textbf{suceso elemental} a cada uno de los posibles
  resultados del experimento aleatorio.
\item
  Llamaremos \textbf{espacio muestral} (\(\Omega\),\(E\)) al conjunto
  formado por todos los sucesos elementales del experimento aleatorio.
\item
  Llamaremos \textbf{suceso} a cualquier subconjunto del espacio
  muestral.
\item
  \textbf{Suceso seguro o cierto}: (\Omega)
\item
  \textbf{Suceso imposible o vacío}: (\emptyset)
\item
  \textbf{Partes de un conjunto}: \(\mathcal{P}(\Omega)\): conjunto de
  todos los sucesos del experimento aleatorio (es decir, el conjunto de
  todos los subconjuntos de \(\Omega\))
\end{itemize}

\end{Definicion}

A continuación describimos el clásico experimento del lanzamiento de un
dado.

\begin{Ejemplo}{Ejemplo}{}

Consideremos el experimento aleatorio que consiste en lanzar un dado. El
espacio muestral de este experimento es \(\Omega=\{1,2,3,4,5,6\}\) o las
figuras de las caras del dado.

Si lo representamos gráficamente, tendríamos:

\begin{center}
\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{probabilidad_files/figure-pdf/pepe-1.pdf}
\end{center}

Por comodidad y conveniencia se opta por representar el espacio muestral
por \[\Omega = \{1,2,3,4,5,6\}.\]

\end{Ejemplo}

Recordemos la notación \(\mathcal{P}(\Omega)\) que usamos para
referirnos al conjunto de todos los subconjuntos de \(\Omega\). Este
conjunto se llama \textbf{conjunto de partes} de \(\Omega\).

\begin{Ejercicio}{Ejercicio}{}

¿Cuantos elementos contiene el conjunto de partes de \(\Omega\) del
experimento anterior?

\end{Ejercicio}

Veamos algún ejemplo menos clásico. Podemos considerar el experimento
aleatorio que consiste en calcular los \(n\) gramas de una palabra
escogida al azar.

\begin{Ejemplo}{Ejemplo \(n\)-gramas}{}

Se define un \(n\)-grama de una palabra como el conjunto de \(n\) letras
consecutivas de la misma (contando los blancos de inicio y final de
palabra que marcamos como ``\_'').

Consideremos el experimento aleatorio que consiste en escoger al azar un
3-grama de la palabra ``\_Baleares\_''. Vamos a escribir el espacio
muestral y algunos sucesos elementales del mismo.

En este caso, si consideramos la palabra ``\_Baleares\_'', el espacio
muestral del experimento sería:

\[\Omega=\{\_Ba, Bal, ale, lea, ear, are, res, es\_\}\]

Algunos sucesos serían:

\begin{itemize}
\tightlist
\item
  3-gramas que empiezan por \(a\): \(\{ale,are\}.\)
\item
  3-gramas de inicio y final de palabra: \(\{\_Ba,es\_\}.\)
\item
  3-gramas que contengan una \(l\): \(\{Bal,ale,lea\}.\)
\end{itemize}

Existen bases de datos que estudian la frecuencias de \(n\)-gramas de
caracteres en textos en diferentes idiomas; generalmente de palabras.
Por ejemplo, en español, los bi-gramas de sílabas más frecuentes son
``EN'' (3.01\%) y ``DE'' (2.77\%) y los tri-gramas de sílabas son
``QUE'' (1.66\%) y ``ENT'' (1.38\%). Podéis consultar más estadísticas,
por ejemplo, en
\href{https://es.sttmedia.com/frecuencias-de-silabas-espanol}{Stefan
Trost Media frecuencias de sílabas en español}.

\end{Ejemplo}

\subsection{Operaciones con sucesos}\label{operaciones-con-sucesos}

Si tenemos dos sucesos \(A,B\subseteq \Omega\), podemos definir:

\begin{itemize}
\tightlist
\item
  \(\Omega\): \emph{suceso} total o \emph{seguro}.
\item
  \(\emptyset\): suceso \emph{vacío} o \emph{imposible}.
\item
  \(A\cup B\): suceso \emph{unión}; el que ocurre si sucede \(A\) o
  \(B\).
\item
  \(A\cap B\): suceso \emph{intersección}; el que ocurre si sucede \(A\)
  y \(B\).
\item
  \(A^c\): suceso \emph{complementario} el que sucede si NO sucede
  \(A\).
\item
  \(A\setminus B = A\cap B^c\): suceso \emph{diferencia}, que acontece
  si sucede \(A\) y NO sucede \(B\).
\end{itemize}

\begin{Definicion}{Sucesos incompatibles}{}

Dos sucesos cualesquiera \(A\) y \(B\) son \emph{incompatibles} (o
\emph{disjuntos}) cuando \(A\cap B=\emptyset\).

\end{Definicion}

Otro ejemplo se observa el sexo y la lateralidad de los estudiantes de
una clase.

\begin{Ejemplo}{Ejemplo}{}

Supongamos que el sexo se divide entre Mujeres y Hombres y la
lateralidad en diestros y zurdos. Vamos a definir el espacio muestral,
los sucesos elementales y a realizar algunas operaciones entre ellos.

\begin{itemize}
\tightlist
\item
  Estudiantes de esta clase: (\Omega).
\item
  Mujeres de esta clase: (A).
\item
  Estudiantes que son zurdos: (B).
\end{itemize}

\end{Ejemplo}

Algunas operaciones entre los sucesos anteriores serían:

\begin{itemize}
\tightlist
\item
  \(A\cup B\): Estudiantes que son mujeres o que son zurdos.
\item
  \(A\cap B\): Mujeres de esta clase que son zurdas.
\item
  \(A^c\): Hombres de esta clase.
\item
  \(A\setminus B\): Mujeres de la clases que NO son zurdas.
\item
  \(B\setminus A\): Hombres de la clase que son zurdos.
\item
  \textbf{¡Cuidado!} No son incompatibles.
\end{itemize}

\subsection{Propiedades}\label{propiedades}

\begin{Proposicion}{Propiedades}{}

\textbf{Conmutativas}:

\[A\cup B=B\cup A, \quad A\cap B=B\cap A\]

\textbf{Asociativas}:

\[
\begin{aligned}
A\cup(B\cup C)=(A\cup B)\cup C, \\
A\cap(B\cap C)=(A\cap B)\cap C.
\end{aligned}
\]

\textbf{Distributivas}

\[
\begin{aligned}
A\cap & (B\cup C)=(A\cap B)\cup (A\cap C),\\
A\cup & (B\cap C)=(A\cup B)\cap (A\cup C).
\end{aligned}
\]

\end{Proposicion}

Veamos algunos diagramas que nos ayuda a demostrar las propiedades
anteriores.

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(A\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(B\cap C\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(A\cup (B\cap C)\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1A.jpeg}
&
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1ByC.jpeg}
&
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1AUByC.jpeg} \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(A\cup B\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(A\cup C\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((A\cup B)\cap (A\cup C)\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1AoB.jpeg}
&
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1AoC.jpeg}
&
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1AUByC.jpeg} \\
\end{longtable}

\begin{Proposicion}{Complementario del complementario}{}

\[(A^c)^c=A\]

\end{Proposicion}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(A\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(A^c\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((A^c)^c\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1A_solo.jpeg}
&
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1solo_Ac.jpeg}
&
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1A_solo.jpeg} \\
\end{longtable}

\begin{Proposicion}{Leyes de De Morgan}{}

\[(A\cup B)^c=A^c\cap B^c\]

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(A\cup B\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((A\cup B)^c\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/proba1dibujos/demorgan6.jpg}
&
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/proba1dibujos/demorgan7.jpg} \\
\end{longtable}

\[(A\cup B)^c=A^c\cap B^c\]

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(A^c\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(B^c\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(A^c\cap B^c\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1Ac_conB.jpeg}
&
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1Bc_conA.jpeg}
&
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1interseccioncomplementarios.jpeg} \\
\end{longtable}

\[(A\cap B)^c=A^c\cup B^c\]

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(A\cap B\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((A\cap B)^c\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1AyB.jpeg}
&
\includegraphics[width=\linewidth,height=1.51042in,keepaspectratio]{Images/_book/Images/venn1interseccioncomplementarios.jpeg} \\
\end{longtable}

\[(A\cap B)^c=A^c\cup B^c\]

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(A^c\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(B^c\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(A^c\cup B^c\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1Ac_conB.jpeg}
&
\includegraphics[width=\linewidth,height=1.5625in,keepaspectratio]{Images/venn1Bc_conA.jpeg}
&
\includegraphics[width=\linewidth,height=1.51042in,keepaspectratio]{Images/venn1Ac_conB.jpeg} \\
\end{longtable}

\end{Proposicion}

\section{Definición de
probabilidad}\label{definiciuxf3n-de-probabilidad}

La probabilidad de un suceso es una puntuación (\emph{score}) numérico
entre 0 y 1 que mide la verosimilitud de que este evento se produzca.

Esta verosimilitud puede estar justificada por:

\begin{itemize}
\item
  Estimación personal
\item
  Estimación de expertos
\item
  La frecuencia con la que se da
\item
  Cálculo formal
\end{itemize}

\begin{Definicion}{Definición formal de probabilidad}{}

Sea \(\Omega\) el espacio muestral de un experimento aleatorio.
Supongamos que el número de posibles resultados, por el momento, es
finito.

Una probabilidad sobre \(\Omega\) es una aplicación
\(P:\mathcal{P}(\Omega)\to [0,1]\) con las siguientes propiedades:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(0\leq P(A)\leq 1\), para todo suceso \(A\).
\item
  \(P(\Omega)=1\).
\item
  Si \(\{A_1,A_2,\ldots,A_n\}\) son sucesos disjuntos dos a dos,
  entonces
\end{enumerate}

\[
P(A_1\cup A_2\cup \cdots \cup A_n)=P(A_1)+P(A_2)+\cdots +P(A_n)
\]

Si \(a\in \Omega\) es un suceso elemental cometeremos el abuso de
notación de poner \(P(a)\) en lugar de \(P(\{a\})\).

\end{Definicion}

Veamos un ejemplo real de cómo se calcula la probabilidad de un suceso.

\begin{Ejemplo}{Ejemplo}{}

En la página de la
\href{http://www.donasang.org/que-es-la-sang/es_frequencies-dels-diferents-grups.html}{Fundación
Banco de Sangre y Tejidos de las Islas Baleares (17-08-2023)} podemos
encontrar información sobre los porcentajes de tipos de sangre de los
donantes de las Islas Baleares:

\[A: 46\%;\  B: 7.5\%;\  AB: 3.5\%;\  O: 43\%.\]

¿Cuál es la probabilidad de que un balear donante de sangre no sea del
tipo O?

\textbf{Experimento aleatorio:} tipo de sangre de un paciente humano:

\[\Omega=\{\mbox{A,B,AB,O}\}\]

\textbf{Probabilidad} de un suceso: se asimila al porcentaje observado
de individuos.

\textbf{Suceso:} \(\{\mbox{O}\}^c=\{\mbox{A,B,AB}\}\).

\[P(\{\mbox{O}\}^c)\!=\!P(\{\mbox{A,B,AB}\})\!=\!
P(\mbox{A})+P (\mbox{B})+P(\mbox{AB})\!=\!0.57.\]

\end{Ejemplo}

Necesitaremos tener propiedades y fórmulas prácticas para poder calcular
probabilidades de sucesos más complejos. Veamos algunas de ellas.

\begin{Proposicion}{Propiedades básicas de la probabilidad}{}

\begin{itemize}
\item
  \(P(\emptyset)=0\).
\item
  \(\scriptsize{P(A\setminus B)=P(A)-P(A\cap B)}\) porque
  \(\scriptsize{P(A)=P(A\setminus B)+P(A\cap B)}\).
\end{itemize}

\begin{center}
\includegraphics[width=0.3\linewidth,height=\textheight,keepaspectratio]{Images/proba1dibujos/A-B.jpg}
\end{center}

\begin{itemize}
\item
  Si \(B\subseteq A\), entonces \(0\leq P(B)\leq P(A)\).
\item
  \(P(A^c)=1-P(A)\).
\end{itemize}

\end{Proposicion}

Una identidad muy utilizada es la de la probabilidad de la unión de dos
sucesos cualesquiera.

\begin{Proposicion}{Probabilidad de la unión de dos sucesos}{}

\(P(A\cup B)=P(A)+P(B)-P(A\cap B)\)

\begin{center}
\includegraphics[width=0.6\linewidth,height=\textheight,keepaspectratio]{Images/proba1dibujos/A-B.jpg}
\end{center}

\end{Proposicion}

La demostración analítica de esta propiedad es la siguiente:

\[
\begin{aligned}
P(A)+P(B)-P(A\cap B) &= P(A\setminus B)+P(A\cap B)\\
& & +P(B\setminus A)+ P(A\cap  B)-P(A\cap  B)\\
&= P(A\setminus B)+P(A\cap B)+ P(B\setminus A) \\
&= P(A\cup B).\\
\end{aligned}
\]

\begin{Proposicion}{Probabilidad de la unión de \(n\) conjuntos}{}

Sean \(A_1, A_2,\ldots A_n\) sucesos. Entonces:

\[
P(\cup_{i=1}^n A_i)=\sum_{i=1}^n P(A_i)-\sum_{1\leq i<j\leq n}P(A_i\cap A_j)+\cdots +(-1)^{n-1}P(A_1\cap A_2\cap \cdots \cap A_n).
\]

\end{Proposicion}

La demostración es sencilla mediante inducción: partimos del caso base
de dos sucesos, suponemos que es cierta para \(n\) sucesos y luego la
extendemos al caso de \(n+1\) sucesos.

Como comprobación, consideremos un ejemplo genérico con tres sucesos.

\(A=\{1,4,5,6\}\), \(B=\{2,4,6,7\}\) y \(C=\{3,5,6,7\}\). En este caso
la fórmula nos da

\[
P(A\cup B\cup C)=  P(A)+P(B)+P(C)-P(A\cap B)-P(A\cap C)
-P(B\cap C)+P(A\cap B\cap C).
\]

Gráficamente tenemos esta situación:

\begin{center}
\includegraphics[width=0.3\linewidth,height=\textheight,keepaspectratio]{Images/proba1dibujos/tresconjunts.jpg}
\end{center}

Ahora podemos comprobar la fórmula para este caso.

\[
\begin{aligned}
P(A\cup B\cup C)&=P(A)+P(B)+P(C)-P(A\cap B) \\
  & & - P(A\cap C)-P(B\cap C)+P(A\cap B\cap C).\\
\end{aligned}
\]

Efectivamente tenemos que:

\[P(A\cup B\cup C)=P(1)+P(2)+P(3)+P(4)+P(5)+P(6)+P(7).\]

Una de las formas más intuitiva de asignación de probabilidades es hacer
el cociente entre los casos favorables a que acontezca el evento y los
casos posibles del experimento; la llamada fórmula de Laplace.

\begin{Proposicion}{Propiedad}{}

\begin{itemize}
\item
  En general dado un suceso \(A=\{a_1,a_2,\ldots,a_k\}\), entonces \[
  P(A)=P(a_1)+P(a_2)+\cdots+P(a_k).
  \]
\item
  \textbf{Fórmula de Laplace}: Si todos los sucesos elementales tienen
  la misma probabilidad, \[
  P(A)=\frac{|A|}{|\Omega|}\Big(=\frac{\mbox{casos favorables}}{\mbox{casos posibles}}\Big).
  \]
\end{itemize}

\end{Proposicion}

En el procesamiento del lenguaje se suelen estudiar las frecuencias de
palabras o letras de un determinado idioma. Veamos un ejemplo sobre las
frecuencias de las vocales en castellano.

\begin{Ejemplo}{< Ejemplo: Frecuencia de vocales/i>}{}

Los porcentajes de vocales de un determinado idioma (de alfabeto latino)
según la
\href{https://es.wikipedia.org/wiki/Frecuencia_de_aparici\%C3\%B3n_de_letras}{Wikipedia}
son:

\[A: 18.7\%;\ E: 26.1\%;\ I: 25.7\%;\ O: 24.4\%;\ U: 5.1\%.\]

¿Cuál es la probabilidad que una vocal escogida al azar de este idioma
sea una E o una O?

El espacio muestral del experimento es \(\Omega=\{A,E,I,O,U\}\).

El suceso que deseamos analizar es \(\{E,0\}\).

Y su probabilidad es

\[P(\{E,O\})=P(E)+P(O)=0.261+0.244=0.505.\]

\end{Ejemplo}

Otro ejemplo en este caso es sobre un test de drogas en el que se
analiza la presencia de cocaína y cannabis en la sangre de los
conductores, inspirado en un caso real.

\begin{Ejemplo}{Ejemplo: Consumo de drogas}{}

Según un artículo de
\href{https://elpais.com/politica/2019/01/02/actualidad/1546426491_623324.html}{El
País}, en un control especial de la policía el \(0.1\%\) de todos los
conductores analizados en un control de tráfico dan positivo en un el
test en cocaína, y el \(1\%\) da positivo en cannabis. Un \(1.05\%\) da
positivo en alguno de los dos test.

\textbf{Pregunta}: ¿Cuál es la probabilidad que un individuo analizado
en el control de drogas escogido al azar no de positivo en ninguno de lo
dos test?

Los sucesos elementales del enunciado del problema son:

\begin{itemize}
\tightlist
\item
  \(A\): dar positivo en cocaína; \(P(A)=0.001.\)
\item
  \(B\): dar positivo en cannabis; \(P(B)=0.01.\)
\end{itemize}

En este caso nos interesa estudiar los sucesos:

\begin{itemize}
\tightlist
\item
  \(A\cup B\): dar positivo en alguno de los dos test;
  \(P(A\cup B)=0.0105.\)
\item
  \((A\cup B)^c\): no dar positivo en ninguno de los test,por tanto:
\end{itemize}

\[P((A\cup B)^c)=1-P(A\cup B)=1-0.0105=0.9895.\]

\textbf{Pregunta}: ¿Cuál es la probabilidad que un analizado al azar de
positivo en los dos test en cocaína y cannabis?

Los sucesos elementales son:

\begin{itemize}
\tightlist
\item
  \(A\): dar positivo en cocaína; \(P(A)=0.001.\)
\item
  \(B\): dar positivo en cannabis; \(P(B)=0.01.\)
\end{itemize}

En este caso nos interesa estudiar los sucesos:

\begin{itemize}
\tightlist
\item
  \(A\cup B\): dar positivo en algún de los dos test;
  \(P(A\cup B)=0.0105.\)
\item
  \(A\cap B\): dar positivo en los dos test
\end{itemize}

de donde, por tanto:

\[\begin{array}{rl}
{P(A\cap B)} &{=P(A)+P(B)-P(A\cup B)}\\ &{=0.001+0.01-0.0105=0.0005}.
\end{array}\]

\textbf{Pregunta}: ¿Cuál es la probabilidad de que un conductor
analizado de positivo en cocaína pero no en cannabis?

Los sucesos elementales son:

\begin{itemize}
\tightlist
\item
  \(A\): dar positivo en cocaína; \(P(A)=0.001.\)
\item
  \(B\): dar positivo en cannabis; \(P(B)=0.01.\)
\end{itemize}

En este caso nos interesa estudiar los sucesos:

\begin{itemize}
\tightlist
\item
  \(A\cap B\): dar positivo en los dos test; \(P(A\cap B)=0.0005.\)
\item
  \(A\setminus B\): dar positivo en cocaína pero no en cannabis, por lo
  tanto tenemos que :
\end{itemize}

\[P(A\setminus B) =P(A)-P(A\cap B) =0.001-0.0005=0.0005.\]

\end{Ejemplo}

\section{Probabilidad condicionada}\label{probabilidad-condicionada}

\begin{Definicion}{Probabilidad condicionada}{}

Dados dos sucesos \(A\) y \(B\), con \(P(A)>0\), la probabilidad
\(P(B|A)\) de \(B\) condicionado a \(A\) es la probabilidad

\begin{itemize}
\tightlist
\item
  de que suceda \(B\) suponiendo que pasa \(A\),
\item
  de que si pasa \(A\), entonces suceda \(B\),
\item
  de que un resultado de \(A\) también pertenezca a \(B\).
\end{itemize}

Se calcula a través de la definición:

\[
P(B|A)=\frac{P(A\cap B)}{P(A)}.
\]

\end{Definicion}

\begin{Ejemplo}{Ejemplo: Probabilidad condicionada}{}

En una clase de 20 hombres y 30 mujeres, 15 hombres y 18 mujeres llevan
gafas. Contestemos las siguientes preguntas:

¿Cuál es la probabilidad de que un alumno lleve gafas?

\[
\frac{33}{50}
\]

¿Cuál es la probabilidad de que un alumno sea mujer y lleve gafas?

\[
\frac{18}{50}
\]

¿Cuál es la probabilidad de que un chica lleve gafas?

\[
\frac{18}{30}=\frac{18/50}{30/50}=\frac{P(\mbox{mujer  y gafas})}{P(\mbox{mujer})}.
\]

Si escogemos un estudiante al azar ¿Cuál es la probabilidad que si es
mujer, entonces lleve gafas?

\[
\frac{18}{30}.
\]

¿Cuál es la probabilidad de que un alumno que lleve gafas sea mujer?

\[
\frac{18}{33}=\frac{18/50}{33/50}=\frac{P(\mbox{mujer y gafas})}{P(\mbox{gafas})}.
\]

Si escogemos un estudiante al azar ¿Cuál es la probabilidad de que si
lleva gafas, entonces sea mujer? \[
    \frac{18}{33}
    \]

\end{Ejemplo}

\begin{Advertencia}{¡Atención!}{}

Hay que distinguir bien entre

\begin{itemize}
\tightlist
\item
  \(P(A\cap B)\): probabilidad de \(A\) \(\color{red}{\text{y}}\) \(B\).
\end{itemize}

\emph{Probabilidad de que sea mujer y lleve gafas.}

\begin{itemize}
\tightlist
\item
  \(P(A|B)\): probabilidad de que \(\color{red}{\text{si}}\) pasa \(B\),
  \(\color{red}{\text{entonces}}\) pase \(A\).
\end{itemize}

\emph{Probabilidad de que, si es mujer, lleve gafas.}

Cuando utilizamos probabilidad condicional \(P(A|B)\) estamos
restringiendo el espacio muestral a \(B\).

\end{Advertencia}

\subsection{Probabilidad condicionada.
Propiedades}\label{probabilidad-condicionada.-propiedades}

La probabilidad condicionada es una probabilidad, en el sentido de la
siguiente propiedad.

\begin{Proposicion}{Propiedad}{}

Sea \(A\subseteq \Omega\) un suceso tal que \(P(A)>0\), entonces

\[
\begin{array}{rccl}
P(-|A):& \mathcal{P}(\Omega) & \to & [0,1]\\
&B & \mapsto & P(B|A).
\end{array}
\] satisface las propiedades de las probabilidades, como por ejemplo:

\[
\begin{array}{l}
P(B^c|A)=1-P(B|A),\\
P(B_1\cup B_2|A)=P(B_1|A)+P(B_2|A)-P(B_1\cap B_2|A).
\end{array}
\]

\end{Proposicion}

También se cumplirán el resto de propiedades mientras se condicionen
cada una de las probabilidades al mismo suceso \(A\).

\begin{Ejercicio}{Ejercicio}{}

Escribid el resto de propiedades que cumpliría una probabilidad
condicionada al evento \(A\).

\end{Ejercicio}

Veamos un ejemplo donde se aplica la probabilidad condicionada, en este
caso, para calcular la probabilidad de que un adulto sea hipertenso,
dado que cree que lo es.

\begin{Ejemplo}{Ejemplo}{}

Un 15\% de los adultos son hipertensos, un 25\% de los adultos creen que
son hipertensos, y un 9\% de los adultos son hipertensos y creen que lo
son.

Si un adulto cree que es hipertenso, ¿cuál es la probabilidad que lo
sea?

Sean los sucesos

\begin{itemize}
\tightlist
\item
  \(A\): ser hipertenso, \(P(A)=0.15\) ,
\item
  \(B\): creer ser hipertenso, \(P(B)=0.25\),
\end{itemize}

Ahora podemos definir el suceso:

\begin{itemize}
\tightlist
\item
  \(A\cap B\): ser hipertenso y creerlo, \(P(A\cap B)=0.09\).
\end{itemize}

de donde, la probabilidad condicionada de ser hipertenso creyéndonos que
lo somos es:

\[\scriptsize P(A|B)=\dfrac{P(A\cap B)}{P(B)}=\dfrac{0.09}{0.25}=0.36.\]

Otra pregunta es, si un adulto es hipertenso, ¿cuál es la probabilidad
que crea que lo es?

Si tenemos los sucesos:

\begin{itemize}
\tightlist
\item
  \(A\): ser hipertenso,
\item
  \(B\): creer ser hipertenso
\end{itemize}

entonces buscamos la probabilidad \(P(B|A)\):

\[
\begin{array}{rl}
P(B|A) & =\dfrac{P(A\cap B)}{P(A)}=\dfrac{0.09}{0.15}=
0.6
\end{array}
\]

\end{Ejemplo}

\begin{Ejemplo}{Ejemplo}{}

Otro ejemplo de probabilidad condicionada en este caso un ejemplo simple
de dígito de control de error.

Un dígito de control de error toma el valor 0 en el 99\% de los casos en
que hay un error. Si la probabilidad de error en un mensaje es del
\(0.5\%\). ¿cuál es la probabilidad de que el mensaje sea erróneo y el
código de error tenga valor 0?

\begin{itemize}
\tightlist
\item
  \(B\): mensaje con error; \(P(B)=0.005\),
\item
  \(A\): código de error vale 0,
\item
  \(P(A|B)=0.99\),
\end{itemize}

entonces: \[P(A\cap B)=P(B)\cdot P(A|B)=0.005\cdot 0.99=0.00495.\]

\end{Ejemplo}

La probabilidad condicional también es útil en la resolución de
problemas de clasificación, como el siguiente ejemplo.

\begin{Ejemplo}{Ejemplo: SPAM}{}

Un 50\% de correos recibidos en un servidor llevan adjuntos y un 65\%
son publicidad no deseada (SPAM). Sólo un 15\% de estos correos no
llevan adjuntos y no son SPAM.

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad que un correo lleve adjunto si es SPAM?
\item
  ¿Cuál es la probabilidad que un correo \textbf{no} tenga adjuntos si
  \textbf{no} es SPAM?
\item
  ¿Cuál es la probabilidad que un correo lleve adjunto si es SPAM?
\end{itemize}

Asignemos sucesos y probabilidades

\begin{itemize}
\tightlist
\item
  \(A\): llevar adjuntos; \(P(A)=0.5\), - \(S\): SPAM; \(P(S)=0.65\), -
  \(A^c\cap S^c=(A\cup S)^c\): no llevar adjunto y no ser SPAM;
  \(P((A\cup S)^c)=0.15\),
\end{itemize}

\[P(A|S)=\dfrac{P(A\cap S)}{P(S)}=?\]

\begin{itemize}
\item
  ¿Cuál es la probabilidad que un correo lleve adjunto si es SPAM?
\item
  \(P(A)=0.5, P(S)=0.65, P(A^c\cap S^c)=P((A\cup S)^c)=0.15\),
\item
  \(P(A\cup S)=1-P((A\cup S)^c)=0.85\),
\item
  \(P(A\cap S)=P(A)+P(S)-P(A\cup S)=0.3\),
\end{itemize}

\[P(A|S)=\dfrac{P(A\cap S)}{P(S)}=\dfrac{0.3}{0.65}\approx 0.46.\]

\begin{itemize}
\item
  Otra pregunta es ¿Cuál es la probabilidad de que un correo no lleve
  adjuntos si no es SPAM?
\item
  \(P(A)=0.5, P(S)=0.65, P(A^c\cap S^c)=P((A\cup S)^c)=0.15.\)
\end{itemize}

\[P(A^c|S^c)=\dfrac{P(A^c\cap S^c)}{P(S^c)}=\dfrac{P(A^c\cap S^c)}{1-P(S)}=\dfrac{0.15}{0.35}\approx 0.43.\]

\end{Ejemplo}

\section{Teorema de la probabilidad
total}\label{teorema-de-la-probabilidad-total}

\begin{Teorema}{Teorema de la probabilidad total}{}

Dados dos sucesos \(A\) y \(B\) se tiene que

\[
\begin{array}{rl}
P(B)&= P(B\cap A) +P(B\cap A^c)\\
& =P(A)\cdot P(B|A)+ P(A^c)\cdot P(B|A^c).
\end{array}
\]

\end{Teorema}

Vamos a generalizar el resultado anterior a una colección de sucesos
\(A_1,A_2,\ldots,A_n\) que forman una partición del espacio muestral
\(\Omega\).

\begin{Definicion}{Partición del espacio espacio muestral}{}

Los sucesos \(A_1,A_2,\ldots, A_n\) son una \textbf{partición} del
espacio muestral \(\Omega\) de un determinado experimento aleatorio, si
cumplen las condiciones siguientes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(A_1\cup A_2\cup\ldots\cup A_n=\Omega\),
\item
  \(A_1,A_2,\ldots,A_n\) son incompatibles dos a dos
  (\(A_i\cap A_j=\emptyset\)).
\end{enumerate}

\end{Definicion}

Ahora podemos volver a enunciar el teorema anterior pero en esta ocasión
para particiones arbitrarias.

\begin{Teorema}{Teorema de la probabilidad total generalizado}{}

Sea \(A_1,A_2,\ldots,A_n\) una partición de \(\Omega\). Sea \(B\) un
suceso cualquiera. Entonces

\[
\begin{array}{rl}
P(B)&= P(B\cap A_1)+\cdots +P(B\cap A_n)\\
& =P(A_1)\cdot P(B|A_1)+\ldots+P(A_n)\cdot P(B|A_n).
\end{array}
\]

\end{Teorema}

Revisitemos el ejemplo de los mensajes con dígitos de control de error.

\begin{Ejemplo}{Ejemplo}{}

Un dígito de control de error toma el valor 0 en un \(99\%\) de los
casos en que hay un error y en un \(5\%\) de los mensajes sin error. La
probabilidad de error en un mensaje es del \(0.5\%\).

¿Cuál es la probabilidad de que un mensaje escogido al azar tenga el
dígito de control a 0?

Sean los sucesos del enunciado:

\begin{itemize}
\tightlist
\item
  \(B\): mensaje con error; \(P(B)=0.005\),
\item
  \(A\): código de error vale 0,
\end{itemize}

entonces obtenemos las probabilidades a partir del enunciado:

\begin{itemize}
\tightlist
\item
  \(P(A|B)=0.99,\)
\item
  \(P(A|B^c)= 0.05\)
\end{itemize}

y por tanto,

\[
\begin{array}{rl}
P(A)=& P(B)\cdot P(A|B)+P(B^c)\cdot P(A|B^c)\\
& =0.005\cdot 0.99+0.995\cdot 0.05=0.0547.
\end{array}
\]

\end{Ejemplo}

\section{Clasificación o diagnóstico caso
binario}\label{clasificaciuxf3n-o-diagnuxf3stico-caso-binario}

Consideremos alguna de las siguientes situaciones:

\begin{itemize}
\tightlist
\item
  Un algoritmo detecta si una transacción con tarjeta de crédito es
  fraude o no.
\item
  Un algoritmo detecta si tiene o no que mostrar un anuncio en una web.
\item
  Un prueba de embarazo.
\item
  Una prueba médica para una enfermedad concreta.
\end{itemize}

Nos ceñiremos a la casuística más elemental el algoritmo de
clasificación o la diagnosis solo da dos resultado \textbf{Positivo} (sí
tienes la enfermedad, sí es un fraude) o \textbf{Negativo} (en caso
contrario).

SPAM continuación

En todas estas situaciones podemos calcular lo que se llama
\textbf{matriz de confusión} que representa todas las situaciones
posibles. En el caso de estudiar una condición de tipo binario,

\begin{longtable}[]{@{}lcc@{}}
\toprule\noalign{}
& El Test da Positivo & El Test da Negativo \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Condición Positiva & Correcto & Error \\
Condición Negativa & Error & Correcto \\
\end{longtable}

En general los modelos y algoritmos de clasificación suelen aportar
puntuaciones (\emph{scores}) que determinan el grado de pertenencia a
una clase, o que miden si dos objetos están en la misma clase.

Así el resultado del clasificador o del diagnóstico puede ser:

\begin{itemize}
\tightlist
\item
  \textbf{un número real}, en cuyo caso debe clasificador entre cada
  clase debe determinarse por un valor umbral (\emph{threshold}) por
  ejemplo para determinar si una persona está estresado podemos dar un
  \emph{scores} entre 0 y 1 (1 máximo estrés 0 estrés nulo),
\item
  \textbf{un resultado discreto} que indica directamente una de las
  clases (esto es necesario si es un algoritmo que debe decidir qué
  hacer con el objeto.
\end{itemize}

\begin{Ejemplo}{Falsos Positivos y Falsos Negativos}{}

Consideremos un problema de predicción de clases binario, en la que los
resultados se etiquetan positivos (P) o negativos (N). Hay cuatro
posibles resultados a partir de un clasificador binario como el
propuesto.

\begin{itemize}
\tightlist
\item
  Si el resultado de una exploración es P y el valor dado es también P,
  entonces se conoce como un Verdadero Positivo (VP).
\item
  Sin embargo si el valor real es N entonces se conoce como un Falso
  Positivo (FP).
\item
  De igual modo, tenemos un Verdadero Negativo (VN) cuando tanto la
  exploración como el valor dado son N.
\item
  Un Falso Negativo (FN) cuando el resultado de la predicción es N pero
  el valor real es P.
\end{itemize}

\end{Ejemplo}

Veamos el siguiente ejemplo:

\begin{Ejemplo}{Falsos Positivos y Negativos}{}

Un ejemplo aproximado de un problema real es el siguiente: consideremos
una prueba diagnóstica que persiga determinar si una persona tiene una
cierta enfermedad.

\begin{itemize}
\tightlist
\item
  Un falso positivo en este caso ocurre cuando la prueba predice que el
  resultado es positivo, cuando la persona no tiene realmente la
  enfermedad.
\item
  Un falso negativo, por el contrario, ocurre cuando el resultado de la
  prueba es negativo, sugiriendo que no tiene la enfermedad cuando
  realmente sí la tiene.
\end{itemize}

En un diagnósticos de una cierta condición (por ejemplo, test embarazo,
test de enfermedad), tenemos dos tipos de sucesos:

\begin{itemize}
\tightlist
\item
  \(T\): el test da positivo,
\item
  \(M\): el sujeto satisface la condición.
\end{itemize}

\end{Ejemplo}

Necesitamos algunas denominaciones adicionales:

\begin{Definicion}{Falsos Positivos y Negativos}{}

\begin{itemize}
\tightlist
\item
  \textbf{Falsos positivos} \(T\cap M^c\): El test da positivo, pero la
  condición no se da,
\item
  \textbf{Coeficiente de falsos positivos} \(P(T|M^c)\),
\item
  \textbf{Falsos negativos} \(T^c\cap M\): El test da negativo, pero la
  condición sí que se da,
\item
  \textbf{Coeficiente de falsos negativos}: \(P(T^c|M)\).
\end{itemize}

\end{Definicion}

\begin{Ejemplo}{Falsos Positivos y Negativos}{}

Un test diseñado para diagnosticar una determinada enfermedad tiene un
coeficiente de falsos negativos de 0.06, y un coeficiente de falsos
positivos de 0.04. En un estudio masivo se observa que un 15\% de la
población da positivo al test.

¿Cuál es la probabilidad que una persona escogida aleatoriamente tenga
esta enfermedad?

Los datos del problema son:

\begin{itemize}
\tightlist
\item
  \(T\): dar positivo al test; \(P(T)=0.15\),
\item
  \(M\): tener la enfermedad,
\item
  \(P(T)=0.15\), \(P(T^c|M)=0.06\), \(P(T|M^c)=0.04\),
\item
  ¿\(P(M)\)?
\end{itemize}

\[
P(T) =P(M)\cdot P(T|M)+P(M^c)\cdot P(T|M^c).
\]

donde

\[
\begin{array}{l}
P(T|M)=1-P(T^c|M)=0.94 \\
P(M^c)=1-P(M).
\end{array}
\]

Por lo tanto

\[
\begin{array}{rl}
0.15 & = P(M)\cdot 0.94+(1-P(M))\cdot 0.04\\
 & =0.04+0.9\cdot P(M)\\
P(M) & =\dfrac{0.11}{0.9}\approx 0.1222.
\end{array}
\]

\end{Ejemplo}

\section{Teorema de Bayes}\label{teorema-de-bayes}

\begin{Teorema}{Teorema de Bayes para dos sucesos}{}

Sean \(A\) y \(B\) dos sucesos. Si \(P(B)>0\), entonces

\[
P(A|B) =\dfrac{P(A)\cdot P(B|A)}{P(B)}=\dfrac{P(A)\cdot P(B|A)}{P(A)\cdot P(B|A)+P(A^c)\cdot P(B|A^c)}.
\]

\end{Teorema}

\begin{Ejemplo}{Ejemplo}{}

Demostrar el teorema de Bayes utilizando que

\[P(A|B) =\dfrac{P(A\cap B)}{P(B)}=\cdots\]

\end{Ejemplo}

Generalicemos este resultado para una partición arbitraria del espacio
muestral.

\begin{Teorema}{Teorema de Bayes para una partición}{}

Sea \(A_1,A_2,\ldots,A_n\) una partición de \(\Omega\). Sea \(B\) un
suceso tal que \(P(B)>0\). entonces(para cualquier \(i=1,2,\ldots,n\)):

\[
\begin{array}{rl}
P(A_i|B) & =\dfrac{P(A_i)\cdot P(B|A_i)}{P(B)}\\
& =\dfrac{P(A_i)\cdot P(B|A_i)}{P(A_1)\cdot P(B|A_1)+\cdots+P(A_n)\cdot P(B|A_n)},
\end{array}
\]

\end{Teorema}

Podéis demostrar el teorema de Bayes utilizando que

\[P(A_i|B) =\dfrac{P(A_i\cap B)}{P(B)}=\cdots\]

\begin{Ejemplo}{Test de VIH}{}

Un test para detección de VIH da positivo un 99\% de los casos en los
que está presente y en un 5\% de los casos en los que el virus está
ausente. En una población con un \(0.5\%\) de infectados por VIH, ¿cuál
es la probabilidad que un individuo que haya dado positivo en el test
esté infectado?

Los sucesos del ejemplo son:

\begin{itemize}
\tightlist
\item
  \(A\): individuo infectado,
\item
  \(B\): el test da positivo,
\end{itemize}

de donde podemos calcular:

\[\scriptsize{
P(A|B) =\dfrac{P(B|A)\cdot P(A)}{P(B|A)\cdot P(A)+P(B|A^c)\cdot P(A^c)}=\dfrac{0.99\cdot 0.005}{0.005\cdot 0.99+0.995\cdot 0.05}=0.09.}
\]

Un test para detección de VIH da positivo un 99\% de los casos en los
que está presente y en un 5\% de los casos en los que el virus está
ausente. En una población con un \(0.5\%\) de infectados por VIH, ¿cuál
es la probabilidad de que un individuo que haya dado \textbf{negativo}
en el test \textbf{no} esté infectado?

Los sucesos del ejemplo son:

\begin{itemize}
\tightlist
\item
  \(A\): individuo infectado,
\item
  \(B\): el test da positivo,
\end{itemize}

de donde podemos calcular:

\[
\scriptsize{P(A^c|B^c) =\dfrac{P(B^c|A^c)\cdot P(A^c)}{P(B^c|A)\cdot P(A)+P(B^c|A^c)\cdot P(A^c)}=\dfrac{0.95\cdot 0.995}{0.01\cdot 0.005+0.95\cdot 0.995}=0.999947.}
\]

\end{Ejemplo}

\begin{Ejemplo}{Ejemplo: Tipos de clientes}{}

Se ha observado que los cientes de una empresa de ventas por internet
son de tres tipos, A, B y C, disjuntos dos a dos. La probabilidad que
ser de cualquiera de cada uno de los tipos es \(1/3\), pero la
probabilidad de compra de cada tipo es diferente: si es de tipo A compra
un 50\% de las veces, si de tipo B, un 75\% de las veces, y de tipo C,
un 60\%.

Supongamos que llega un cliente ¿cuál es la probabilidad de que si ha
comprado sea del tipo B?

Los sucesos del ejercicio son \(A\): el cliente es de tipo A, \(B\): el
cliente es de tipo B, \(C\): el cliente es de tipo C y

\[P(A)=P(B)=P(C)=1/3.\]

Buscamos estudiar el suceso \(E\): el cliente compra, se tiene que:

\[P(E|A)=0.5, P(E|B)=0.75, P(E|C)=0.6.\]

\[P(B|E)\!=\!\dfrac{P(E|B)\cdot P(B)}{P(E|A)\!\cdot\! P(A)\!+\!P(E|B)\!\cdot\! P(B)\!+\!P(E|C)\!\cdot\! P(C)}\!=\!\ldots\]

\end{Ejemplo}

\begin{Ejemplo}{Ejemplo: Fidelización de clientes}{}

Para fidelizar a sus clientes una empresa implementa un test de
detección precoz de abandono de clientes de una empresa de telefonía da
positivo el 97.5\% de las ocasiones en las que, posteriormente, el
cliente se da de baja, y un 12\% de las veces en que no se dio de baja.
La probabilidad que un cliente escogido al azar se dé de baja es de un
2\%.

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad que un individuo escogido al azar de positivo
  en el test?
\item
  ¿Cuál es la probabilidad que un individuo escogido al azar se de de
  baja y dé positivo en el test?
\item
  ¿Cuál es la probabilidad que un individuo que dé negativo en el test
  se dé de baja?
\end{itemize}

Definimos los sucesos y datos del ejercicio:

\begin{itemize}
\tightlist
\item
  \(T\): Dar positivo al test,
\item
  \(B\): darse de baja; \(P(B)=0.02\),
\item
  \(P(T|B)=0.975, P(T|B^c)=0.12\).
\end{itemize}

\[P(B)=0.02, P(T|B)=0.975, P(T|B^c)=0.12.\]

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad que un individuo escogido al azar de positivo
  en el test?
\end{itemize}

\[
\begin{array}{rl}
P(T) = & P(B)\cdot P(T|B)+P(B^c)\cdot P(T|B^c)\\[1ex]
& =0.02\cdot 0.975+0.98\cdot 0.12=0.1371.
\end{array}
\]

¿Cuál es la probabilidad que un individuo escogido al azar se de de baja
y dé positivo en el test?

\[P(B\cap T)= P(B)\cdot P(T|B)=0.02\cdot 0.975=0.0195.\]

\[P(B)=0.02, P(T|B)=0.975, P(T|B^c)=0.12.\]

¿Cuál es la probabilidad que un individuo que dé negativo en el test se
dé de baja?

\[
\begin{array}{rl}
P(B|T^c)= &\displaystyle \frac{P(B\cap T^c)}{P(T^c)}=
\frac{P(B)-P(B\cap T)}{1-P(T)}\\[2ex] & \displaystyle =
\frac{0.02-0.0195}{1-0.1371}\approx 0.00058
\end{array}
\]

O también se obtiene así \[
    P(B|T^c)=\frac{P(T^c|B)\cdot P(B)}{P(T^c|B)\cdot P(B)+P(T^c|B^c)\cdot P(B^c)},
    \]

donde \(P(T^c|B)=1-P(T|B)=0.025\) y \(P(T^c|B^c)=1-P(T|B^c)=0.88.\)

\end{Ejemplo}

\section{Independencia de sucesos}\label{independencia-de-sucesos}

\begin{Definicion}{Sucesos Independientes}{}

Diremos que los sucesos \(A\) y \(B\) son \textbf{independientes} si
\(P(A\cap B)=P(A)\cdot P(B)\).

\(A_1,\ldots, A_n\) son sucesos \textbf{independientes} cuando, para
toda subfamilia \(A_{i_1},\ldots,A_{i_k}\), \[
P(A_{i_1}\cap \cdots\cap A_{i_k})=P(A_{i_1})\cdots P(A_{i_k}).
\]

\end{Definicion}

\begin{Proposicion}{Propiedad}{}

Dados dos sucesos \(A\) y \(B\) con \(P(A),P(B)0\), las siguientes
afirmaciones son equivalentes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(A\) y \(B\) son independientes.
\item
  \(P(A|B)=P(A)\).
\item
  \(P(B|A)=P(B)\).
\item
  \(A^c\) y \(B\) son independientes.
\item
  \(A\) y \(B^c\) son independientes.
\item
  \(A^c\) y \(B^c\) son independientes.
\end{enumerate}

\end{Proposicion}

Veamos un sencillo ejemplo de compras de billetes de avión y alojamiento
en hotel.

\begin{Ejemplo}{Ejemplo billete avión}{}

En la web de viajes WEBTravel, el 55\% de los clientes compra billete de
avión, el \(20\%\) alojamiento en hotel, y el \(60\%\) billete de avión
o alojamiento en hotel. ¿Son los sucesos comprar billete de avión y
comprar alojamiento en hotel independientes?

Los sucesos y datos del ejemplo son:

\begin{itemize}
\tightlist
\item
  \(A\): comprar billete de avión; \(P(A)=0.55\),
\item
  \(B\): comprar alojamiento; \(P(B)=0.2\),
\end{itemize}

por tanto, podemos calcular las probabilidades siguientes

\(P(A\cap B)=P(A)+P(B)-P(A\cup B)=0.55+0.2-0.6=0.15\) y
\(P(A)\cdot P(B) = 0.55\cdot 0.2=0.11.\)

Concluimos que son dependientes, ya que
\(P(A\cap B)\neq P(A)\cdot P(B)\).

\end{Ejemplo}

\section{Sucesos independientes vs
disjuntos}\label{sucesos-independientes-vs-disjuntos}

\begin{Ejercicio}{sucesos disjuntos e independencia}{}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Dos sucesos \(A\) y \(B\) disjuntos, ¿son necesariamente
  independientes?
\item
  Dos sucesos \(A\) y \(B\) independientes, ¿son necesariamente
  disjuntos?
\item
  \(\emptyset\) y un suceso cualquiera \(A\), ¿son necesariamente
  independientes?
\item
  \(\Omega\) y un suceso cualquiera \(A\), ¿son necesariamente
  independientes?
\item
  ¿Qué condiciones se tienen que dar para que un suceso \(A\) sea
  independiente de si mismo?
\end{enumerate}

\end{Ejercicio}

\chapter{Variables aleatorias}\label{variables-aleatorias}

\section{Introducción}\label{introducciuxf3n}

Hasta ahora nuestros sucesos han sido de varios tipos: \(\{C,+\}\) en la
moneda, nombres de periódicos, ángulos en una ruleta, número de veces
que sale cara en el lanzamiento de una moneda etc.\ldots

Necesitamos estandarizar de alguna manera todos estos sucesos. Una
solución es asignar a cada suceso un cierto conjunto de números reales,
es decir, convertir todos los sucesos en \emph{sucesos de números
reales} para trabajar con ellos de forma unificada.

Para conseguirlo utilizaremos unas funciones que transformen los
elementos del espacio muestral en números; estas funciones son las
variables aleatorias.

\section{Definición de variable
aleatoria}\label{definiciuxf3n-de-variable-aleatoria}

Comenzaremos dando una definición poco rigurosa, pero suficiente, de
variable aleatoria.

\begin{Definicion}{Variable Aleatoria (definición práctica)}{}

Una variable aleatoria (v.a.) es una aplicación que toma valores
numéricos determinados por el resultado de un experimento aleatorio

\end{Definicion}

\begin{Advertencia}{Aviso}{}

Esta es una \textbf{definición práctica} para empezar a trabajar. Más
adelante daremos la formulación rigurosa (funciones medibles y
\(\sigma\)-álgebras).

\end{Advertencia}

\begin{Nota}{Notación}{}

\begin{itemize}
\tightlist
\item
  Normalmente representaremos las v.a. por letras mayúsculas
  \(X,Y,Z\ldots\)
\item
  Los valores que ``\emph{toman}'' las v.a. los representaremos por
  letras minúsculas (las mismas en principio) \(x,y,z\ldots\)
\end{itemize}

\end{Nota}

\begin{Ejemplo}{Ejemplo}{}

Lanzamos un dado convencional de parchís el espacio muestral del
experimento es

\[\Omega=\{1,2, 3, 4,  5, 6\}.\]

Una v.a \(X:\Omega\to\mathbb{R}\) sobre este espacio queda definida por

\[X(1)=1, X(2)=2, X(3)=3, X(4)=4, X(5)=5, X(6)=6.\]

\begin{itemize}
\tightlist
\item
  Ahora el suceso \(A=\{2, 4, 6\}\), es decir ``salir número par'', es
  equivalente a \(\{X=2,X=4,X=6\}\).
\item
  El suceso \(B=\{1,2,3\}\), es decir ``salir un número inferior o igual
  a \(3\)'' es en términos de la v.a. \(\{X=1,X=2,X=3\}\) o también
  \(\{X\leq
  3\}\).
\end{itemize}

Consideremos el experimento lanzar una anilla al cuello de una botella.
Si acertamos a ensartar la anilla en la botella el resultado del
experimento es \textbf{éxito} y \textbf{fracaso} en caso contrario.

El espacio muestral asociado a este experimento será
\(\Omega=\{\mbox{éxito, fracaso}\}\). Construyamos la siguiente variable
aleatoria:

\[X:\{\mbox{éxito, fracaso}\}\to\mathbb{R}\]

definida por

\[X(\mbox{éxito})=1 \mbox{ y } X(\mbox{fracaso})=0.\]

\end{Ejemplo}

\section{Tipos de variables
aleatorias}\label{tipos-de-variables-aleatorias}

Hay dos tipos fundamentales de variables aleatorias, las discretas y las
continuas.

Damos a continuación una definición informal.

\begin{Definicion}{Variables Aleatorias Discretas y Continuas}{}

\begin{itemize}
\tightlist
\item
  Una variable aleatoria es \textbf{discreta} si sólo puede tomar una
  cantidad numerable de valores con probabilidad positiva.
\item
  Las variables aleatorias \textbf{continuas} toman valores en
  intervalos.
\item
  También existen las variables aleatorias \textbf{mixtas}; con una
  parte discreta y otra continua.
\end{itemize}

\end{Definicion}

\section{Ejemplo}\label{ejemplo}

\begin{Ejemplo}{Ejemplo}{}

Son variables \emph{aleatorias discretas}:

\begin{itemize}
\tightlist
\item
  Número de artículos defectuosos en un cargamento.
\item
  Número de clientes que llegan a una ventanilla de un banco en una
  hora.
\item
  Número de errores detectados en las cuentas de una compañía.
\item
  Número de reclamaciones de una póliza de un seguro médico.
\end{itemize}

Son variables \emph{aleatorias continuas}:

\begin{itemize}
\tightlist
\item
  Renta anual de una familia.
\item
  Cantidad de petróleo importado por un país.
\item
  Variación del precio de las acciones de una compañía de
  telecomunicaciones.
\item
  Porcentaje de impurezas en un lote de productos químicos.
\end{itemize}

\end{Ejemplo}

\section{Variables aleatorias
discretas}\label{variables-aleatorias-discretas}

Pasamos ahora a describir el comportamiento de la v.a. Para ello
utilizaremos distintas funciones que nos darán algunas probabilidades de
la variable aleatoria.

En el caso discreto estas funciones son la de probabilidad, y la función
de distribución o de probabilidad acumulada.

En el caso discreto la función de probabilidad es la que nos da las
probabilidades de los sucesos elementales de la v.a. que definimos a
continuación.

\section{Distribuciones de probabilidad
discretas}\label{distribuciones-de-probabilidad-discretas}

\begin{Definicion}{Función de Probabilidad}{}

La \textbf{función de probabilidad} (\emph{probability mass function} o
incluso abusando de notación \emph{probability density function}) de una
variable aleatoria discreta \(X\) a la que denotaremos por \(P_{X}(x)\)
está definida por

\[P_{X}(x)=P(X=x),\]

es decir la probabilidad de que \(X\) tome el valor \(x\).

Si \(X\) no asume ese valor \(x\), entonces \(P_{X}(x)=0\).

\textbf{Dominio de una variable aleatoria discreta}

El conjunto \[D_X=\{ x\in\mathbb{R} \mid P_X(x)>0\}\] recibe el nombre
de \textbf{dominio} de la v.a. y son los valores posibles de esta
variable.

En el caso discreto lo más habitual es que \(X(\Omega)=D_X\).

\end{Definicion}

\begin{Ejemplo}{Ejemplo: Dado de parchís}{}

Lanzamos un dado de parchís una vez, en esta ocasión representaremos los
sucesos elementales por el número de puntos de la cara obtenida, tenemos
que
\[\Omega=\{\mbox{1-puntos,2-puntos,3-puntos,4-puntos,5-puntos,6-puntos}\}\]
y la variable aleatoria \(X:\Omega\to \mathbb{R}\) viene definida por

\[X(\mbox{i-puntos})=i\mbox{ para } i=1,2,3,4,5,6.\]

Supongamos que el dado está bien balanceado. Entonces
\[\scriptsize{P_{X}(1)=P_{X}(2)=P_{X}(3)=P_{X}(4)=P_{X}(5)=P_{X}(6)=\frac16; \mbox{  concretamente}.}\]

\[\scriptsize{
P_{X}(x)=
  \left\{
  \begin{array}{ll}
   \frac16 ,& \mbox{si } x=1,2,3,4,5,6.\\
  0 & \mbox{en otro caso.}
  \end{array}
  \right.}
\]

Su dominio es \[D_X=\{1,2,3,4,5,6\}.\]

\end{Ejemplo}

\begin{Ejemplo}{Ejemplo: lanzamiento moneda}{}

Sea \(X\) la v.a. asociada al lanzamiento de una moneda. Su espacio
muestral es \(\Omega=\{c,+\}\), la v.a. queda definida por:

\[X(\omega)=\left\{\begin{array}{ll} 1 & \mbox{si } \omega=c \\
0 & \mbox{si }\omega=+\end{array}\right.\] Su función de probabilidad
es:

\[P_{X}(x)=P(X=x)=\left\{\begin{array}{ll} \frac12, & \mbox{si } x=0,1,\\
0, & \mbox{en otro caso}.\end{array}\right.\]

Finalmente su dominio es \(D_X=\{0,1\}.\)

\end{Ejemplo}

\begin{Ejemplo}{Ejemplo: urna con bolas}{}

Tenemos una urna con tres bolas rojas, una negra y dos blancas.
Realizamos una extracción y observamos el color de la bola entonces un
espacio muestral es \[\Omega=\{roja, blanca, negra\}.\]

Una variable aleatoria asociada al experimento es:

\[X(\omega)=\left\{\begin{array}{ll} 1, & \mbox{si } \omega=roja,  \\
2, & \mbox{si }\omega=negra ,\\ 3, & \mbox{si } \omega=blanca.\end{array}\right.\]

La función de probabilidad es

\[P_{X}(x)=\left\{\begin{array}{ll} \frac36, & \mbox{si } x=1,\\[0.5ex]
\frac16, & \mbox{si } x=2,\\ \frac26, & \mbox{si } x=3,\\ 0 & \mbox{en otro
caso.}\end{array}\right.\]

El dominio de la v.a. \(X\) es \(D_X=\{1,2,3\}.\)

\end{Ejemplo}

\section{Propiedades de la función de
probabilidad}\label{propiedades-de-la-funciuxf3n-de-probabilidad}

\begin{Proposicion}{Propiedades básicas de la función de probabilidad}{}

Sea \(X\) una v.a. discreta \(X:\Omega:\to\mathbb{R}\) con dominio
\(D_X\). Su función de probabilidad \(P_{X}\) verifica las siguientes
propiedades:

\begin{itemize}
\tightlist
\item
  \(0\leq P_{X}(x)\leq 1\) para todo \(x\in\mathbb{R},\)
\item
  \(\sum\limits_{x\in D_X} P_{X}(x)=1.\)
\end{itemize}

\end{Proposicion}

\begin{Ejemplo}{Ejemplo: lanzmiento moneda}{}

Lanzamos al aire tres veces, de forma independiente, una moneda
perfecta. El espacio muestral de este experimento es
\[\Omega=\{ccc,cc+,c+c,+cc,c++,+c+,++c,+++\}\] (expresados en orden de
aparición).

Este espacio tiene todos los sucesos elementales equiprobables.

Consideremos la variable aleatoria asociada a este experimento:

\[X=\mbox{ número de caras en los tres lanzamientos}.\]

Su función de probabilidad es:

\[
\begin{array}{l}
P(X=0)=P(\{+++\})=\frac18,\\ P(X=1)=P(\{c++,+c+,++c\})=\frac38,\\
    P(X=2)=P(\{cc+,c+c,+cc\})=\frac38,\\
    P(X=3)=P(\{ccc\})=\frac18.
\end{array}
\]

Podemos reescribir la función de probabilidad de \(X\) de forma
simplificada:

\[P_{X}(x)=\left\{\begin{array}{ll} \frac18, & \mbox{si } x=0, 3,\\[0.5ex]
\frac38, & \mbox{si } x=1,2,\\ 0, & \mbox{en otro caso}.\end{array}\right.\]

Efectivamente los valores de la función de distribución suman 1:

\[\sum_{x=0}^3 P_X(x)= \frac18+\frac38+\frac38+\frac18=1.\]

\end{Ejemplo}

\section{Función de distribución de variables
aleatorias}\label{funciuxf3n-de-distribuciuxf3n-de-variables-aleatorias}

\begin{Definicion}{Función de distribución de Probabilidad (acumuladada)}{}

La función de \emph{distribución de probabilidad} (acumulada) de la v.a.
\(X\) (de cualquier tipo; discreta o continua) \(F_{X}(x)\) representa
la probabilidad de que \(X\) tome un menor o igual que \(x\), es decir,

\[F_{X}(x)=P(X\leq x).\]

Esta función también se denomina función de \textbf{distribución de
probabilidad o simplemente función de distribución} de una v.a., y en
inglés \emph{cumulative distribution function} por lo que se abrevia con
el acrónimo \texttt{cdf}.

\end{Definicion}

\begin{Proposicion}{Propiedades de la Función de Distribución}{}

Sea \(X\) una v.a. y \(F_{X}\) su función de distribución:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(P(X>x)=1-P(X\leq x)=1-F_{X}(x).\)
\item
  Sea a y b tales que \(a<b\),
  \(P(a<X\leq b)=P(X\leq b)-P(X\leq a)=F_{X}(b)-F_{X}(a).\)
\end{enumerate}

\end{Proposicion}

\textbf{Demostración}:

Tenemos que el complementario de \(X\) mayor que \(x\) es:
\(\overline{\left\{X>x\right\}}=\left\{X>x\right\}^c=\left\{X\leq x\right\}\).
Además,

\[P(X>x)=1-P(\overline{\left\{X>x\right\}})=1-P(X\leq x)=1-F_{X}(x),\]

lo que demuestra la primera propiedad.

Por otro lado, si \(X\) se encuentra entre dos valores \(a\) y \(b\)
\(\left\{a< X \leq b\right\}= \left\{X\leq b\right\}-\left\{X\leq  a\right\}\).
Ahora podemos hacer

\begin{align*}
P(a<X\leq b)= & P(\left\{X\leq b\right\}-\left\{X\leq a\right\})\\
= &  P(\left\{X\leq b\right\})-P(\left\{X\leq a\right\})\\
= &  F_{X}(b)-F_{X}(a).
\end{align*}

Lo que finaliza la demistración de la propiedad.

\begin{Proposicion}{Propiedades de la Función de Distribución}{}

Sea \(F_{X}\) la función de distribución de una v.a. \(X\) entonces:

\begin{itemize}
\tightlist
\item
  \(0\leq F_{X}(x)\leq 1\).
\item
  La función \(F_{X}\) es no decreciente.
\item
  La función \(F_{X}\) es continua por la derecha.
\item
  Si denotamos por
  \(F_X(x_0^{-})=\displaystyle \lim_{x\to x_0^{-}} F(x)\), entonces se
  cumple que \(P(X< x_0)=F_X(x_0^{-})\) y que
  \(P(X=x_0)=F_X(x_0)-F_X(x_0^{-})\).
\item
  Se cumple que \(\displaystyle \lim_{x\to\infty} F_{X}(x)=1\);
  \(\displaystyle \lim_{x\to-\infty}F_{X}(x)=0\).
\item
  Toda función \(F\) verificando las propiedades anteriores es función
  de distribución de alguna v.a. \(X\).
\end{itemize}

\end{Proposicion}

\begin{Advertencia}{Advertencia: Desigualdades estrictas}{}

En las propiedades anteriores no se pueden cambiar en general las
desigualdades de estrictas o no estrictas.

Veamos que propiedades tenemos cuando se cambian estas desigualdades.

Dada una \(F_{X}\) una función de distribución de la v.a. \(X\) y
denotamos por
\(F_{X}(x_0^{-})=\displaystyle \lim_{x\to x_0^{-}} F_{X}(x),\), entonces
se cumplen las siguientes igualdades:

\begin{itemize}
\tightlist
\item
  \(P(X=x)=F_{X}(x)-F_{X}(x^{-})\).
\item
  \(P(a< X< b)=F_{X}(b^{-})-F_{X}(a)\).
\item
  \(P(a\leq X< b)=F_{X}(b^{-})-F_{X}(a^{-})\).
\item
  \(P(X<a)=F_{X}(a^{-})\),
\item
  \(P(a\leq X\leq b)=F_{X}(b)-F_{X}(a^{-})\).
\item
  \(P(X\geq a)=1-F_{X}(a^{-})\).
\end{itemize}

\end{Advertencia}

\begin{Definicion}{Más propiedades de la función de distribución}{}

\begin{itemize}
\tightlist
\item
  Si \(F_X\) es continua en \(x\) se tiene que \(P(X=x)=0\). Así que si
  la v.a. es continua \(P(X\leq a)=P(X< a)+P(X=a)=P(X<a)\) y propiedades
  similares.
\item
  Sea \(X\) una variable aleatoria discreta que con dominio \(D_X\) y
  que tiene por función de probabilidad \(P_{X}(x)\) entonces su función
  de distribución \(F_{X}(x_0)\) es
  \[F_{X}(x_0)=\sum_{x\leq x_0} P_{X}(x),\] donde
  \(\sum\limits_{x\leq x_0}\) indica que sumamos todos los \(x \in D_X\)
  tales que \(x\leq
  x_0.\)
\end{itemize}

\end{Definicion}

\textbf{Demostración}:

Si \(X\) es continua, \[P(X=a)=F(a)-F(a^{-})=F(a)-F(a)=0\] por lo tanto

\[P(X\leq a)=P(X<a)+P(X=a)= P(X<a)+0= P(X<a),\]

lo que demuestra la primera propiedad.

Para demostrar la segunda basta hacer

\begin{align*}
F_{X}(x_0)= &  P(X\leq x_0)=P\left(\bigcup_{x\leq
x_0; x\in D_X} \{x\}\right)= \sum_{x\leq x_0}P(X=x)=\\
&\sum_{x\leq x_0}P_{X}(x).
\end{align*}

Lo que demuestra estas dos propiedades.

\begin{Ejemplo}{Ejemplo: dado (continuación)}{}

En el experimento del dado se tiene que:

\[P_{X}(x)=\left\{\begin{array}{ll} \frac16, & \mbox{si } x=1,2,3,4,5,6\\ 0, & \mbox{en el resto de casos.}\end{array}\right.\]

por lo tanto

\[
F_{X}(x)=P(X\leq x)=
\left\{
    \begin{array}{ll}
   0, & \mbox{si } x<1,\\
   \frac16, &\mbox{si } 1\leq x<2,\\[1ex]
   \frac26, &\mbox{si } 2\leq x<3,\\
   \frac36, &\mbox{si } 3\leq x<4,\\
   \frac46, &\mbox{si } 4\leq x<5,\\
   \frac56, &\mbox{si } 5\leq x<6,\\
   1, &\mbox{si } 6\leq x.\end{array}
\right.
\]

Calculemos más detalladamente algún valor de \(F_{X}\), por ejemplo:

\begin{align*}
F_{X}(3.5) & =  P(X\leq 3.5)=  P(\{X=1\}\cup\{X=2\}\cup \{X=3\})\\
&= P(\{X=1\})+P(\{X=2\})+P(\{X=3\})\\
&= \frac16+\frac16+\frac16=\frac36 =\frac12,
\end{align*}

o tambiñen podemos prodeder así:

\[F_{X}(3.5)=\sum_{x\leq 3.5} P_X(x)=\sum_{x=1}^3 P(X=x)=\sum_{x=1}^3 \frac16= 3 \cdot
   \frac16=\frac12.
\]

\end{Ejemplo}

\begin{Proposicion}{Propiedades}{}

Sea \(X\) una variable con función de distribución \(F_{X}\) entonces:

\begin{itemize}
\tightlist
\item
  \(0\leq F_{X}(x)\leq 1\) para todo \(x\),
\item
  Si \(x<x'\), entonces \[F_{X}(x)\leq F_{X}(x').\] Es una función
  creciente,es decir, no necesariamente estrictamente creciente.
\item
  \(\displaystyle \lim_{x\to -\infty}F_{X}(x)=0\) y
  \(\displaystyle \lim_{x\to +\infty}F_{X}(x)=1.\)
\item
  Es continua por la derecha
  \(\displaystyle \lim_{x\to x_0^{+}}F_{X}(x)=F_{X}(x_0)\).
\end{itemize}

\end{Proposicion}

\section{Momentos de variables aleatorias
discretas}\label{momentos-de-variables-aleatorias-discretas}

Al igual que en la estadística descriptiva se utilizan distintas medidas
para resumir los valores centrales y para medir la dispersión de una
muestra, podemos definir las correspondiente medidas para variables
aleatorias.

A estas medidas se les suele añadir el adjetivo \textbf{poblacionales}
mientras que a las que provienen de la muestra se las adjetiva como
\textbf{muestrales}.

Por ejemplo podemos buscar un valor que resuma toda la variable. Este
valor es el que ``\emph{esperamos}'' que se resuma la v.a. o esperamos
que las realizaciones de la v.a. queden cerca de él. Demos su definición
formal.

\subsection{Esperanza de una variable aleatoria
discreta}\label{esperanza-de-una-variable-aleatoria-discreta}

\begin{Definicion}{Definición: Esperanza de una variable aleatoria discreta}{}

El valor \textbf{esperado o esperanza} (\emph{expected value} en inglés)
\(E(X)\) de una v.a. discreta \(X\), se define como

\[
E(X)=\sum_{x\in X(\Omega)} x\cdot P_{X}(x).
\]

En ocasiones se denomina \textbf{media} (\emph{mean} en inglés,
\emph{mitjana} en catalán) poblacional o simplemente media y muy
frecuentemente se la denota \(\mu_{X}=E(X)\) o simplemente \(\mu=E(X)\).

\end{Definicion}

\begin{Ejemplo}{Ejemplo: Intepretación de de la media}{}

\textbf{Ejemplo: lanzamiento de un dado} \(n\) veces

Supongamos que lanzamos un dado \(n\) veces y obtenemos unas frecuencias
absolutas \(n_{i}\) para el resultado \(i\) con \(i=1,\ldots,6\). Sea
\(X\) la v.a. que nos representa el valor de una tirada del dado.

Calculemos la media aritmética (o media muestral) de los datos

\[
\overline{x}=\frac{1\cdot n_1+2\cdot  n_2+3\cdot  n_3+4\cdot  n_4+5\cdot  n_5+6 \cdot 
n_6}{n}=\sum_{x=1}^6 x \cdot \frac{n_{x}}{n}.
\]

Si \(n\to \infty\) se tiene que
\(\displaystyle\lim_{n\to \infty} \frac{n_{x}}{n}=P_{X}(x).\) Por lo
tanto
\(E(X)=\displaystyle \lim_{n\to\infty}\sum_{x=1}^6x \cdot \frac{n_{x}}{n}.\)

Entonces el valor esperado en una v.a. discreta puede entenderse como el
valor promedio que tomaría una v.a. en un número grande de repeticiones.

\end{Ejemplo}

\begin{Ejemplo}{Ejemplo: Erratas en un texto}{}

Sea \(X\)= número de erratas en una página de un texto con dominio
\(D_X=\{0,1,2\}\).

Resulta que

\begin{align*}
P(X=0)&= 0.42,\ P(X=1)=0.4,\ P(X=2)=0.18, \mbox{ por lo tanto, }\\
E(X)&= 0\cdot 0.42+ 1\cdot 0.4 + 2 \cdot 0.18=0.76.
\end{align*}

Elegida una página del texto al azar esperamos encontrar \(0.76\)
errores por página.

Supongamos que el editor nos paga \(2\) euros por cada página que
encontremos con \(1\) error y \(3\) euros por cada página con dos
errores (y nada por las páginas correctas) ¿Cuánto \emph{esperamos}
cobrar si analizamos una página?

\end{Ejemplo}

\begin{Proposicion}{Propiedad: Esperanzas de funciones de variables aleatorias discretas}{}

Sea \(X\) una v.a. discreta con función de probabilidad \(P_{X}\) y de
distribución \(F_{X}\). Entonces el \emph{valor esperado de una función}
\(g(x)\) es:

\[E(g(X))=\sum_{x}g(x) \cdot  P_{X}(x).\]

\end{Proposicion}

\begin{Proposicion}{Propiedades}{}

\begin{itemize}
\tightlist
\item
  \(E(k)=k\) para cualquier constante \(k\).
\item
  Si \(a\leq X\leq b\) entonces \(a\leq E(X)\leq b\).
\item
  Si \(X\) es una v.a. discreta que toma valores enteros no negativos
  entonces \(E(X)=\sum_{x=0}^{+\infty}(1- F_X(x)).\)
\end{itemize}

\end{Proposicion}

La demostración de las propiedades anteriores se deja como ejercicio.

\begin{Ejemplo}{Ejemplo: paleta de colores aleatoria}{}

Supongamos que estamos sentados delante de nuestro ordenador con un
amigo y le decimos que en dos minutos podemos programar una paleta para
poner colores a unos gráficos.

Queremos que la paleta tenga dos botones con las opciones color rojo y
color azul. Como hemos programado a gran velocidad resulta que el
programa tiene un error; cada vez que se abre la paleta los colores se
colocan al azar (con igual probabilidad) en cada botón, así que no
sabemos en qué color hemos de pinchar.

Además, como nos sobraron \(15\) segundos para hacer el programa y
pensando en la comodidad del usuario, la paleta se cierra después de
haber seleccionado un color y hay que volverla a abrir de nuevo.

La pregunta es ¿cuál es el valor esperado del número de veces que hemos
pinchar el botón de color azul antes de obtener este color?

Llamemos \(X\) al número de veces que pinchamos en el botón azul (y nos
sale rojo) hasta obtener el primer azul. La variable \(X\) toma valores
en los enteros no negativos. Su función de probabilidad queda
determinada por

\[
P_X(x)=P(X=x)=P(\stackrel{x \mbox{ veces}}{\overbrace{rojo, rojo,\ldots,rojo},azul})
=\left(\frac12\right)^{x+1}.
\]

\end{Ejemplo}

\subsection{Series geométricas}\label{series-geomuxe9tricas}

\textbf{Series geométricas}

\begin{itemize}
\tightlist
\item
  Una \textbf{progresión geométrica} de razón \(r\) es una sucesión de
  la forma\\
  \[
  r^0, r^1,\ldots,r^n,\ldots.
  \]
\item
  La serie geométrica es la suma de todos los valores de la progresión
  geométrica \(\displaystyle\sum_{k=0}^{+\infty} r^k\).
\item
  Las sumas parciales desde el término \(n_0\) al \(n\) de una
  progresión geométrica valen \[
  \sum_{k=n_0}^n r^k=\frac{r^{n_0}- r^n r}{1-r}.
  \]
\end{itemize}

\begin{Proposicion}{Propiedades}{}

\begin{itemize}
\item
  Si \(|r|<1\) la serie geométrica es convergente y
  \[\sum_{k=0}^{+\infty }
  r^k=\frac1{1-r}\].
\item
  En el caso en que se comience en \(n_0\) se tiene que
  \[\sum_{k=n_0}^{+\infty} r^k=\frac{r^{n_0}}{1-r}.\]
\item
  Si \(|r|<1\) también son convergentes las derivadas, respecto de
  \(r\), de la serie geométrica y convergen a la derivada
  correspondiente. Así tenemos que
\end{itemize}

\begin{align*}
\left(\sum_{k=0}^{+\infty} r^k\right)'= & \sum_{k=1}^{+\infty}k
r^{k-1}; \qquad  \left(\frac1{1-r}\right)'=\frac1{(1-r)^2}\\
\left(\sum_{k=0}^{+\infty} r^k\right)^{''}=&\sum_{k=2}^{+\infty}k (k-1)
r^{k-2}  ;\qquad  \left(\frac1{1-r}\right)^{''}=\frac2{(1-r)^3}
\end{align*}.

\end{Proposicion}

\begin{Ejemplo}{Ejemplo: paleta de colores (continuación)}{}

Si seguimos con el ejemplo de la paleta de colores, su esperanza es:

\begin{align*}
E(X)= & \sum_{x=0}^{+\infty} x\cdot  P(X=x)=\sum_{x=0}^{+\infty} x\cdot
\left(\frac12\right)^{x+1}=  \left(\frac12\right)^2\sum_{x=1}^{+\infty} x\cdot
\left(\frac12\right)^{x-1}\\ & =\left(\frac12\right)^2\cdot
\frac1{\left(1-\frac12\right)^2}=1.
\end{align*}

Ahora calculemos su función de distribución

\begin{align*}
F_X(x)= &  P(X\leq x)=\sum_{k=0}^x P(X=k)=\sum_{k=0}^x
\left(\frac12\right)^{k+1}= \frac{\frac12-\frac12^{x+1}\cdot
\frac12}{1-\frac12}=\\ & 1-\left(\frac12\right)^{x+1}.
\end{align*}

Como la variable toma valores enteros positivos, podemos calcular su
valor esperado de esta otra manera

\[E(X)=\sum_{x=0}^{+\infty} (1-F_X(x))=\sum_{x=0}^{+\infty}\left(\frac12\right)^{x+1}=\frac12\cdot 
\frac1{1-\frac12}=1.\]

Calculad el valor esperado de la variable

\[
Y=\mbox{número de intentos para conseguir el color azul.}
\]

\end{Ejemplo}

\subsection{Momentos de una variable aleatoria.
Varianza}\label{momentos-de-una-variable-aleatoria.-varianza}

\begin{Proposicion}{Definición: Momentos de orden \(m\)}{}

Llamaremos \textbf{momento de orden} \(m\) respecto al punto \(C\) a
\[E\left((X-C)^m\right).\]

\begin{itemize}
\tightlist
\item
  Cuando \(C=0\) los momentos reciben el nombre de \textbf{momentos
  respecto al origen}.
\item
  Cuando \(C=E(X)\) reciben el nombre de \textbf{momentos centrales o
  respecto de la media}. Luego la esperanza es el momento de orden \(1\)
  respecto al origen. Estos momentos son la versión poblacional de los
  momentos que vimos en el curso de estadística descriptiva, recibiendo
  estos último el nombre de momentos muestrales.
\end{itemize}

\end{Proposicion}

Resumen de conceptos:

\begin{itemize}
\tightlist
\item
  Hemos descrito el comportamiento aleatorio de una v.a. discreta
  mediante sus funciones de probabilidad \(P_{X}\) y de distribución
  \(F_{X}\).
\item
  También tenemos un valor central; el valor esperado \(E(X)\).
\item
  Como medida básica nos queda definir una medida de lo lejos que están
  los datos del valor central \(E(X)\) una de estas medidas es la
  varianza de \(X\).
\end{itemize}

\subsection{Medidas de la
variabilidad}\label{medidas-de-la-variabilidad}

\begin{Definicion}{Definición: Varianza}{}

Sea \(X\) una v.a. Llamaremos \textbf{varianza} de \(X\) a

\[Var(X)=E((X-E(X))^2).\]

Por lo tanto, la varianza es el momento central de orden \(2\).

De forma frecuente se utiliza la notación \[\sigma_{X}^2=Var(X).\]

A la raíz cuadrada positiva de la varianza
\[\sigma_{X}=+\sqrt{Var(X)}.\]

se la denomina desviación típica o estándar de \(X\).

\end{Definicion}

\begin{Proposicion}{Propiedad}{}

\begin{itemize}
\tightlist
\item
  Si \(X\) es una v.a. discreta con función de probabilidad \(P_X\) su
  varianza es
  \(\sigma_{X}^2=Var(X)=E((X-E(X))^2)=\sum_{x}(x-E(X))^2\cdot  P_{X}(x).\)
\item
  Sea \(X\) una v.a.
  \(Var(X)=E(X^2)-(E(X))^2=\sum_{x} x^2\cdot  P_{X}(X)-(E(X))^2\)
\end{itemize}

\end{Proposicion}

\textbf{Demostración}

\textbf{Demostración de b)}

\begin{align*}
Var(X)= & \sum_{x}(x-E(X))^2 P_{X}(x) = \sum_{x}(x^2 -2\cdot x\cdot E(X)+(E(X)^2)\cdot P_{X}(x)\\
= &  \sum_{x}x^2\cdot P_{X}(x) -  E(X)\sum_{x}2\cdot x \cdot P_{X}(x) + (E(X)^2)\cdot\sum_{x} P_{X}(x)\\
= &  E(X^2)- 2 E(X)\cdot E(X) + (E(X))^2=E(X^2)-(E(X))^2.
\end{align*}

Se deja como ejercicio la primera afirmación.

\begin{Ejemplo}{Ejemplo: número de errores (continuación)}{}

Calculemos en el ejemplo del contero de errores la varianza de estos.

Recordemos que:

\[
P(X=0)=0.42,\quad P(X=1)=0.4, \quad P(X=2)=0.18,
\]

y que

\[
E(X)=0.76.
\]

Entonces:

\[
Var(X)=E(X^2)-(E(X))^2 = E(X^2)-(0.76)^2.
\]

Ahora necesitamos calcular

\[E(X^2)= 0^2 (0.41)+ 1^2 (0.4)+ 2^2 (0.18)=0.4+0.72=1.12\] y por lo
tanto

\[Var(X)= E(X^2)-(0.76)^2=1.12-0.5776=0.542\] y
\[\sqrt{Var(X)}=\sqrt{0.542}\]

En resumen \(\sigma_{X}^2=0.542\) y \(\sigma_{X}=\sqrt{0.542}\)

\end{Ejemplo}

\subsection{Propiedades de la
varianza}\label{propiedades-de-la-varianza}

\textbf{Propiedades de la varianza}

\begin{itemize}
\tightlist
\item
  \(Var(X)\geq 0\).
\item
  \(Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0\).
\item
  El mínimo de \(E((X-C)^2)\) se alcanza cuando \(C=E(X)\) y es
  \(Var(X)\). Esta propiedad es una de las que hace útil a la varianza
  como medida de dispersión.
\end{itemize}

\textbf{Ejercicio}

Se deja como ejercicio la demostración de estas propiedades.

\section{Transformaciones lineales de
v.a.}\label{transformaciones-lineales-de-v.a.}

\begin{Definicion}{Transformación lineal}{}

Un \textbf{cambio de variable lineal} o \textbf{transformación lineal}
de una v.a. \(X\) es otra v.a. \(Y= a+ b\cdot  X\) donde
\(a,b\in\mathbb{R}\).

\end{Definicion}

Propiedad: Esperanza de una transformación lineal

Sea \(X\) una v.a. con \(E(X)=\mu_{X}\) y \(Var(X)=\sigma_{X}^2\) y
\(a,b\in\mathbb{R}\). Entonces si \(Y=a+b\cdot  X\):

\begin{itemize}
\tightlist
\item
  \(E(Y)=E(a + b X)=a+ b E(X)= a + b \cdot \mu_{X}\).
\item
  \(Var(Y)=Var(a+bX)=b^2 Var(X)= b^2\cdot  \sigma_{X}^2\)-
\item
  \(\sigma_{Y}=\sqrt{Var(Y)}=\sqrt{b^2 Var(X)}=|b| \cdot \sigma_{X}\)-
\end{itemize}

\textbf{Demostración}:

\begin{align*}
E(Y)= &  E(a+bX)=\sum_{x}(a+b\cdot x)\cdot P_{X}(x)\\
= &  a \sum_{x} P_{X}(x) + b \sum_{x} x\cdot P_{X}(x)\\ 
= &  a + b\cdot E(X)=a + b\cdot\mu_{X}.
\end{align*}

Lo que demuestra esta propiedad, las emás se dejan comom ejercicio.

\section{Variables aleatorias
continuas}\label{variables-aleatorias-continuas}

Como ya hemos dicho las variables aleatorias continuas toman valores en
intervalos o áreas.

Lo más habitual es que estas variables tengan función de distribución
continua y derivable (salvo a los más en una cantidad finita o numerable
de puntos:-)).

En lo que sigue supondremos que la función de distribución de variables
aleatorias continuas cumplen estas propiedades.

Notemos que si \(X\) es una v.a. con función de distribución continua se
tiene que \(P(X=x_0)=F_X(x_0)-F(x_0^{-})=0\). Por lo que no tiene
sentido definir \emph{función de probabilidad}.

En general tendremos que \(P(X<x_0)=P(X\leq x_0)\).

Por otra parte podemos utilizar una regla parecida del cociente entre
casos favorables y casos posibles de Laplace pero en este caso el conteo
se hace por la \emph{medida} de los casos posibles partida por la
\emph{medida} de los casos favorables.

Veamos un ejemplo de v.a. continua, que ampliaremos en el tema
siguiente, en el que se utilizan todos estos conceptos.

\begin{Ejemplo}{Ejemplo: Distribución uniforme en \([0,1]\)}{}

\textbf{Ejemplo: distancia dardo centro de la diana}

Supongamos que lanzamos un dardo a una diana de radio \(1\), de forma
que sea \emph{equiprobable} cualquier distancia al centro (¡Cuidado!
esto no es equivalente que cualquier punto de la diana sea
\emph{equiprobable}).

Consideremos la v.a. continua \(X=\) distancia al centro de la diana.

Su función de distribución es

\[
F_{X}(x)=
\left\{
\begin{array}{ll}
0, & \mbox{si } x\leq 0,\\
x, & \mbox{si } 0<x<1,\\
1, & \mbox{si } x\geq 1.
\end{array}
\right.
\]

consideremos

\begin{itemize}
\tightlist
\item
  C.F. \emph{longitud favorable} que es \(x-0\),
\item
  C.P. \emph{longitud posible} que es \(1-0\),
\end{itemize}

luego

\[P(X\leq x)=\frac{C.F.}{C.P.}=\frac{x-0}{1-0}=x.\]

el siguente código grafica la función de distribución uniforme

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{curve}\NormalTok{(}\FunctionTok{punif}\NormalTok{(x,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{),}\AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{,}
      \AttributeTok{main=}\StringTok{"Función de distribución de una v.a. }\SpecialCharTok{\textbackslash{}n}
\StringTok{      uniforme en el intervalo unidad."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{variables_aleatorias_files/figure-pdf/figUNIF-1.pdf}
\end{center}

\end{Ejemplo}

\begin{Proposicion}{Propiedades}{}

En las variables continuas los sucesos del tipo \(\{X\leq x \}\) y
\(\{X< x \}\) tendrán la misma probabilidad. Otras identidades similares
son :

\begin{itemize}
\tightlist
\item
  \(P(X\leq b)=P(X<b)\).
\item
  \(P(X<b)=P(X<a)+P(a<X<b)\).
\item
  \(P(a<X<b)=P(X<b)-P(X<a)\).
\end{itemize}

\end{Proposicion}

\textbf{Demostración:}

Algunas identidades son evidentes \(P(X\leq b)=P(X<b)+P(X=b)=P(X<b).\)

Para otras, como la siguiente, podemos hacer

\[\{X\leq a\}\cap \{a<X<b\}=\emptyset\]
\[\{X\leq a\}\cup \{a<X<b\}=\{X<b\},\]

entonces

\textbackslash begin\{eqalign\emph{\} P(X\textless{} b) = \&
P(\{X\leq a\}\cup \{a\textless X\textless b\}) =
P(X\leq a)+P(a\textless X\textless b)= \textbackslash{} \&
P(X\textless{} a)+P(a\textless X\textless b).\$
\textbackslash end\{align}\}

La demostración de las otras propiedades las dejamos como ejercicio.

\begin{Proposicion}{Propiedades de la Función de Distribución}{}

Las propiedades anteriores y combinaciones de ellas se pueden escribir
utilizando la función de distribución de \(X\):

Dada una variable aleatoria continua se tiene que:

\begin{itemize}
\tightlist
\item
  \(F_{X}(b)=F_{X}(a)+P(a<X<b)\).
\item
  \(P(a<X<b)=F_{X}(b)-F_{X}(a)\).
\item
  \(P(a\leq X\leq b)=F_{X}(b)-F_{X}(a)\).
\end{itemize}

\end{Proposicion}

Se deja la demostración como ejercicio.

\begin{Ejemplo}{Ejemplo}{}

\textbf{Ejemplo: diana (continuación)}

En el ejemplo de la diana:

\[P(0.25<X<0.3)=F_{X}(0.3)-F_{X}(0.25)=0.3-0.25=0.05.\]

\end{Ejemplo}

\begin{Definicion}{Definición: Función de densidad}{}

Una función \(f:\mathbb{R}\to\mathbb{R}\) es una función de densidad
sobre \(\mathbb{R}\) si cumple que

\begin{itemize}
\tightlist
\item
  \(f_{X}(x)\geq 0\) para todo \(x \in\mathbb{R}.\)
\item
  \(f\) es continua salvo a lo más en una cantidad finita de puntos
  sobre cada intervalo acotado de \(\mathbb{R}\).
\item
  \(\displaystyle\int\limits_{-\infty}^{+\infty} f_{X}(x) dx=1.\)
\end{itemize}

\end{Definicion}

\begin{Teorema}{Propiedad: Relación entre la función de distribución y la densidad}{}

Sea \(X\) una v.a. con función de distribución \(F_X\). Sea
\(f:\mathbb{R}\to\mathbb{R}\) una función de densidad tal que

\[F_X(x)=\displaystyle\int_{-\infty}^{x} f_X(t) dt.\mbox{ para todo } x\in\mathbb{R},\]

Entonces \(X\) es una variable aleatoria continua y \(f_X\) es la
densidad de la v.a. \(X\).

Además el los valores de \(F_X\) son continuos y derivables en los
puntos donde \(f_X\) es continua y la derivada de la función de
distribución es una densidad \(F'_x(x)=f_X(x)\).

\end{Teorema}

\begin{Definicion}{Definición: Dominio de una variable aleatoria continua}{}

El conjunto \(D_X=\{x\in\mathbb{R}| f_x(x)>0\}\) recibe el nombre de
soporte o dominio de la variable aleatoria continua y se interpreta como
su conjunto de resultados posibles.

\end{Definicion}

\begin{Ejemplo}{Ejemplo: diana (continuación)}{}

En nuestra ejemplo de la diana, la función \(f\) es una densidad

\[
f_{X}(x)=\left\{
\begin{array}{ll}
0, & \mbox{si } x\leq 0,\\
1, & \mbox{si } 0 < x < 1,\\
0, & \mbox{si } 1\leq x.
\end{array}\right.
\]

que es la densidad de \(X\), en efecto:

\[
f_{X}(x)=\left\{
\begin{array}{ll}
0, & \mbox{si } x\leq 0,\\
1, & \mbox{si } 0 < x < 1,\\
0, & \mbox{si } 1\leq x.
\end{array}\right.
\]

\begin{itemize}
\item
  Si \(x \leq 0\) entonces
  \(\displaystyle\int_{-\infty}^x f_X(t) dt = 0.\)
\item
  Si \(0\leq x\leq 1\) entonces
  \(\displaystyle\int_{-\infty}^x f_X(t) dt = \int_0^x 1 dt = x.\)
\item
  Si \(x\geq 1\) entonces
  \(\displaystyle\int_{-\infty}^x f_X(t) dt = \int_0^1 1 dt = 1.\)
\end{itemize}

Por lo tanto, \(F_X(x)=\displaystyle\int_{-\infty}^x f_X(t) dt\) para
todo \(x\in\mathbb{R}.\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{curve}\NormalTok{(}\FunctionTok{dunif}\NormalTok{(x,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{),}\AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{,}\FloatTok{1.5}\NormalTok{),}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{,}
      \AttributeTok{main=}\StringTok{"Densidad de la distribución uniforme en [0,1]"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{variables_aleatorias_files/figure-pdf/unnamed-chunk-1-1.pdf}
\end{center}

\end{Ejemplo}

\begin{Proposicion}{Propiedades}{}

La función de densidad nos permite calcular diversas probabilidades.

Propiedades de la función de densidad

\begin{itemize}
\item
  Sea \(X\) una v.a. continua con función de distribución \(F_X\) y de
  densidad \(f_X\), entonces \begin{align*}
  P(a< X< b) = &   P(a<X\leq b)= P(a\leq X< b)=\\
   & & P(a\leq X\leq b)= \displaystyle\int_{a}^b f_X(x) dx.
  \end{align*}
\item
  Si \(A\) es un subconjunto adecuado de \(\mathbb{R}\) entonces
  \[P(X\in A)=\displaystyle\int_{A} f(x) dx=\displaystyle\int_{A\cap D_X} f(x) dx.
  \]
\end{itemize}

Propiedades de la función de densidad

Sea \(X\) una v.a. continua con función de distribución \(F_X\) y de
densidad \(f_X\), entonces:

\begin{itemize}
\tightlist
\item
  Si \(f_x\) es continua en un punto \(x\), \(F_X\) es derivable en ese
  punto y \(F_X'(x)=f_X(x).\)
\item
  \(P(X=x)=0\) para todo \(x\in\mathbb{R}.\)
\end{itemize}

\end{Proposicion}

\begin{Ejercicio}{Ejercicio}{}

Comprobar estas propiedades en el ejemplo de la diana.

\end{Ejercicio}

\begin{Ejemplo}{Ejemplo tiempo ejecución de un proceso}{}

Sea \(X=\) tiempo de ejecución de un proceso. Se supone que \(X\) sigue
una distribución uniforme en dos unidades de tiempo, si tarda más el
proceso se cancela.

Calculemos la función de densidad y de distribución de la v.a \(X\).

Entonces

\[
F_{X}(x)=P(X\leq x)=\frac{CF}{CP}=\frac{x}2.
\]

Luego su función de distribución es:

\[
F_{X}(x)=\left\{\begin{array}{ll}
0, & \mbox{si } x\leq 0,\\
\frac{x}2 & \mbox{si } 0<x<2,\\
1, & \mbox{si } 2\leq x.
\end{array}\right.
\]

Su función de densidad por su lado es: \[
f_{X}(x)=F_{X}'(x)=\left\{\begin{array}{ll}
0 & \mbox{si } x\leq 0\\
\frac12 & \mbox{si } 0<x\leq 2\\
0 & \mbox{si } 2\leq x
\end{array}\right.
\]

Efectivamente

\begin{itemize}
\tightlist
\item
  \(f_{X}(x)\geq 0,\) y tiene un conjunto finito de discontinuidades: en
  \(0\) y en \(2\)
\item
  \(F_X(x)=\displaystyle\int_{-\infty}^x f_X(t) dt,\) para todo
  \(x\in \mathbb{R}\) (Ejercicio: resolverlo gráficamente.)
\item
  \(\displaystyle\int_{-\infty}^{+\infty}f_{X}(x)dx=
  \int_0^2\frac12dx=\left[\frac{x}2\right]_0^2
  =\frac22-\frac02=1.\)
\end{itemize}

\end{Ejemplo}

\begin{Ejercicio}{Ejercicio: Tiempo de un proceso}{}

Calcular la probabilidad de que uno de nuestros procesos tarde más de
una unidad de tiempo en ser procesado. Calcular también la probabilidad
de que dure entre \(0.5\) y \(1.5\) unidades de tiempo.

\end{Ejercicio}

\section{Esperanza y varianza para variables aleatorias
continuas}\label{esperanza-y-varianza-para-variables-aleatorias-continuas}

Algunas de estas propiedades ya han sido estudiadas en el caso de
variables aleatorias discretas. Por ello, en esta sección nos
centraremos en presentar sus definiciones, métodos de cálculo y algunos
ejemplos en el contexto continuo.

A partir de ahora, salvo indicación en contrario, consideraremos que
\(X\) es una variable aleatoria continua con función de densidad
\(f_{X}(x)\)

\begin{Definicion}{Definición: Esperanza y Varianza v.a. continuas}{}

\begin{itemize}
\tightlist
\item
  Su esperanza es:
  \[E(X)=\displaystyle\int\limits_{-\infty}^{+\infty} x\cdot f_{X}(x)dx.\]
\item
  Si \(g(x)\) es una función de la variable \(X\) entonces:
  \[E(g(X))=\displaystyle\int\limits_{-\infty}^{+\infty} g(x)\cdot f_{X}(x)dx.\]
\item
  \textbf{Varianza} \[\sigma_{X}^2=E((X-\mu_{X})^2)=
    \displaystyle\int\limits_{-\infty}^{+\infty} (x-\mu_{X})^2 \cdot f_{X}(x)dx.
    \]
\item
  Su desviación típica es: \[\sigma_{X}=+\sqrt{\sigma_{X}^2}.\]
\end{itemize}

\end{Definicion}

\begin{Proposicion}{Propiedades}{}

\begin{itemize}
\tightlist
\item
  \(\sigma_{X}^2\geq 0\).
\item
  \(Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0\).
\item
  \(\displaystyle Var(x)=E(X^2)-\mu_{X}^2=\int_{-\infty}^{+\infty}x^2\cdot  f_{X}(x)dx - \mu_{X}^2.\)
\item
  El mínimo de \(E((X-C)^2)\) se alcanza cuando \(C=E(X)\) y es
  \(Var(X)\).
\end{itemize}

\end{Proposicion}

\begin{Ejemplo}{Ejemplo: Diana (continuación)}{}

\[\mu_{X}=  \int_0^1 x  dx=\left[\frac{x}{2}\right]_0^1=\frac12,\]
\[E(X^2)=\int_0^1 x^2 dx=\left[\frac{x^3}{3}\right]_0^1=\frac13,\]

\[Var(X)=E(X^2)-E(X)^2=\frac13-\left(\frac12\right)^2=\frac1{12}.\]
Podemos comprobar que con la definición directa el resultado es el mismo

\begin{align*}
Var(X)= & E\left(\left(X-E(X)\right)^2\right)=
\int_0^1 \left(x-\frac12\right)^2 dx= \\ & 
\left[\frac13 \left(x-\frac12\right)^3\right]_0^1= 
\frac13\cdot \left(\left(1-\frac12\right)^3-\left(0-\frac12\right)^3\right)
= \frac13\left(\frac18-\left(-\frac18\right)\right)=\frac13\cdot \frac28=\frac1{12}.
\end{align*}

\end{Ejemplo}

\section{Esperanza de transformaciones lineales de v.a.
continuas}\label{esperanza-de-transformaciones-lineales-de-v.a.-continuas}

\begin{Proposicion}{Propiedades}{}

Sea \(X\) una v.a. continua con \(E(X)=\mu_{X}\) y
\(Var(X)=\sigma_{X}^2\) sea \(Y=a+b X\), donde \(a,b\in\mathbb{R}\), es
una nueva v.a. continua obtenida mediante una transformación lineal de
\(X\). Se verifican las mismas propiedades que en el caso discreto:

\begin{itemize}
\tightlist
\item
  \(E(Y)=E(a+b\cdot  X)=a+b\cdot  E(X)\).
\item
  \(Var(Y)=Var(a+b\cdot  X)=b^2 \cdot  Var(X)\).
\item
  \(\sigma_{Y}=|b|\cdot  \sigma_{X}\).
\item
  \(Z=\frac{X-\mu_{X}}{\sigma_{X}}\) es una transformación lineal de
  \(X\) de forma que \[E(Z)=0 \mbox{ y } Var(Z)=1\]
\end{itemize}

\end{Proposicion}

\begin{Ejemplo}{Ejemplo}{}

En una empresa de venta de vinos por internet, sea \(X=\) número de
litros de vino del país vendidos en un año. Supongamos que sabemos que
\(E(X)=10000\) y que \(Var(X)=100.\) Supongamos que los gastos fijos de
distribución son 50.000 € y el beneficio por litro es de 10 € por
botella. Definimos \(T=10\cdot X-50000,\) que será el beneficio después
de gastos.

Entonces la esperanza del beneficio es \[E(T)=10 E(X)-50000 = 50000,\] y
\[Var(T)=10^2 Var(X)= 10000.\]

\end{Ejemplo}

\section{Transformaciones de variables
aleatorias}\label{transformaciones-de-variables-aleatorias}

Muchas variables aleatorias son funciones de otras v.a. En lo que sigue
resumiremos diversas técnicas para dada una v.a. \(X\) y una
transformación \(Y=h(X)\) encontrar \(F_{Y}\) a partir de \(F_{X}\).

\begin{Proposicion}{Propiedad: Transformaciones de v.a. discretas}{}

Sea \(X\) una v.a. discreta con
\(X(\Omega)=\{x_1,x_2,\ldots,x_{n},..\}\) y sea
\(h:\mathbb{R}\to\mathbb{R}\) una aplicación. Entonces \(Y=h(X)\) es
también una v.a. discreta. Además si \(P_X\) y \(F_{X}\) son las
funciones de probabilidad y de distribución de \(X\) entonces

\begin{itemize}
\tightlist
\item
  \(\displaystyle P_{Y}(y)=\sum_{x_{i}|h(x_{i})=y}P_X(x_{i}).\)
\item
  \(\displaystyle F_{Y}(y)=\sum_{x_{i}|h(x_{i})\leq y} P_X(x_{i}).\)
\end{itemize}

\end{Proposicion}

Desafortunadamente para variables no discretas el resultado no es tan
sencillo como el anterior, pues la transformación de, por ejemplo, una
v.a. continua puede ser continua, discreta, mixta,\(\ldots\)

\begin{Proposicion}{Propiedad: Transformación de v.a. continuas en continuas**}{}

Sea \(X\) una v.a. continua cuya función de densidad es \(f_{X}\). Sea
\(h:\mathbb{R}\to\mathbb{R}\), una aplicación estrictamente monótona y
derivable, por lo tanto \(h'(x)\not=0\) para todo \(x\in\mathbb{R}\).
Sea \(Y=h(X)\) la transformación de \(X\) por \(h\). Entonces \(Y\) es
una v.a. continua con función de densidad

\[f_{Y}(y)=\left.\frac{f_{X}(x)}
{\left|h'(x)\right|}\right|_{x=h^{-1}(y)}\]

\end{Proposicion}

\begin{Proposicion}{Densidad de una transformación de una v.a. continua}{}

Sea \(X\) una v.a. continua cuya función de densidad es \(f_{X}\). Sea
\[h:\mathbb{R}\to\mathbb{R}\] una aplicación, no necesariamente monótona
tal que :

\begin{itemize}
\tightlist
\item
  sea derivable con derivada no nula
\item
  la ecuación \(h(x)=y\) tiene un número finito de soluciones
  \(x_1,x_2,..,x_{n}\)
\end{itemize}

entonces:

\[
\displaystyle f_{Y}(y)=\left.\sum_{k=1}^{n} \frac{f_{X}(x)}
{\left|h'(x)\right|}\right|_{x=x_{k}}.
\]

\end{Proposicion}

\section{Método general de transformación de
v.a.}\label{muxe9todo-general-de-transformaciuxf3n-de-v.a.}

Cuando no podamos aplicar las propiedades anteriores intentaremos
calcular primero la función de distribución de la transformación y luego
su densidad.

Notemos que en general si \(Y=g(X)\) es una v.a. transformación de la
v.a. \(X\) entonces

\[
F_{Y}(y)=P(Y\leq y)=P(g(X)\leq y).
\]

Por ejemplo, si \(g\) es estrictamente creciente y continua,

\[
F_{Y}(y)=P(g(X)\leq y)=P(X\leq g^{-1}(y))=F_{X}(g^{-1}(y)),
\]

y si \(g\) es estrictamente decreciente y continua, \[
F_{Y}(y)=P(g(X)\leq y)=P(X\geq g^{-1}(y))=1-F_{X}(g^{-1}(y)).
\]

\section{Desigualdades de Markov y de
Chebychev}\label{desigualdades-de-markov-y-de-chebychev}

En esta sección distintas desigualdades que acotan determinadas
probabilidades de una variable aleatoria.

Estas desigualdades sirven en algunos casos para acotar probabilidades
de determinados sucesos.

También son útiles desde el punto de vista teórico, por ejemplo para
justificar que la varianza es una medida de la dispersión de los datos.

\subsection{Desigualdad de Markov}\label{desigualdad-de-markov}

\begin{Proposicion}{Propiedad: Desigualdad de Markov}{}

Sea \(X\) una v.a. positiva con \(E(X)\) finita. Entonces

\[
P(X\geq a)\leq \frac{E(X)}{a}\mbox{ para todo }a>0
\]

\end{Proposicion}

\textbf{Demostración}:

Si \(X\) es continua y solo toma valores positivos

\begin{align*}
E(X) =& \int_{-\infty}^{+\infty} x\cdot f_{X}(x) dx=  
\int_0^{+\infty} x\cdot f_{X}(x) dx\\ 
& =  \int_0^{a} x\cdot f_{X}(x) dx +\int_{a}^{+\infty} x\cdot f_{X}(x) dx
 \geq   \int_{a}^{+\infty} x\cdot f_{X}(x) dx \\
& \geq a \int_{a}^{+\infty}
f_{X}(x) dx = a \cdot  P(X\geq a),
\end{align*}

de donde se sigue que

\[P(X\geq a)\leq \frac{E(X)}{a}.\]

\subsection{Desigualdad de Markov}\label{desigualdad-de-markov-1}

\begin{Proposicion}{Propiedad: Desigualdad de Markov}{}

Sea \(X\) una v.a. con \(E(X)\) finita entonces para todo \(a>0\)

\[P(|X|\geq a )\leq \frac{E(|X|)}{a}.\]

\end{Proposicion}

Se deja como \textbf{ejercicio} la prueba del corolario anterior a
partir de la desigualdad de Markov.

\section{Desigualdad de Chebychev}\label{desigualdad-de-chebychev}

\begin{Proposicion}{Propiedad: Desigualdad de Chebychev}{}

La \textbf{desigualdad de Chebychev} también se escribe de Chebyshov y
en inglés \emph{Chebyshev}.

Sea \(X\) una v.a.con \(E(X)=\mu\) y \(Var(X)=\sigma^2\) entonces para
todo \(a>0\),

\[P(|X-\mu|\geq a)\leq \frac{\sigma^2}{a^2}.\]

\end{Proposicion}

\textbf{Demostración}

Apliquemos la consecuencia de la desigualdad de Markov a la v.a. no
negativa

\[Y^2=(X-\mu)^2\]

entonces

\[
P(Y^2\geq a^2) \leq 
\frac{E(Y^2)}{a^2}=\frac{E((X-\mu)^2)}{a^2}
= \frac{Var(X)}{a^2}=\frac{\sigma^2}{a^2}
.
\]

Por otra parte

\[
P(Y^2\geq a^2)=P(|Y|\geq a)= P(|X-\mu|\geq a),
\]

hecho que, junto con la desigualdad anterior, demuestra el resultado.

\subsection{Uso de la desigualdad de
Chebychev}\label{uso-de-la-desigualdad-de-chebychev}

\begin{Nota}{Utilidad básica de la desigualdad de Chebychev}{}

Supongamos que \(X\) es una v.a. con \(Var(X)=0\), entonces, aplicando
la desigualdad anterior

\[P(|X-E(X)|\geq a )=0\mbox{ para todo }a>0,\]

lo que implica que

\[P(X=E(X))=1,\]

Por lo que la probabilidad de que \(X\) sea constantemente \(E(X)\) es
1, hecho que nos confirma la utilidad de la varianza como una medida de
la dispersión de los datos.

\end{Nota}

\begin{Ejemplo}{Ejemplo: tiempo de respuesta}{}

Se sabe que el tiempo de respuesta medio y la desviación típica de un
sistema multiusuario son 15 y 3 unidades de tiempo respectivamente.
Entonces:

\[
P(|X-15|\geq 5)\leq \frac9{25}=0.36.
\]

\end{Ejemplo}

Si sustituimos \(a\) por \(a\cdot \sigma\) en la desigualdad de
Chebychev, nos queda:

\[
P(|X-\mu|\geq a\cdot \sigma)\leq
\frac{\sigma^2}{(a\cdot \sigma)^2}=\frac1{a^2},
\]

que es otra manera de expresar la desigualdad de Chebychev.

\section{Más formas de la desgualdad de
Chebychev}\label{muxe1s-formas-de-la-desgualdad-de-chebychev}

La desigualdad de Chebychev también se puede escribir de al menos dos
maneras más:

\[
P(\mu-a\leq X\leq \mu+a)\geq 1-\frac{\sigma^2}{a^2},
\]

y tomado como \(a=k\cdot \sigma\),

\[
P(\mu-k\cdot \sigma\leq X\leq \mu+ k \cdot \sigma)\geq 1-\frac1{k^2}.
\]

\subsection{La varianza como medida de
dispersión}\label{la-varianza-como-medida-de-dispersiuxf3n}

Tomando la segunda expresión que hemos visto para la desigualdad de
Chebychev para distintos valores de \(k>0\) obtenemos la siguiente
tabla:

\begin{table}
\centering
\begin{tabular}{|c|c|}
$k$ &  $P\left(|X-E(X)|\geq k  \cdot \sigma\right)$\\
\hline
$1$ & $\leq 1$ \\
$2$ & $\leq 0.25$ \\
$3$ & $\leq 0.111$ \\
$4$ & $\leq 0.0025$\\ \hline
\end{tabular}
\end{table}

Por ejemplo para \(k=2\), esta desigualdad se puede interpretar como
que, dada una v.a. \(X\) con cualquier distribución que tenga \(E(X)\) y
\(Var(X)\) finitos, \emph{la probabilidad de que un valor se aleje de la
media} \(\mu\) más de \(a=2\) desviaciones típicas es menor o igual que
\(0.25\).

Es decir sólo el 25\% de los valores estarán alejados de la media más de
\(2\cdot \sigma\) ¡\emph{Sea cual sea la distribución de la v.a.}!

\chapter{Teoría de la probabilidad}\label{teoruxeda-de-la-probabilidad}

En esta sección definiremos de forma rigurosa los conceptos básicos de
la teoría de la probabilidad.

Lo haremos de forma esquemática dejando las demostraciones que sean
fáciles o medias al lector, como ejercicio.

Se supone que el lector conoce la teoría básica dde conjuntos,
operaciones entrde conjuntos, aplicaciones entrde conjuntos y principios
básicos de numerabilidad.

\begin{Definicion}{Definición: Álgebra y \(\sigma\)-álgebra}{}

Sea \(\Omega\) un conjunto y
\(\mathcal{A}\subseteq \mathcal{P}(\Omega)\) una familia de subconjuntos
de \(\Omega\). Diremos que \(\mathcal{A}\) es una \textbf{álgebra} sobre
\(\Omega\) si:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\Omega\in\mathcal{A}\).
\item
  Si \(A\in\mathcal{A}\), entoncess \(A^c\in\mathcal{A}\).
\item
  Si \(A_1,\ldots,A_n\in\mathcal{A}\), entoncess
  \(\bigcup_{i=1}^{n} A_i\in\mathcal{A}\), para todo \(n\in\mathbb{N}\).
\end{enumerate}

Si, además, \(\mathcal{A}\) es cerrada respecto a \textbf{uniones
numerables}, es decir, si para toda familia
\((A_i)_{i=1}^{\infty}\subseteq\mathcal{A}\) se cumple que
\(\bigcup_{i=1}^{\infty} A_i\in\mathcal{A}\), entoncess diremos que
\(\mathcal{A}\) es una \textbf{\(\sigma\)-álgebra} sobre \(\Omega\).

El par \((\Omega,\mathcal{A})\) se llama \textbf{espacio medible} y los
elementos de \(\mathcal{A}\) se denominan \textbf{conjuntos medibles} (o
\textbf{sucesos}).

\end{Definicion}

\begin{Proposicion}{Proposición}{}

Sea \(\mathcal{A}\) una \(\sigma\)-álgebra sobre \(\Omega\). Entonces:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\emptyset\in\mathcal{A}\).
\item
  \(\mathcal{A}\) es cerrada respecto a \textbf{intersecciones finitas y
  numerables} y respecto a la \textbf{diferencia dde conjuntos}. En
  particular, si \(A,B\in\mathcal{A}\), entoncess
  \(A\cap B\in\mathcal{A}\) y \(A\setminus B\in\mathcal{A}\).
\item
  (Continuidad para uniones crecientes) Si
  \((A_i)_{i=1}^{\infty}\subseteq\mathcal{A}\) cumple
  \(A_i\subseteq A_{i+1}\) para todo \(i\), entoncess
  \(\bigcup_{i=1}^{\infty} A_i\in\mathcal{A}\).
\item
  (Continuidad para intersecciones decrecientes) Si
  \((A_i)_{i=1}^{\infty}\subseteq\mathcal{A}\) cumple
  \(A_{i+1}\subseteq A_i\) para todo \(i\), entoncess
  \(\bigcap_{i=1}^{\infty} A_i\in\mathcal{A}\).
\end{enumerate}

\end{Proposicion}

\begin{Proposicion}{Proposición}{}

Sean \(\mathcal{A}\) y \(\mathcal{B}\) dos \(\sigma\)-álgebras de
\(\Omega\) entoncess
\(\mathcal{C}={A\cap B: A\in\mathcal{A}, B\in\mathcal{B}}\) es una
\(\sigma\)-álgebra de \(\Omega\).

Si \(\mathcal{F}\in\mathcal{P}(\Omega)\) particular la intersección de
todas as \(\sigma\)-álgebras de \(\Omega\) que continene a
\(\mathcal{F}\) recibe el nombre de \(\sigma\)-álgebra generada por
\(\mathcal{F}\).

\end{Proposicion}

Algunas \(\sigma\)-álgebras notables

La \(\sigma\)-álgebra más grande de \(\Omega\) es
\(\mathcal{P}(\Omega)\) y la más pequeña o trivial es
\(\{\emptyset,\Omega\}\).

Dado \(A\subseteq \Omega\), la familia \(\{\emptyset,A,A^c,\Omega\}\) es
la \(\sigma\)-álgebra de \(\Omega\) generada por \(A\).

La \(\sigma\)-álgebra de Borel de \(\mathbb{R}\) es la
\(\sigma\)-álgebra generada por los semi-intervalos abiertos por derecha
\(\{x \in R : x<a\}=]-\infty,a]\) con \(a\in\mathbb{R}\).

La anterior \(\sigma\)-álgebra se puede generalizar a \(\mathbb{R}^n\)
como la \(\sigma\)-álgebra generada por
\(\{(x_1,\ldots,x_n) \in \mathbb{R}^n : x_i<a\}\) con \(a\in\mathbb{R}\)
y para \(i\in\{1,2,\ldots,n\}\).

\begin{Proposicion}{Proposición}{}

La intersección arbitraria de \(\sigma\)-álgebras de partes de un
conjunto \(\Omega\) es una \(\sigma\)-álgebra en \(\Omega\). Así, si
\(C\) es una familia de subconjuntos de \(\Omega\), existe la más
pequeña \(\sigma\)-álgebra de \(\Omega\) que contiene a \(C\); la
llamaremos \(\sigma\)-álgebra engendrada por \(C\)y la denotaremos
\(\sigma(C)\).''

\end{Proposicion}

Vamos a esbozar la algunas ideas para construir \(\sigma\)-álgebras

\begin{Ejercicio}{\(\sigma\)-álgebra producto Ejercicio}{}

Sean \((\Omega_1,\mathcal{A}_1)\) y \((\Omega_2,\mathcal{A}_2)\) dos
espacios medibles.

Podemos construir una \textbf{\(\sigma\)-álgebra producto} para un
espacio medible producto \(\Omega=\Omega_1\times \Omega_2\).

Tomaremos como \textbf{conjunto producto medible} los conjuntos de la
forma \(A_1 \times A_2\) con \(A_i \in \mathcal{A}_i\) para \(i=1,2\).
La \(\sigma\)- álgebra generada por estos productos dde conjuntos
medibles se llama \(\sigma\)-\textbf{álgebra producto} y la denotaresmos
por \(\mathcal{A}_1 \times \mathcal{A}_2\).

Estudiad si la \(\sigma\)-álgebra de Borel en \(\mathbb{R}^n\) es igual
al producto de \(n\) copias de la \(\sigma\)-álgebra de Borel en
\(\mathbb{R}\).

\end{Ejercicio}

\begin{Ejercicio}{\(\sigma\)-álgebra inducida}{}

Dado un espacio medible \((\Omega,\mathcal{A})\) y un subconjunto
\(B \subset \Omega\) no vacío, podemos construir una \(\sigma\)-álgebra
\(\sigma\)-álgebra en \(B\) a la que llamaremos inducida

\[
 \mathcal{A}_B = \{ A \cap B : A \in \mathcal{A} \}
 \]

Demostrar que \((B,\mathcal{A}_B)\) es un espacio medible.

\end{Ejercicio}

\begin{Definicion}{Definición: \(pi\) y \(d\) sistemas}{}

Se define \(\pi\)-\textbf{sistema} con una familia subconjuntos de
\(\Omega\) cerrada bajo intersecciones finitas.

Definimos \(d\)-\textbf{sistema} o clase de Dynkin con una familia de
subconjuntos de \(\Omega\) \(\mathcal{D}\subseteq\mathcal{P}(\Omega)\)
que cumplan las siguientes propiedades:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\Omega\in \mathcal{D}\).
\item
  Si \(\{A_n\}_{n\geq 1}\) es una sucesión creciente dde conjuntos de
  \(\mathcal{D}\), entoncess
  \(\cup_{n=1}^{\infty} A_n \in \mathcal{D}.\)
\item
  Si \(A,B\in \mathcal{D}\) y \(A\subset B\), entoncess
  \(B - A \in \mathcal{D}\).
\end{enumerate}

\end{Definicion}

\textbf{Ejercicio}

Demostrar que la intersección arbitraria de d-sistemas sigue siendo un
d-sistema, lo que facilita la demostración de que una familia de
subconjuntos forma una \(\sigma\)-álgebra.

\textbf{Problemas propuestos}

\section{Medidas y probabilidades}\label{medidas-y-probabilidades}

\subsection{\texorpdfstring{\textbf{Definición de
Medida}}{Definición de Medida}}\label{definiciuxf3n-de-medida}

Sea \((\Omega,\mathcal{A})\) un \textbf{espacio medible}, donde:

\begin{itemize}
\item
  \(\Omega\) es el \textbf{espacio de referencia}.
\item
  \(\mathcal{A}\) es una \textbf{\(\sigma\)-álgebra} de subconjuntos de
  \(\Omega\).
\end{itemize}

Una \textbf{medida} es una función:

\[
\mu : \mathcal{A} \to [0, +\infty]
\]

que cumple dos propiedades fundamentales:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Aditividad numerable (\(\sigma\)-aditividad):} Si \((A_n)\)es
  una sucesión dde conjuntos \textbf{disjuntos} en \(\mathcal{A}\),
  entoncess:
\end{enumerate}

\[
  \mu\left( \bigcup_n A_n \right) = \sum_n \mu(A_n).
  \]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Medida del conjunto vacío:} \[
    \mu(\emptyset) = 0.
    \]
\end{enumerate}

A la \(\sigma\)-álgebra y su espacio de medida
\((\Omega,\mathcal{A},\mu)\) la llamaremos \textbf{espacio de medida}.

\subsection{\texorpdfstring{\textbf{Tipos de
medidas}}{Tipos de medidas}}\label{tipos-de-medidas}

Según el comportamiento de \$\mu \$, podemos clasificar las medidas en:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Medida finita:} Si \(\mu(\Omega)<+\infty\), es decir, la
  medida total del espacio es finita.
\item
  \textbf{Medida \(\sigma\)-finita:} Si \(\Omega\) puede cubrirse con
  una colección \textbf{numerable} dde conjuntos medibles de
  \textbf{medida finita}.
\item
  \textbf{Medida de probabilidad:} Si \$\mu(\Omega) = 1 \$, se llama
  \textbf{probabilidad}, y el espacio medible
  \((\Omega, \mathcal{A}, \mu)\) se llama \textbf{espacio de
  probabilidad}.
\end{enumerate}

\subsection{\texorpdfstring{\textbf{Ejemplos}}{Ejemplos}}\label{ejemplos}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Medida de conteo:} Si \(\mu(A)\) es simplemente el número de
  elementos de\(A\) (cuando\(A\) es finito o numerable), entoncess es
  una medida finita si \(\Omega\) es finito, pero puede ser infinita si
  \(\Omega\)es infinito.
\item
  Medida de Lebesgue en \(\mathbb{R}\):
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Es la \textbf{medida estándar de la longitud} en \(\mathbb{R}\).
\item
  Es una \textbf{medida \(\sigma\)-finita} porque \(\mathbb{R}\) puede
  cubrirse con intervalos de medida finita como \([-n,n]\).
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Medida de probabilidad uniforme en \([0,1]\):
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Es una \textbf{medida de probabilidad} porque \(\mu([0,1]) = 1\).
\item
  La probabilidad de un subconjunto \(A\) es simplemente la longitud de
  \(A\) en \([0,1]\).
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{Medida de Dirac:}
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Es una \textbf{medida de probabilidad}.
\item
  La probabilidad de un conjunto \(A\) es 1 si \(0\in A\) y 0 en caso
  contrario.
\end{itemize}

\section{\texorpdfstring{\textbf{Proposición 3.1: Propiedades
fundamentales de la
medida}}{Proposición 3.1: Propiedades fundamentales de la medida}}\label{proposiciuxf3n-3.1-propiedades-fundamentales-de-la-medida}

Sea \(\mu\) una medida definida en un espacio medible
\((\Omega,\mathcal{A})\), se cumplen las siguientes propiedades:

\subsection{\texorpdfstring{\textbf{(a)
Monotonía}}{(a) Monotonía}}\label{a-monotonuxeda}

Si \(A \subseteq B\), entoncess: \[
\mu(A) \leq \mu(B).
\] Si además \(\mu(A) < +\infty\), entoncess: \[
\mu(B - A) = \mu(B) - \mu(A).
\]

\textbf{Demostración}: Como \(B\) puede descomponerse como
\(B = A \cup (B - A)\) con \(A \cap (B - A) = \emptyset\), la propiedad
de \textbf{aditividad de la medida} nos dice que: \[
\mu(B) = \mu(A) + \mu(B - A) \geq \mu(A).
\] Si \(\mu(A) < +\infty\), despejando obtenemos
\(\mu(B - A) = \mu(B) - \mu(A)\).

\subsection{\texorpdfstring{\textbf{(b) Continuidad hacia
arriba}}{(b) Continuidad hacia arriba}}\label{b-continuidad-hacia-arriba}

Si \((A_n)\) es una sucesión creciente dde conjuntos, es decir, \[
A_1 \subseteq A_2 \subseteq A_3 \subseteq \dots,
\] entoncess: \[
\mu\left(\bigcup_n A_n\right) = \lim_{n \to \infty} \mu(A_n).
\]

\textbf{Demostración}: Sea \(A = \bigcup_n A_n\). Si
\(\mu(A_n) = +\infty\) para algún \(n\), entoncess \(\mu(A_k) = \infty\)
para todo \(k \geq n\) y el resultado es trivial. Si todos los \(A_n\)
tienen \textbf{medida finita}, reescribimos la unión como:

\[
A = A_1 \cup (A_2 - A_1) \cup (A_3 - A_2) \cup \dots
\]

Dado que los términos son \textbf{disjuntos}, la aditividad numerable
implica: \[
\mu(A) = \mu(A_1) + (\mu(A_2) - \mu(A_1)) + (\mu(A_3) - \mu(A_2)) + \dots
\] y esto converge a \(\lim_{n} \mu(A_n)\).

\subsection{\texorpdfstring{\textbf{(c) Continuidad hacia
abajo}}{(c) Continuidad hacia abajo}}\label{c-continuidad-hacia-abajo}

Si \((A_n)\) es una sucesión decreciente dde conjuntos, es decir: \[
A_1 \supseteq A_2 \supseteq A_3 \supseteq \dots,
\] y al menos uno de los \(A_n\) tiene medida finita, entoncess: \[
\mu\left(\bigcap_n A_n\right) = \lim_{n \to \infty} \mu(A_n).
\]

\textbf{Demostración}: Podemos suponer sin pérdida de generalidad que
\(A_1\) tiene medida finita. Definimos \(A = \bigcap_n A_n\) y
consideramos la sucesión creciente \(B_n = A_1 - A_n\), la cual
satisface:

\[
\bigcup_n B_n = A_1 - A.
\]

Aplicando la \textbf{continuidad hacia arriba} al conjunto \(B_n\), se
obtiene: \[
\mu(A_1 - A) = \lim_n \mu(A_1 - A_n).
\]

Restando de \(\mu(A_1)\), se obtiene la ecuación deseada: \[
\mu(A) = \lim_n \mu(A_n).
\]

\subsection{\texorpdfstring{\textbf{(d) Subaditividad numerable
(σ-subaditividad)}}{(d) Subaditividad numerable (σ-subaditividad)}}\label{d-subaditividad-numerable-ux3c3-subaditividad}

Si \((A_n)\) es una sucesión arbitraria dde conjuntos, entoncess: \[
\mu\left(\bigcup_n A_n\right) \leq \sum_n \mu(A_n).
\]

\textbf{Demostración}: Sea \(A := \bigcup_{n=1}^{\infty} A_n\).
Descomponemos \(A\) en términos de las uniones de diferencias: \[
A = \bigcup_{n=1}^{\infty} \left( A_n - \bigcup_{i=1}^{n-1} A_i \right).
\]

Por \textbf{aditividad numerable} y el hecho de que la medida es no
negativa: \[
\mu(A) = \sum_n \mu(A_n - \bigcup_{i=1}^{n-1} A_i) \leq \sum_n \mu(A_n).
\]

\section{\texorpdfstring{\textbf{Conclusión}}{Conclusión}}\label{conclusiuxf3n}

Estas propiedades son fundamentales en la teoría de la medida y se
aplican en muchas áreas como \textbf{análisis real, probabilidad y
teoría de integración}. En particular:

\begin{itemize}
\tightlist
\item
  La \textbf{monotonía} muestra que medidas más grandes contienen
  subconjuntos de medida más pequeña.
\item
  La \textbf{continuidad hacia arriba y hacia abajo} garantiza que la
  medida respeta límites de secuencias dde conjuntos.
\item
  La \textbf{σ-subaditividad} es una propiedad crucial para la
  construcción de medidas y prueba de teoremas como el \textbf{teorema
  de Carathéodory}.
\end{itemize}

\chapter{Distribuciones notables 1}\label{distribuciones-notables-1}

\section{Introducción}\label{introducciuxf3n-1}

En este tema estudiaremos diversos tipos de experimentos que son muy
frecuentes y algunas de las variables aleatorias asociadas a ellos.

Estas variables reciben distintos nombres que aplicaremos sin distinción
al tipo de población del experimento a la variable o a su función de
probabilidad, densidad o distribución.

Empezaremos con las variables aleatorias discretas que se presentan con
frecuencia ya que están relacionadas con situaciones muy comunes como el
número de caras en varios lanzamiento de una moneda, el número de veces
que una maquina funciona hasta que se estropea, el numero de clientes en
una cola,\ldots{}

\section{Distribución Bernoulli}\label{distribuciuxf3n-bernoulli}

\begin{Definicion}{Distribución Bernoulli}{}

Consideremos un experimento con dos resultados posibles éxito (E) y
fracaso (F). El espacio de sucesos será \(\Omega=\{E,F\}\).

Supongamos que la probabilidad de éxito es \(P(E)=p\), y naturalmente
\(P(F)=1-p=q\) con \(0<p<1\).

Consideremos la aplicación

\[
X:\Omega=\{E,F\}\to \mathbb{R}
\]

definida por

\[
X(E)=1\mbox{, }X(F)=0.
\]

Su función de probabilidad es

\[
P_{X}(x)=
\left\{
\begin{array}{ll} 1-p=q & \mbox{si } x=0\\
p & \mbox{si } x=1\\
0 & \mbox{en cualquier otro caso}
\end{array}
\right..
\]

Su función de distribución es

\[
F_{X}(x)=P(X\leq x)=
\left\{
\begin{array}{ll} 
0 & \mbox{si } x<0\\
1-p=q & \mbox{si } 0\leq x <1\\
1 & \mbox{si } 1\leq x \\
\end{array}
\right..
\]

Bajo estas condiciones diremos que \(X\) \textbf{es una v.a. Bernoulli}
o que sigue una ley de \textbf{distribución de probabilidad Bernoulli}
de parámetro \(p\). * Lo denotaremos por
\[X\sim Ber(p)\mbox{ o también } X\sim B(1,p).\]

\end{Definicion}

Este tipo de experimentos (éxito/fracaso)se reciben el nombre de
experimentos Bernoulli.

Fue su descubridor un científico suizo
\href{https://es.wikipedia.org/wiki/Jakob_Bernoulli}{Jacob Bernoulli},
uno más de la conocida
\href{https://es.wikipedia.org/wiki/Familia_Bernoulli}{familia de
científicos suizos Bernoulli}.

Su \textbf{valor esperado} es

\[E(X)=\displaystyle\sum_{x=0}^1 x\cdot P(X=x)= 0\cdot(1-p)+1\cdot p=p.\]

Calculemos también \(E(X^2)\)

\[E(X^2)=\displaystyle\sum_{x=0}^1 x^2\cdot P(X=x)= 0^2\cdot(1-p)+1^2\cdot p=p.\]

La \textbf{varianza} de una va.a Bernouilli es

\[Var(X)=E(X^2)-\left(E(X)\right)^2=p-p^2=p\cdot (1-p)=p\cdot q.\]

Su desviación típica es

\[
\sqrt{Var(X)}=\sqrt{p \cdot (1-p)}.
\]

Pongamos en una tabla el resumen de v.a. con distribución Bernoulli

\begin{table}
\centering
\begin{tabular}{|l|}
\hline\rowcolor{LightBlue}
$X$ Bernoulli: $Ber(p)$ 
\\\hline
$D_X= \{0,1\}$ 
\\\hline
$P_X(x)=P(X=x)=
\left\{
\begin{array}{ll}
1-p=q & \mbox{ si } x=0\\
p & \mbox{ si } x=1 \\
0 & \mbox{ en otro caso.}
\end{array}\right.
$ 
\\\hline
$F_X(x)=P(X\leq X)=
\left\{
\begin{array}{ll}
 0 & \mbox{ si } x<0\\ 
 (1-p) & \mbox{ si } 0\leq x< 1 \\ 
1 & \mbox{ si } x\geq 1
\end{array}
\right.$.
\\\hline
$E(X)=p$; $\scriptstyle Var(X)= p \cdot (1-p)$ \\\hline
\end{tabular}
\end{table}

\begin{Ejemplo}{Ejemplo : Cálculos con R}{}

Veamos los cálculos básicos \(Ber(p=0.25)\) en \texttt{R}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\DecValTok{0}\NormalTok{,}\AttributeTok{size=}\DecValTok{1}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.75
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\DecValTok{1}\NormalTok{,}\AttributeTok{size=}\DecValTok{1}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rbinom}\NormalTok{(}\AttributeTok{n=}\DecValTok{20}\NormalTok{,}\AttributeTok{size =} \DecValTok{1}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
 [1] 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0
=======
 [1] 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 1 0
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

El siguiente código dibuja las función de probabilidad y la de
distribución de una \(Ber(p=0.25)\)

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/ber_plot_1-1.pdf}
\end{center}

\end{Ejemplo}

\section{Distribución binomial}\label{distribuciuxf3n-binomial}

\begin{Definicion}{Distribución binomial}{}

Si repetimos \(n\) veces de forma independiente un experimento Bernoulli
de parámetro \(p\).

El espacio muestral \(\Omega\) estará formado por cadenas de \(E\)'s y
\(F\)'s de longitud \(n\) Consideremos la v.a.

\[X(\overbrace{EFFF\ldots EEF}^{n})=\mbox{número de éxitos en la cadena}.\]
A la variable aleatoria anterior se le conoce como distribución binomial
de parámetros \(n\) y \(p\), y lo denotaremos por \(X\sim B(n,p).\)

Obviamente se tiene que una v.a. Bernoulli es una binomial con \(n=1\)

\[B(1,p)=Ber(p).\]

\end{Definicion}

La \textbf{función de probabilidad} de una binomial es

\[
P_{X}(x)=\left\{
\begin{array}{ll}
{n\choose x}\cdot p^x \cdot(1-p)^{n-x} &\mbox{ si } x=0,1,\ldots,n\\
0 & \mbox{ en otro caso}
\end{array}\right..
\]

Su \textbf{función de distribución} no tiene una fórmula cerrada. Hay
que acumular la función de probabilidad:

\begin{align*}
F_{X}(x)=P(X\leq x)&=\sum_{i=0}^x P_X(i)\\ 
& =
\left\{
\begin{array}{ll}
0 & \mbox{ si } x<0\\\displaystyle
\sum_{i=0}^k {n\choose i}\cdot p^i \cdot (1-p)^{n-i} & \mbox{ si } 
\left\{
 \begin{array}{l} 
 k\leq x< k+1\\
 k=0,1,\ldots,n.
 \end{array}
\right.\\
1 & \mbox{ si } n\leq x
\end{array}
\right.
\end{align*}

Recordemos los números binomiales con un ejemplo

\begin{Ejemplo}{Números binomiales}{}

Los números binomiales calculan el número de equipos de baloncesto
distintos que (\(k=5\) jugadores) se pueden hacer con 6 jugadores
(\(n=6\)).

Es decir cuántas maneras distintas hay para elegir (\emph{choose}) 5
jugadores en un conjunto de 6 jugadores. Todo el mundo diría ¡¡¡6!!!.
Efectivamente con R es

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 6
\end{verbatim}

Con 10 jugadores el número de equipos de 5 distintos es bastante más
grande

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 252
\end{verbatim}

Y, por ejemplo, con un equipo de fútbol profesional que tiene en
plantilla 22 jugadores (quitando los guardametas) se pueden formar
¡¡nada menos que!!

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\DecValTok{22}\NormalTok{,}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 646646
\end{verbatim}

un bonito número capicúa que nos da el número de equipos distintos que
se pueden formar.

\end{Ejemplo}

\begin{Ejercicio}{Ejercicio}{}

Calculad las funciones de distribución de una binomial \(B(n=1,p=0.3)\)
y comprobar que coinciden con las distribuciones de una \(Ber(p=0.3)\).

\end{Ejercicio}

\begin{Nota}{Observaciones sobre la distribución binomial}{}

\begin{itemize}
\tightlist
\item
  La probabilidad de fracaso se suele denotar con \(q=1-p\), \textbf{sin
  ningún aviso adicional}, con el fin de acortar y agilizar la escritura
  de las fórmulas.
\item
  Su \textbf{función de distribución no tienen una formula general}, hay
  que calcularla con una función de R o Python\ldots{} En el siglo
  pasado se tabulaban en los libros de papel :-).
\item
  En el material adicional os pondremos unas tablas de esta distribución
  para distintos valores de \(n\) y \(p\) para que disfrutéis de tan
  ancestral método de cálculo.
\item
  Cualquier paquete estadístico, hoja de cálculo dispone de funciones
  para el cálculo de estas probabilidades, así que el \textbf{uso de las
  tablas} queda \textbf{totalmente anticuado}.
\end{itemize}

\end{Nota}

La \textbf{esperanza} de una v.a. \(X\) con distribución \(B(n,p)\) es

\[E(X)=\displaystyle\sum_{k=0}^n k \cdot {n \choose k }\cdot p^k\cdot q^{n-k} = n\cdot p.\]

La esperanza de \(X^2\) es

\begin{eqnarray*}
E(X^2)&=& \displaystyle\sum_{k=0}^n k^2 \cdot {n \choose k }\cdot p^k\cdot q^{n-k}\\
&=& n\cdot p\cdot q+(n\cdot p)^2.
\end{eqnarray*}

Por lo tanto su \textbf{varianza} se calcula así

\[Var(X)=E(X^2)-\left(E(X)\right)^2=n\cdot p \cdot q=n\cdot p\cdot (1-p).\]

Su desviación típica es

\[\sqrt{n\cdot p\cdot q}=\sqrt{n\cdot p\cdot (1-p)}.\]

En temas posteriores veremos una forma sencilla del cálculo de la
esperanza y varianza de una \(B(n,p)\) como las suma de \(n\) v.a.
\(Ber(p)\) independientes.

\begin{Ejercicio}{Ejercicio}{}

Justificar de forma intuitiva que si \(X_i\) con \(i=1,2,\ldots, n\) son
v.a. \(Ber(p)\) independientes entonces
\(X=\displaystyle\sum_{i=1}^n X_i\) sigue una distribución \(B(n,p).\)

\end{Ejercicio}

\subsection{\texorpdfstring{Resumen: v.a. con distribución binomial
\(B(n,p)\)}{Resumen: v.a. con distribución binomial B(n,p)}}\label{resumen-v.a.-con-distribuciuxf3n-binomial-bnp}

\begin{table}
\centering
\begin{tabular}{|l|}
\hline\rowcolor{LightBlue}
$X$ binomial: $B(n,p)$ \\\hline
$D_X= \{0,1,\ldots n\}$ \\\hline
$P_X(x)=P(X=x)=\left\{\begin{array}{ll}\scriptstyle {n\choose x}\cdot p^x\cdot (1-p)^{n-x} & \mbox{ si } x=0,1,\ldots,n\\0 & \mbox{ en otro caso.}\end{array}\right.$ \\\hline
$F_X(x)=P(X\leq X)=
\scriptstyle\left\{
\begin{array}{ll}
 0 & \mbox{ si } x<0\\ 
\sum_{i=0}^k {n\choose i}\cdot p^i\cdot (1-p)^{n-i} & \mbox{si } k\leq x< k+1;\quad k=0,1,\dots,n \\ 
1 & \mbox{ si } x\geq n
\end{array}
\right.$.\\\hline
$E(X)=n\cdot p$; $ Var(X)=n\cdot p \cdot (1-p)$ \\\hline
\end{tabular}
\end{table}

\subsubsection{Cálculos distribución binomial con
R}\label{cuxe1lculos-distribuciuxf3n-binomial-con-r}

Veamos los cálculos básicos con funciones de R para una v.a. \(X\) con
distribución binomial \(B(n=10,p=0.25)\).

Si queremos calcular con \texttt{R} algún valor de la función de
distribución como por ejemplo \(F_X(0)=P(X\leq 0)\), tenemos que hacer:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pbinom}\NormalTok{(}\DecValTok{0}\NormalTok{,}\AttributeTok{size=}\DecValTok{10}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.05631351
\end{verbatim}

y si queremos por ejemplo \(F_X(4)=P(X\leq 4)\), tenemos que hacer:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pbinom}\NormalTok{(}\DecValTok{4}\NormalTok{,}\AttributeTok{size=}\DecValTok{10}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9218731
\end{verbatim}

Sin embargo, si queremos calcular algún valor de la función de
probabilidad como por ejemplo \(P(X=0)\), tenemos que hacer:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\DecValTok{0}\NormalTok{,}\AttributeTok{size=}\DecValTok{10}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.05631351
\end{verbatim}

o por ejemplo para \(P(X=4)\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\DecValTok{4}\NormalTok{,}\AttributeTok{size=}\DecValTok{10}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.145998
\end{verbatim}

\subsubsection{Generación de muestras aleatorias con
R}\label{generaciuxf3n-de-muestras-aleatorias-con-r}

Generaremos una muestra aleatoria de 100 valores de una población con
distribución \(B(20,0.5)\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2019}\NormalTok{)}
\FunctionTok{rbinom}\NormalTok{(}\DecValTok{100}\NormalTok{,}\AttributeTok{size =} \DecValTok{20}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  [1] 12 11  9 11  6  6 12  5  7 11 12 11  8  8 11 11  7 11  9 10  9 10 14
 [24]  8  8  5 11 14 11 10 11  5 12  8  6  7  9 10  5 12 11  9 12 11 12 10
 [47] 13 13  8  8  9  7  6  9 10  9 16 13  6  6  8  8 11  9 12 15  9  7 12
 [70] 11  9  8  9  8 11 15  7 10  9 12  6 13 14  8 10  8 10 11 11  9 10 11
 [93] 12  8 10 12  9 13  9 13
\end{verbatim}

Que corresponde a los resultados de repetir 100 veces el experimento de
lanzar una moneda 20 veces y contar el número de caras.

\subsubsection{Cálculos distribución binomial con
Python}\label{cuxe1lculos-distribuciuxf3n-binomial-con-python}

Veamos los cálculos básicos con funciones de Python para una v.a. \(X\)
con distribución binomial \(B(n=10,p=0.25)\).

Primero importamos la función \texttt{binom} de la librería
\texttt{scipy.stat}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ binom}
\end{Highlighting}
\end{Shaded}

En general en el paquete \texttt{scipy}, la función de probabilidad se
invocará con el método \texttt{pmf}, la de distribución con el método
\texttt{cdf} mientras que una muestra aleatoria que siga esta
distribución con el método \texttt{rvs}. En todos ellos aparecerá
siempre el parámetro \texttt{loc} que se utiliza para desplazar el
dominio de la variable aleatoria. Por ejemplo, en este caso

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{binom.pmf(k, n, p, loc) }\OperatorTok{=}\NormalTok{  binom.pmf(k }\OperatorTok{{-}}\NormalTok{ loc, n, p)}
\end{Highlighting}
\end{Shaded}

Para calcular los valores de la función de distribución como por ejemplo
\(F_X(0)=P(X\leq 0)\) y \(F_X(4)=P(X\leq 4)\) utilizamos la función
\texttt{cdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{binom.cdf(}\DecValTok{0}\NormalTok{,n}\OperatorTok{=}\DecValTok{10}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.056313514709472684
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{binom.cdf(}\DecValTok{4}\NormalTok{,n}\OperatorTok{=}\DecValTok{10}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.9218730926513672
\end{verbatim}

Notemos que al no indicar el valor de \texttt{loc}, se le asume que toma
el valor 0.

Para calcular los valores de la función de probabilidad \(P(X=0)\) y
\(P(X=4)\) utilizamos la función \texttt{pmf}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{binom.pmf(}\DecValTok{0}\NormalTok{,n}\OperatorTok{=}\DecValTok{10}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.056313514709472656
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{binom.pmf(}\DecValTok{4}\NormalTok{,n}\OperatorTok{=}\DecValTok{10}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.14599800109863284
\end{verbatim}

Notemos que al no indicar el valor de \texttt{loc}, se le asume que toma
el valor 0.

Si queremos generar una muestras aleatorias que siga una distribución
binomial, podemos usar la función \texttt{rvs}. En este caso,
generaremos una muestra aleatoria de 100 valores de una población
\(B(20,0.5)\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{binom.rvs(n}\OperatorTok{=}\DecValTok{20}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{,size }\OperatorTok{=} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
array([4, 4, 4, 5, 5, 6, 8, 5, 6, 5, 7, 5, 2, 3, 9, 4, 4, 9, 2, 4, 6, 7,
       4, 5, 4, 8, 7, 5, 6, 6, 6, 0, 6, 4, 5, 6, 7, 5, 2, 7, 4, 5, 5, 5,
       3, 2, 3, 5, 3, 8, 6, 3, 8, 7, 8, 5, 6, 2, 4, 7, 3, 4, 6, 7, 4, 5,
       3, 5, 7, 6, 3, 4, 5, 5, 4, 6, 5, 3, 7, 3, 4, 6, 4, 5, 4, 3, 6, 3,
       5, 2, 4, 8, 3, 6, 5, 9, 5, 8, 4, 8], dtype=int64)
=======
array([5, 5, 5, 9, 5, 6, 6, 7, 7, 6, 4, 7, 5, 4, 4, 4, 6, 2, 7, 3, 3, 6,
       4, 4, 2, 8, 6, 5, 6, 7, 6, 7, 4, 5, 5, 5, 3, 4, 7, 6, 6, 4, 7, 5,
       6, 5, 4, 6, 6, 6, 6, 5, 6, 3, 6, 5, 5, 4, 6, 7, 9, 4, 4, 3, 5, 4,
       8, 4, 4, 5, 2, 3, 5, 6, 4, 6, 5, 6, 6, 4, 3, 5, 5, 5, 4, 6, 6, 7,
       5, 6, 2, 6, 5, 6, 3, 5, 7, 6, 3, 3], dtype=int64)
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

\begin{Advertencia}{Observación}{}

Notemos que la secuencia aleatoria generada no es la misma que con
\texttt{R}. De hecho, si volvemos a ejecutar esta función obtendremos
una muestra aleatoria distinta.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{binom.rvs(n}\OperatorTok{=}\DecValTok{20}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{,size }\OperatorTok{=} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
array([ 4,  7,  6,  4,  9,  6,  3,  3,  8,  7,  6,  4,  3,  7,  2, 13,  5,
        5,  5,  7,  8,  2,  3,  4,  2,  1,  6,  8,  4,  4,  7,  7,  7,  4,
        5,  7,  4,  7,  6,  3,  3,  5, 10,  5,  7,  1,  7,  4,  3,  5,  4,
        8,  5,  2,  3,  8,  3,  7,  7,  7,  6,  4,  4,  8,  3,  6,  5,  6,
        7,  5,  5,  6,  5,  8,  3,  5,  6,  6,  2,  3,  6,  7,  6,  4,  2,
        7,  8,  5,  6,  3,  3,  3,  7,  3,  3,  7,  5,  7,  3,  2],
=======
array([ 1,  3,  4,  5,  5,  3,  5,  8,  5,  6,  3,  8,  2,  9,  9,  2,  7,
        3,  7,  4,  5,  5,  3,  6,  1,  3,  3,  5,  6,  6,  2,  2,  4,  6,
        6,  3,  6,  6, 10,  5,  7, 10,  4,  4,  6,  7,  4,  7,  3,  7,  7,
        6,  2,  5,  1,  9,  4,  6,  4,  6,  5,  4,  5,  7,  5,  7,  4,  4,
        5,  2,  7,  5,  3,  5,  4,  9,  7,  5,  5,  6,  3,  5,  9,  5,  6,
        9,  5,  7,  8,  9,  4,  6,  3,  6,  3,  7,  5,  9,  5,  3],
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
      dtype=int64)
\end{verbatim}

\end{Advertencia}

Veamos algunos cálculos básicos con funciones de Python para la binomial
\(B(n=10,p=0.25)\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{binom.cdf(}\DecValTok{5}\NormalTok{,n}\OperatorTok{=}\DecValTok{10}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.9802722930908203
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{binom.pmf(}\DecValTok{1}\NormalTok{,n}\OperatorTok{=}\DecValTok{10}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.1877117156982421
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{binom.rvs(n}\OperatorTok{=}\DecValTok{20}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{,size}\OperatorTok{=}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
array([3, 3, 3, 4, 3, 4, 5, 7, 5, 3], dtype=int64)
=======
array([ 4, 10,  6,  5,  4,  5,  4,  5,  9,  6], dtype=int64)
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

\subsubsection{Gráficas de la distribución binomial con
R}\label{gruxe1ficas-de-la-distribuciuxf3n-binomial-con-r}

El siguiente código de R dibuja las función de probabilidad y la de
distribución de una \(B(n=10,p=0.25)\)

\begin{center}
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/unnamed-chunk-7-1.pdf}
\end{center}

Ahora con \texttt{ggplot2}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning: package 'ggplot2' was built under R version 4.4.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dplyr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning: package 'dplyr' was built under R version 4.4.3
\end{verbatim}

\begin{verbatim}

Adjuntando el paquete: 'dplyr'
\end{verbatim}

\begin{verbatim}
The following objects are masked from 'package:stats':

    filter, lag
\end{verbatim}

\begin{verbatim}
The following objects are masked from 'package:base':

    intersect, setdiff, setequal, union
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyr)}
\FunctionTok{library}\NormalTok{(stats)}

\CommentTok{\# Parámetros de la distribución hipergeométrica}
\NormalTok{M }\OtherTok{\textless{}{-}} \DecValTok{100}  \CommentTok{\# Tamaño total de la población}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{floor}\NormalTok{(}\FloatTok{0.6} \SpecialCharTok{*}\NormalTok{ M)  }\CommentTok{\# Número de elementos de éxito en la población}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{10}  \CommentTok{\# Tamaño de la muestra extraída}

\CommentTok{\# Valores de la variable aleatoria}
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{0}\SpecialCharTok{:}\NormalTok{N}

\CommentTok{\# Función de masa de probabilidad (PMF)}
\NormalTok{pdf }\OtherTok{\textless{}{-}} \FunctionTok{dhyper}\NormalTok{(x, n, M }\SpecialCharTok{{-}}\NormalTok{ n, N)}

\CommentTok{\# Función de distribución acumulativa (CDF)}
\NormalTok{cdf }\OtherTok{\textless{}{-}} \FunctionTok{phyper}\NormalTok{(x, n, M }\SpecialCharTok{{-}}\NormalTok{ n, N)}

\CommentTok{\# Crear un dataframe para ggplot}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =} \FunctionTok{rep}\NormalTok{(x, }\DecValTok{2}\NormalTok{),}
                   \AttributeTok{prob =} \FunctionTok{c}\NormalTok{(pdf, cdf),}
                   \AttributeTok{type =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"PMF"}\NormalTok{, }\StringTok{"CDF"}\NormalTok{), }\AttributeTok{each =} \FunctionTok{length}\NormalTok{(x)))}

\CommentTok{\# Crear los gráficos con ggplot2}
\FunctionTok{ggplot}\NormalTok{(data, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ prob, }\AttributeTok{fill =}\NormalTok{ type, }\AttributeTok{color =}\NormalTok{ type)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{data =} \FunctionTok{subset}\NormalTok{(data, type }\SpecialCharTok{==} \StringTok{"PMF"}\NormalTok{), }\AttributeTok{alpha =} \FloatTok{0.6}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_step}\NormalTok{(}\AttributeTok{data =} \FunctionTok{subset}\NormalTok{(data, type }\SpecialCharTok{==} \StringTok{"CDF"}\NormalTok{), }\AttributeTok{direction =} \StringTok{"mid"}\NormalTok{, }\AttributeTok{size =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{type, }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free\_y"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Distribución Hipergeométrica"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Número de éxitos en la muestra"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Probabilidad"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"blue"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"blue"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
i Please use `linewidth` instead.
\end{verbatim}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/unnamed-chunk-8-1.pdf}
\end{center}

\subsubsection{Gráficos de la distribución binomial con
Python}\label{gruxe1ficos-de-la-distribuciuxf3n-binomial-con-python}

Necesitaremos usar estas librerías:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ scipy.stats }\ImportTok{as}\NormalTok{ stats}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Parámetros de la distribución binomial}
\NormalTok{n }\OperatorTok{=} \DecValTok{10}
\NormalTok{p }\OperatorTok{=} \FloatTok{0.7}

\CommentTok{\# Valores posibles de X}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{0}\NormalTok{, n}\OperatorTok{+}\DecValTok{1}\NormalTok{)}

\CommentTok{\# Función de probabilidad (PMF)}
\NormalTok{pmf\_values }\OperatorTok{=}\NormalTok{ stats.binom.pmf(x, n, p)}

\CommentTok{\# Función de distribución acumulada (CDF)}
\NormalTok{cdf\_values }\OperatorTok{=}\NormalTok{ stats.binom.cdf(x, n, p)}

\CommentTok{\# Graficar la función de probabilidad (PMF)}
\NormalTok{plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{12}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\NormalTok{plt.subplot(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{plt.bar(x, pmf\_values, color}\OperatorTok{=}\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.7}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}P(X=k)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Valores de X\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Probabilidad\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Función de Probabilidad (PMF) {-} Binomial(10, 0.7)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xticks(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
([<matplotlib.axis.XTick object at 0x000001B1B6FA9520>, <matplotlib.axis.XTick object at 0x000001B1B6FA9D90>, <matplotlib.axis.XTick object at 0x000001B1B6F99CA0>, <matplotlib.axis.XTick object at 0x000001B1C06E2CD0>, <matplotlib.axis.XTick object at 0x000001B1C0036F10>, <matplotlib.axis.XTick object at 0x000001B1C06EFD90>, <matplotlib.axis.XTick object at 0x000001B1C06EF1C0>, <matplotlib.axis.XTick object at 0x000001B1C06EF370>, <matplotlib.axis.XTick object at 0x000001B1C0036F40>, <matplotlib.axis.XTick object at 0x000001B1C06E24F0>, <matplotlib.axis.XTick object at 0x000001B1C06E7F70>], [Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, '')])
=======
([<matplotlib.axis.XTick object at 0x00000269D97DA520>, <matplotlib.axis.XTick object at 0x00000269D97DAD90>, <matplotlib.axis.XTick object at 0x00000269D97C9CA0>, <matplotlib.axis.XTick object at 0x00000269D9F12CD0>, <matplotlib.axis.XTick object at 0x00000269D9867F10>, <matplotlib.axis.XTick object at 0x00000269D9F1FD90>, <matplotlib.axis.XTick object at 0x00000269D9F1F1C0>, <matplotlib.axis.XTick object at 0x00000269D9F1F370>, <matplotlib.axis.XTick object at 0x00000269D9867F40>, <matplotlib.axis.XTick object at 0x00000269D9F124F0>, <matplotlib.axis.XTick object at 0x00000269D9F14F70>], [Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, '')])
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.legend()}
\NormalTok{plt.grid(axis}\OperatorTok{=}\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{, linestyle}\OperatorTok{=}\StringTok{\textquotesingle{}{-}{-}\textquotesingle{}}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.7}\NormalTok{)}

\CommentTok{\# Graficar la función de distribución acumulada (CDF)}
\NormalTok{plt.subplot(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{plt.step(x, cdf\_values, where}\OperatorTok{=}\StringTok{\textquotesingle{}mid\textquotesingle{}}\NormalTok{, color}\OperatorTok{=}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}F(X)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.scatter(x, cdf\_values, color}\OperatorTok{=}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Valores de X\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Probabilidad acumulada\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{\textquotesingle{}Función de Distribución Acumulada (CDF) {-} Binomial(10, 0.7)\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xticks(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
([<matplotlib.axis.XTick object at 0x000001B1C070CD00>, <matplotlib.axis.XTick object at 0x000001B1C070CCD0>, <matplotlib.axis.XTick object at 0x000001B1C070C100>, <matplotlib.axis.XTick object at 0x000001B1C075D160>, <matplotlib.axis.XTick object at 0x000001B1C075D880>, <matplotlib.axis.XTick object at 0x000001B1C075DC70>, <matplotlib.axis.XTick object at 0x000001B1C073C1F0>, <matplotlib.axis.XTick object at 0x000001B1C07429A0>, <matplotlib.axis.XTick object at 0x000001B1C0751340>, <matplotlib.axis.XTick object at 0x000001B1C0756310>, <matplotlib.axis.XTick object at 0x000001B1C07630A0>], [Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, '')])
=======
([<matplotlib.axis.XTick object at 0x00000269D9F3DD00>, <matplotlib.axis.XTick object at 0x00000269D9F3DCD0>, <matplotlib.axis.XTick object at 0x00000269D9F3D100>, <matplotlib.axis.XTick object at 0x00000269D9F8D160>, <matplotlib.axis.XTick object at 0x00000269D9F8D880>, <matplotlib.axis.XTick object at 0x00000269D9F8DC70>, <matplotlib.axis.XTick object at 0x00000269D9F6D1F0>, <matplotlib.axis.XTick object at 0x00000269D9F729A0>, <matplotlib.axis.XTick object at 0x00000269D9F81340>, <matplotlib.axis.XTick object at 0x00000269D9F86310>, <matplotlib.axis.XTick object at 0x00000269D9F930A0>], [Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, '')])
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.legend()}
\NormalTok{plt.grid(axis}\OperatorTok{=}\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{, linestyle}\OperatorTok{=}\StringTok{\textquotesingle{}{-}{-}\textquotesingle{}}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.7}\NormalTok{)}

\CommentTok{\# Mostrar gráficos}
\NormalTok{plt.tight\_layout()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/unnamed-chunk-10-1.pdf}
\end{center}

\begin{Ejemplo}{Ejemplo: número de bolas rojas extraídas de una urna con reposición}{}

Tenemos una urna con \(100\) bolas de las cuales 40 son rojas y 60 son
blancas. Extraemos al azar una bola, anotamos su color y la devolvemos a
(reponemos en) la urna.

Supongamos que repetimos este proceso \(n=10\) reponiendo en cada
ocasión la bola extraída.

Consideremos la variable aleatoria \(X\) como el número de bolas rojas
extraídas (con reposición) en \(n=10\) repeticiones del mismo
experimento de Bernoulli.

Bajo estas condiciones repetimos \(n=10\) veces el mismo experimento de
Bernoulli con probabilidad de éxito (sacar bola roja)
\[P(Roja)=P(Éxito)=p=\frac{40}{100}=0.4.\]

Así que la variable \(X\) que es el número de bolas rojas extraídas de
la urna (con reposición) en \(n=10\) ocasiones sigue una ley binomial
\(B(n=10,p=0.4).\)

Nos preguntamos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  ¿Cuál es la probabilidad de que saquemos exactamente \(4\) bolas
  rojas?
\item
  ¿Cuál es la probabilidad de que saquemos al menos \(4\) bolas rojas?
\item
  ¿Cuál es la probabilidad de que saquemos menos de \(3\) bolas rojas?
\item
  ¿Cuál es el valor esperado del número de bolas rojas?
\item
  ¿Cuál es la desviación típica del número de bolas rojas?
\end{enumerate}

\textbf{Solución 1}. ¿Cuál es la probabilidad de que saquemos
exactamente \(4\) rojas?

Utilizando la función de probabilidad, tenemos que: \begin{eqnarray*}
P(X=4)&=&{10\choose 4}\cdot 0.4^4\cdot (1-0.4)^{10-4}
= \frac{10!}{(10-4)!\cdot 4!}\cdot 0.4^4\cdot 0.6^6\\
&=& \frac{7\cdot 8\cdot 9\cdot 10}{1\cdot 2\cdot 3\cdot 4}\cdot 0.4^4\cdot 0.6^6=0.2508227.
\end{eqnarray*}

Con R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\DecValTok{4}\NormalTok{,}\AttributeTok{size=}\DecValTok{10}\NormalTok{,}\AttributeTok{prob =} \FloatTok{0.4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2508227
\end{verbatim}

\textbf{Solución 2}. ¿Cuál es la probabilidad de que saquemos al menos
\(4\) bolas rojas?

La probabilidad de sacar al menos 4 rojas se expresa como

\(P(X \geq 4)=1-P(X<4)=1-P(X\leq 3):\)

\begin{align*}
P(X\leq 3)=& P(X=0)+P(X=1)+P(X=2)+P(X=3)\\
=& 
 {10\choose 0}\cdot 0.4^0\cdot (1-0.4)^{10-0}+ {10\choose 1}\cdot 0.4^1\cdot (1-0.4)^{10-1}\\
+&{10\choose 2}\cdot 0.4^2\cdot (1-0.4)^{10-2}+ {10\choose 3}\cdot 0.4^3\cdot (1-0.4)^{10-3}\\
=&0.3822806.
\end{align*}

Con R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pbinom}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{0.4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3822806
\end{verbatim}

Así que

\[P(X \geq 4 )=1-P(X< 4)=1-P(X\leq 3)\approx 1-0.3823=0.6177.\]

Otra manera usando \texttt{R} sería:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{pbinom}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{0.4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6177194
\end{verbatim}

Aunque en estos casos el parámetro \texttt{lower.tail\ =\ FALSE} es sin
duda nuestra mejor opción:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pbinom}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{0.4}\NormalTok{,}\AttributeTok{lower.tail =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6177194
\end{verbatim}

\textbf{Solución 3}. ¿Cuál es la probabilidad de que saquemos menos de
\(3\) bolas rojas?

\begin{align*}
P(X< 3)=& P(X\leq 2)= P(X=0)+P(X=1)+P(X=2)\\
=& 
{10\choose 0}\cdot 0.4^0\cdot (1-0.4)^{10-0}+ {10\choose 1}\cdot 0.4^1\cdot (1-0.4)^{10-1}\\
&+
{10\choose 2}\cdot 0.4^2\cdot (1-0.4)^{10-2}\\
=&0.1672898.
\end{align*}

En \texttt{R}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{0.4}\NormalTok{)}\SpecialCharTok{+}\FunctionTok{dbinom}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{0.4}\NormalTok{)}\SpecialCharTok{+}\FunctionTok{dbinom}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{0.4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1672898
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pbinom}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{0.4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1672898
\end{verbatim}

\textbf{Solución 4}. ¿Cuál es el valor esperado del número de bolas
rojas?

Como \(X\) es una \(B(n=10,p=0.4)\) sabemos que

\[E(X)=n\cdot p = 10\cdot 0.4=4.\]

Aunque en Python tenemos la función \texttt{stats} que nos lo calcula
directamente:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"E(X) = }\SpecialCharTok{\{m\}}\StringTok{"}\NormalTok{.}\BuiltInTok{format}\NormalTok{(m}\OperatorTok{=}\NormalTok{binom.stats(n }\OperatorTok{=} \DecValTok{10}\NormalTok{, p }\OperatorTok{=} \FloatTok{0.4}\NormalTok{, moments}\OperatorTok{=}\StringTok{\textquotesingle{}m\textquotesingle{}}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
E(X) = 4.0
\end{verbatim}

\textbf{Solución 5}. ¿Cuál es la desviación típica del número de bolas
rojas?

La varianza es: \[
Var(X)=n\cdot p \cdot(1-p)=10\cdot 0.4\cdot 0.6=2.4.
\]

Por lo tanto la desviación típica es

\[\sqrt{Var(X)}=\sqrt{2.4}= 1.5491933.\]

Aunque en Python tenemos la función \texttt{stats} que nos lo calcula
directamente:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"Var(X) = }\SpecialCharTok{\{v\}}\StringTok{"}\NormalTok{.}\BuiltInTok{format}\NormalTok{(v}\OperatorTok{=}\NormalTok{binom.stats(n }\OperatorTok{=} \DecValTok{10}\NormalTok{, p }\OperatorTok{=} \FloatTok{0.4}\NormalTok{, moments}\OperatorTok{=}\StringTok{\textquotesingle{}v\textquotesingle{}}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Var(X) = 2.4
\end{verbatim}

\end{Ejemplo}

\section{Distribución geométrica}\label{distribuciuxf3n-geomuxe9trica}

Todos hemos jugado a, por ejemplo, tirar una moneda hasta que obtengamos
la primera cara. O también tirar una pelota a una canasta de baloncesto
hasta obtener la primera canasta.

Desde otro punto de vista también podemos intentar modelar el número de
veces que accionamos una interruptor y la bombilla se ilumina hasta que
falla. O también el número de veces que un cajero automático nos da
dinero hasta que falla.

La \textbf{modelización de este tipo de problemas se consigue con la
llamada distribución geométrica}.

\begin{Definicion}{Distribución geométrica}{}

Repitamos un experimento Bernoulli, de parámetro \(p\), de forma
independiente hasta obtener el primer éxito. Sea \(X\) la v.a. que
cuenta el número de fracasos antes del primer éxito. Por ejemplo que
hayamos tenido \(x\) fracasos será una cadena de \(x\) fracasos
culminada con un éxito. Más concretamente

\[P(\overbrace{FFF\ldots F}^{x}E)=P(F)^{x}\cdot P(E)=(1-p)^{x}\cdot p=q^{x}\cdot p.\]

Su función de probabilidad es

\[
P_X(x)=P(X=x)=\left\{\begin{array}{ll}
(1-p)^{x}\cdot p & \mbox{ si } x=0,1,2,\ldots\\
0 &\mbox{ en otro caso}
\end{array}\right..
\]

La v.a. definida anteriormente diremos que sigue una distribución
geométrica de parámetro \(p\). La denotaremos por \(Ge(p)\). Su dominio
es \(D_X=\{0,1,2,\ldots\}\).

\end{Definicion}

\begin{Ejemplo}{Ejemplo}{}

Por ejemplo calculemos P(\(X\leq 3\)). Por la propiedad de la
probabilidad del suceso complementario tenemos que

\[
P(X\leq 3 )=1-P(X> 3)=1-P(X\geq 4)
\]

Efectivamente, el complementario del evento \(X\leq 3\) nos dice que
hemos fracasado más de tres veces hasta conseguir el primer éxito, es
decir, \textbf{hemos fracasado 4 o más veces}. Podemos simbolizar dicho
evento de la forma siguiente: \[
\{X>3\}=\{X\geq 4\}= \{FFFF\}
\]

Ahora, al ser los intentos independientes, tenemos que:

\begin{eqnarray*}
P(X>3) & = & P(\{FFFF\})= P(F)\cdot P(F)\cdot P(F)\cdot P(F)\\
&=& (1-p)\cdot (1-p)\cdot (1-p)\cdot (1-p)= (1-p)^{3+1}\\
&=&(1-p)^{4}.
\end{eqnarray*}

El valor de la función de distribución de \(X\) en \(x=3\) será, pues:
\[F_X(3)=P(X\leq 3)=1-P(X>3)=1-(1-p)^{3+1}.\] Generalizando el resultado
anterior a cualquier entero positivo \(k=0,1,2,\ldots\), tenemos:
\[F_X(k)=P(X\leq k)=1-(1-p)^{k+1},\mbox{ si } k=0,1,2,\ldots\]

En general, tendremos que: \[
F_X(x)=P(X\leq x)=
\left\{\begin{array}{ll} 
0, & \mbox{ si } x<0,\\
1- (1-p), & \mbox{ si } k=0\leq x <1,\\
1- (1-p)^2, & \mbox{ si } k=1\leq x <2,\\
1- (1-p)^3, & \mbox{ si } k=2\leq x <3,\\
1- (1-p)^{k+1}, & \mbox{ si } \left\{ \begin{array}{l}k\leq x< k+1,\\\mbox{para } k=0,1,2,\ldots\end{array}
 \right.
\end{array}
\right..
\]

\end{Ejemplo}

Lo que demuestra la siguiente propiedad

\begin{Proposicion}{Función de distribución de una \(Ge(p)\)}{}

Si \(X\) es una v.a. que sigue una distribución geométrica de parámetro
\(p\), entonces su función de distribución es:

\[
F_X(x)=P(X\leq x)=
\left\{\begin{array}{ll} 
0, & \mbox{ si } x<0,\\
1- (1-p)^{k+1}, & \mbox{ si } \left\{ \begin{array}{l}k\leq x< k+1,\\\mbox{para } k=0,1,2,\ldots\end{array}
\right.
\end{array}
\right..
\]

Notemos que el límite de la función de distribución es: \[
\displaystyle\lim_{k\to +\infty } F_X(k)=\lim_{k\to +\infty } 1-(1-p)^{k+1}=
1,
\] ya que \(0<1-p<1\).

\end{Proposicion}

Hagamos los cálculos necesarios para los momentos básicos de la
distribución geométrica. Recordemos del tema de variables aleatorias que

Si \(|r|<1\) son convergentes las derivadas, respecto de \(r\), de la
serie geométrica y convergen a la derivada correspondiente. Así tenemos
que

\[
\begin{array}{rlrl}
\left(\sum_{k=0}^{+\infty} r^k\right)'&= \sum_{k=1}^{+\infty}k\cdot
r^{k-1} &= \left(\frac1{1-r}\right)'=\frac1{(1-r)^2}\\
\left(\sum_{k=0}^{+\infty} r^k\right)^{''}&= \sum_{k=2}^{+\infty}k \cdot(k-1)\cdot
r^{k-2}&=\left(\frac1{1-r}\right)^{''}=\frac2{(1-r)^3}
\end{array}
\]

Ahora podemos calular el valor esperado y la varianza de una v.a.
\(Ge(p)\).vRecordemos que \(P(X=x)=(1-p)^x\cdot p\) si
\(x=0,1,2,\ldots\) y aplicado la fórmula anterior con \(r=1-p\)

\begin{align*}
E(X)=&\sum_{x=0}^{+\infty} x\cdot P_x(x)=\sum_{x=0}^{+\infty} x\cdot (1-p)^x\cdot p\\
=& p\cdot (1-p) \cdot \sum_{x=1}^{+\infty} x\cdot (1-p)^{x-1}\\
=& p\cdot (1-p)\cdot \frac{1}{(1-(1-p))^2}=p\cdot (1-p)\cdot \frac{1}{p^2}=\frac{1-p}{p}
\end{align*}

Necesitamos calcular \(E(X^2)\), aplicado la fórmula anterior con
\(r=1-p\)

\begin{align*}
E(X^2)
=&\sum_{x=0}^{+\infty} x^2\cdot P_X(x)=\sum_{x=1}^{+\infty} x^2\cdot (1-p)^x\cdot p
\\
=& 
\sum_{x=1}^{+\infty} (x\cdot (x-1)+x)\cdot (1-p)^{x}\cdot p\\
=&
 \sum_{x=1}^{+\infty} x\cdot (x-1)\cdot (1-p)^{x}\cdot p + \sum_{x=1}^{+\infty} x \cdot (1-p)^{x}\cdot p\\
=&
 (1-p)^{2}\cdot p\cdot \sum_{x=2}^{+\infty} x\cdot (x-1)\cdot (1-p)^{x-2} + (1-p)\cdot p\sum_{x=1}^{+\infty} x \cdot (1-p)^{x-1}\\ 
=&
 (1-p)^{2}\cdot p\cdot \sum_{x=2}^{+\infty} x\cdot (x-1)\cdot (1-p)^{x-2}
 +(1-p)\cdot p\sum_{x=1}^{+\infty} x \cdot (1-p)^{x-1}\\
=&
 p\cdot (1-p)^2 \frac{2}{(1-(1-p))^3}+ (1-p)\cdot p \frac{1}{(1-(1-p))^2}\\
=&
p\cdot (1-p)^2 \frac{2}{p^3}+ (1-p)\cdot p \frac{1}{p^2}=\frac{2\cdot (1-p)^2}{p^2}+\frac{1-p}{p}.
\end{align*}

Ahora la varianza es

\begin{align*}
Var(X)=& E(X^2)-E(X)^2=\frac{2\cdot (1-p)^2}{p^2}+\frac{1-p}{p}-\left(\frac{1-p}{p}\right)^2\\
=&
\frac{2\cdot (1-p)^2+p\cdot(1-p)-(1-p)^2}{p^2}=\frac{(1-p)^2+p\cdot(1-p)}{p^2}\\
=&
\frac{1-2\cdot p + p^2+p-p^2}{p^2}= \frac{1-p}{p^2}.
\end{align*}

Por último su desviación típica es

\[\sqrt{Var(X)}=\sqrt{\frac{1-p}{p^2}}.\]

\subsection{\texorpdfstring{Resumen distribución geométrica \(Ge(p)\)
empezando en
0}{Resumen distribución geométrica Ge(p) empezando en 0}}\label{resumen-distribuciuxf3n-geomuxe9trica-gep-empezando-en-0}

\begin{table}
\centering
\begin{tabular}{|l|}
\hline\rowcolor{LightBlue}
$X=$ Geométrica (empieza en $0$) número de fracasos para conseguir el primer éxito
\\\hline
$D_X=\{0,1,\ldots n,\ldots\}$ \\\hline
$P_X(x)=P(X=x)=\left\{\begin{array}{ll}(1-p)^{x}\cdot p & \mbox{ si } x=0,1,2,\ldots \\0 & \mbox{ en otro caso.}\end{array}\right.$\\\hline
$F_X(x)=P(X\leq X)=\left\{\begin{array}{ll} 0 & \mbox{ si } x<0\\
 1- (1-p)^{k+1} & \mbox{ si } \left\{ \begin{array}{l}k\leq x< k+1\\\mbox{para } k=0,1,2,\ldots\end{array}
 \right.\end{array}\right.$ \\\hline
$E(X)=\frac{1-p}{p}$; $Var(X)=\frac{1-p}{p^2}$\\\hline
\end{tabular}
\end{table}

La variable geométrica que cuenta los intentos para obtener el primer
éxito.

Supongamos que sólo estamos interesados en el \textbf{número de
intentos} para obtener el primer éxito. Si definimos \(Y\)= número de
intentos para obtener el primer éxito. Entonces \(Y=X+1\) donde
\(X\sim Ge(p)\). Su dominio es \(D_Y=\{1,2,\ldots\}\) La media se
incrementa en un intento debido al éxito
\(E(Y)=E(X+1)=E(X)+1=\frac{1-p}{p}+1=\frac1{p}\). La varianza es la
misma \(Var(Y)=Var(X+1)=Var(X)=\frac{1-p}{p^2}\).

\subsection{\texorpdfstring{Resumen distribución geométrica \(Ge(p)\)
empezando en
\(1\)}{Resumen distribución geométrica Ge(p) empezando en 1}}\label{resumen-distribuciuxf3n-geomuxe9trica-gep-empezando-en-1}

\renewcommand{\arraystretch}{1.75}
\begin{table}
\centering
\begin{tabular}{|l|}
\hline\rowcolor{LightBlue}
$Y$ geométrica (que cuenta el éxito) número de **INTENTOS** para OBTENER el primer éxito
\\\hline
$D_Y=\{1,2,\ldots n,\ldots\}$ \\\hline
$P_Y(y)=P(Y=y)=\left\{\begin{array}{ll}(1-p)^{y-1}\cdot p & \mbox{ si } y=1,2,3,\ldots\\ 0 & \mbox{ en otro caso.}\end{array}\right.$\\\hline
$F_Y(y)=P(Y\leq y)=\left\{\begin{array}{ll} 0 & \mbox{ si } y<1\\ 1- (1-p)^{k} & \mbox{ si } \left\{ \begin{array}{l}k\leq y< k+1\\\mbox{para } k=1,2,3,\dots \end{array} \right.\end{array}\right.$ \\\hline
$E(X)=\frac1{p}; Var(X)=\frac{1-p}{p^2}$
\\\hline
\end{tabular}
\end{table}

\subsection{Propiedad de la falta de
memoria}\label{propiedad-de-la-falta-de-memoria}

\begin{Proposicion}{Propiedad de la falta de memoria}{}

Sea \(X\) una v.a. discreta con dominio \(D_X=\{0,1,2,\ldots\}\), con
\(P(X=0)=p\).

Entonces \(X\) sigue una ley \(Ge(p)\) si, y sólo si, \[
P\left(X> k+j\big| X\geq j\right)=P(X> k)
\] para todo \(k,j=0,1,2,3\ldots\).

\end{Proposicion}

\textbf{Demostración}

Si \(X\) es geométrica entonces el lado derecho de la igualdad es

\[
P(X>k)=1-P(X\leq k)=1-\left(1-(1-p)^{k+1}\right)=(1-p)^{k+1},
\] y el lado de izquierdo es

\begin{align*}
P\left(X> k+j\big| X\geq j\right)=&\frac{P\left(\{X> k+j\}\cap \{X\geq j\} \right)}{P\left(X\geq j\right)}=
\frac{P\left(X>k+j \right)}{P\left(X\geq j \right)} = \frac{1-P(X\leq k+j)}{1-P(X\leq j-1)}\\
=& \frac{1-(1-(1-p)^{k+j+1})}{1-(1-(1-p)^{j-1+1})} =\frac{(1-p)^{k+j+1}}{(1-p)^{j}} = (1-p)^{k+1},
\end{align*}

lo que demuestra la igualdad.

Para demostrar el recíproco, tomemos \(j=1\) y \(k\geq 0\). Entonces,
por la propiedad de la pérdida de memoria: \[
P\left(X> k+1\big| X\geq 1\right)=P(X> k)
\] Como \(P(X=0)=p\), tenemos que
\(P(X \geq 1 )=1-P(X<1)=1-P(X=0)=1-p\).

Combinado las igualdades, tenemos que:

\[
P\left(X> k+1\big| X\geq 1\right)=\frac{P(X>k+1, X\geq 1)}{P(X\geq 1)}=\frac{P(X>k+1)}{P(X\geq 1)}=P(X>k).
\] Así podemos poner que

\begin{eqnarray*}
P(X>k+1)&=&P(X\geq 1)\cdot P(X>k)=\left(1-P(X<1)\right)\cdot P(X>k)\\
&=&\left(1-P(X=0)\right)\cdot P(X>k)=(1-p)\cdot P(X>k).
\end{eqnarray*}

Es decir en general tenemos que

\[
P(X>k+1)=(1-p)\cdot P(X>k)
\] Del mismo modo para \(j=2\)

\[
\scriptsize{P(X>k+2)=(1-p)\cdot P(X>k+1)}
\]

Restando la primera igualdad de la última obtenemos.

\[
\scriptsize{P(X>k+1)-P(X>k+2)=(1-p)\cdot P(X>k)-(1-p)\cdot P(X>k+1)}
\]

de donde operando en cada lado de la igualdad obtenemos la recurrencia

\[
\scriptsize{[1-P(X\leq k+1)]-[1-P(X\leq k+2)]=(1-p)\cdot [P(X>k)-P(X>k+1)]}
\]

Ahora operando \[
P(X\leq k+2)-P(X\leq k+1)=(1-p)\cdot[1-P(X\leq k)-\left(1-P(X\leq k+1)\right)]
\] \[
P(X=k+2)=(1-p)\cdot[P(X\leq k+1)-P(X\leq k)]
\] \[
P(X=k+2)=(1-p)\cdot P(X=k+1)
\]

De forma similar obtenemos

\[
P(X=k+1)=(1-p)\cdot P(X=k)
\] Utilizando la recurrencia anterior, podemos calcular todas las
probabilidades \(P(X=k)\) a partir de la \(P(X=0)=p\): \[
\scriptsize{
\begin{array}{rl}
P(X=0)&= p,\\
P(X=1)&=P(X=0+1)= (1-p)\cdot P(X=0) =(1-p)\cdot p,\\
P(X=2)&=P(X=1+1)= (1-p)\cdot P(X=1)=(1-p)\cdot (1-p)\cdot p=(1-p)^2\cdot p,\\
 \vdots & \vdots \\
P(X=k)&=P(X=(k-1)+1)= (1-p)\cdot P(X=k-1)=(1-p)\cdot (1-p)^{k-1}\cdot p=(1-p)^{k}\cdot p,
\end{array}
}
\] lo que demuestra el recíproco, es decir, que \(X\) es \(Geom(p)\).

Lo que demuestra la propiedad de la falta de memoria

\begin{Advertencia}{Observación: Interpretación de la propiedad}{}

La propiedad de la falta de memoria \[
P(X> k+j\big|X \geq j)=P(X > k),
\] significa que, aunque \textbf{ya llevemos al menos \(j\) fracasos},
la probabilidad de \textbf{que fracasemos \(k\) veces más} no disminuye,
es la misma que era cuando empezamos el experimento.

A este efecto se le suele etiquetar con la frase \textbf{el experimento
carece de memoria} o es un \textbf{experimento sin memoria}
(\emph{Memoryless Property}).

\end{Advertencia}

Un ejemplo muy sencillo nos aclarará el alcance de esta propiedad

\begin{Ejemplo}{Ejercicio: la llave que abre la puerta}{}

Tenemos un llavero con 10 llaves, solo una de ellas abre una puerta.
Cada vez que probamos una llave y falla olvidamos que llave hemos
probado. ¿Cuál es la probabilidad de que si ya lo hemos intentado 5
veces necesitemos más de 4 intentos adicionales para abrir la puerta?

Tomemos \(k=4,j=5\), aplicando la propiedad de la falta de memoria

\[
P(X> 4+5/X \geq 5)=P(X > 4)
\]

Después de 5 fracasos no estamos ``más cerca'' de abrir la puerta. La
propiedad de la falta de memoria nos dice que en \textbf{después de cada
intento es como si empezásemos de nuevo a abrir la puerta}. Tras 5
fracasos la probabilidad de que fallemos más de 4 veces más es la misma
que cuando lo intentamos la primera vez.

¿Cuál es el número esperado de fracasos hasta abrir la puerta?

\[
E(X)=\frac{1-p}{p}=\frac{1-\frac{1}{10}}{\frac{1}{10}}=\frac{\frac{9}{10}}{\frac{1}{10}}=9.
\]

La varianza es

\[
Var(X)=\frac{1-p}{p^2}=\frac{1-\frac{1}{10}}{\left(\frac{1}{10}\right)^2}=\frac{\frac{9}{10}}{\frac{1}{100}}=
90.
\]

La desviación típica es \(\sqrt{90}=9.486833.\)

\end{Ejemplo}

\begin{Ejemplo}{Ejemplo: El clásico del fútbol}{}

\textbf{Ejemplo: partidos hasta que el Barça gana al Madrid}

Los partidos Real Madrid vs FC Barcelona de \textbf{la liga} española se
suelen denominar \textbf{El Clásico}, sean en el Bernabeu (estadio del
Real Madrid) o en el Camp Nou (estadio del Barça)

Sea \(X\) la variable que cuenta el número de veces consecutivas que en
un partido de fútbol de la liga el Barça no gana al Madrid sea en el
Camp Nou o el Bernabeu.

Nuestra amiga Aina es muy culé (hincha del Barça) y quiere averiguar
cuántos partidos consecutivos de \textbf{El Clásico} tiene que ver hasta
ver ganar al Barça por primera vez.

Le interesa estimar cuánto le va a costar este capricho. Tendrá que
comprar las entradas y pagar los viajes de Barcelona a Madrid.

En \href{https://es.wikipedia.org/wiki/El_Cl\%C3\%A1sico}{datos
historicos de \textbf{El clásico} en la wikipedia} están los datos hasta
el 3 de marzo de 2019: se han jugado en total 178 \textbf{Clásicos}
donde el Real Madrid ganó en 72 ocasiones, el Barça, en 72 y empataron
34 veces.

Nos hacemos las siguientes preguntas:

\begin{itemize}
\tightlist
\item
  Si Aina solo tiene dinero para ir a ver 3 partidos, ¿cuál es la
  probabilidad de no ver ganar al Barça en al menos tres partidos
  consecutivos?
\item
  ¿Cuántos partidos se tienen que jugar de media para ver ganar al Barça
  por primera vez?
\end{itemize}

Con los datos anteriores, podemos estimar que la probabilidad de que el
Barça gane un clásico cualquiera es:

\[P(\mbox{Barça})=\frac{72}{178}=0.4045.\]

Por tanto, podemos modelar la variable \(X\), que cuenta el número de
veces consecutivas que en un partido de fútbol de la liga el Barça no
gana al Madrid, con una ley geométrica empezando en cero con
probabilidad de éxito \(p=P(\mbox{Barça})=\frac{72}{178}\),

\[X=Ge\left(p=\frac{72}{178}=0.4045\right)\]

Así que lo que nos pregunta Aina es la siguiente probabilidad

\[P(X\geq 3)=1-P(X\leq 2)=1-\left(1-\frac{72}{178}\right)^{2+1}=0.7888.\]

Así que Aina tiene una probabilidad del \(78.88\%\) de no ver ganar al
Barça en al menos 3 partidos antes de ver uno en el sí que gane.

Para responder a la segunda pregunta, usando que la distribución de
\(X\) es:

\[X=Ge\left(p=\frac{72}{178}=0.4045\right)\]

entonces

\[E(X)=\frac{1-p}{p}=\frac{1-0.4045}{0.4045}=1.4722\]

y

\[Var(X)=\frac{1-p}{p^2}=\frac{1-0.4045}{0.4045^2}=3.6397\]

La desviación típica es \[\sqrt{3.6397}=1.9078.\]

\end{Ejemplo}

\subsubsection{Cálculos con R}\label{cuxe1lculos-con-r}

Veamos los cálculos básicos con R para la distribución geométrica
\(Ge(p=0.25)\). R implementa la geométrica que cuenta el número de
fracasos.

\(P(X=0)=(1-0.25)^0\cdot 0.25^1=0.25\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dgeom}\NormalTok{(}\DecValTok{0}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.25
\end{verbatim}

\(P(X\leq 0)=1- (1-0.25)^{0+1}=1-0.75=0.25\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pgeom}\NormalTok{(}\DecValTok{0}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.25
\end{verbatim}

\(P(X\leq 4)=1-(1-0.25)^{4+1}=1-0.75=1-0.75^5=0.7626953.\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pgeom}\NormalTok{(}\DecValTok{4}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.7626953
\end{verbatim}

Una muestra aleatoria de tamaño 25 de una \(Ge(0.25)\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rgeom}\NormalTok{(}\AttributeTok{n=}\DecValTok{25}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1]  5  4  1  6 10  0  0 10  7  0  6  2  1  3  0  2  5  0  0  5  5  3  3
[24]  2  2
\end{verbatim}

\subsubsection{Gráficos con R el
código}\label{gruxe1ficos-con-r-el-cuxf3digo}

\begin{center}
\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/graficos22-1.pdf}
\end{center}

\subsubsection{Cálculos con Python}\label{cuxe1lculos-con-python}

Veamos los cálculos básicos con Python para la distribución geométrica
\(Ge(p=0.25)\). scipy.stats implementa la distribución geométrica que
cuenta el número intentos así que empieza en 1

Cargamos la función de la librería

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ geom}
\end{Highlighting}
\end{Shaded}

La función de probabilidad es \texttt{geom.pmf(x,p,loc=0)=geom.pmf(x,p)}
es un geométrica que cuenta el número de intentos para obtener el primer
éxito el valor por defecto del último parámetro es \texttt{loc=0}.

Si queremos la que cuenta el número de fracasos para obtener el primer
éxito (la geométrica que empieza en 0) tenemos que usar
\texttt{geom.pmf(x,p,loc=-1)}.

Es decir \texttt{geom.pmf(x,p,loc=-1)=geom.pmf(x-1,p,loc=0)}

Veamos pues los cálculos para la \(Ge(p)\) que empieza en \(0\).

\(P(X=0)=(1-0.25)^0\cdot 0.25^1=0.25\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{geom.pmf(}\DecValTok{0}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{,loc}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.25
\end{verbatim}

\(P(X\leq 0)=1- (1-0.25)^{0+1}=1-0.75=0.25\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{geom.cdf(}\DecValTok{0}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{,loc}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.24999999999999997
\end{verbatim}

\(P(X\leq 4)=1-(1-0.25)^{4+1}=1-0.75=1-0.75^5=0.7626953.\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{geom.cdf(}\DecValTok{4}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{,loc}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.7626953125
\end{verbatim}

Una muestra aleatoria de tamaño 25 de una \(Ge(0.25)\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{geom.rvs(p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{, size}\OperatorTok{=}\DecValTok{20}\NormalTok{, loc}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
array([ 1,  4, 11,  0,  1,  2,  0,  0,  0,  5,  0,  2,  4,  9,  0,  4,  2,
        3,  2,  0], dtype=int64)
=======
array([1, 9, 2, 4, 1, 0, 1, 0, 0, 0, 1, 1, 7, 1, 1, 2, 5, 8, 1, 0],
      dtype=int64)
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

\textbf{Ejercicio}

Qué probabilidades son las que calcula el siguiente código y qué tipo de
variables geométricas son?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{geom.cdf(}\BuiltInTok{range}\NormalTok{(}\DecValTok{5}\NormalTok{),p}\OperatorTok{=}\FloatTok{0.3}\NormalTok{,loc}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0.    , 0.3   , 0.51  , 0.657 , 0.7599])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{geom.cdf(}\BuiltInTok{range}\NormalTok{(}\DecValTok{5}\NormalTok{),p}\OperatorTok{=}\FloatTok{0.3}\NormalTok{,loc}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0.3    , 0.51   , 0.657  , 0.7599 , 0.83193])
\end{verbatim}

Con Python también podemos calcular directamente algunos parámetros
asociado a una función de distribución predefinida

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{geom.stats(p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{, loc}\OperatorTok{=}\DecValTok{0}\NormalTok{, moments}\OperatorTok{=}\StringTok{\textquotesingle{}mv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(array(4.), array(12.))
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{geom.stats(p}\OperatorTok{=}\FloatTok{0.25}\NormalTok{, loc}\OperatorTok{={-}}\DecValTok{1}\NormalTok{, moments}\OperatorTok{=}\StringTok{\textquotesingle{}mv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(array(3.), array(12.))
\end{verbatim}

\begin{Ejercicio}{Ejercicio}{}

Comprobad que las medias y las varianzas calculadas en el código
anterior, corresponden a una \(Ge(p=0.3)\) empezando en \(1\) y a una
\(Ge(p=0.3)\) empezando en \(0\).

¿Son las varianzas siempre iguales?

\end{Ejercicio}

\subsubsection{Gráficos distribución geométrica con
Python}\label{gruxe1ficos-distribuciuxf3n-geomuxe9trica-con-python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ hypergeom}

\CommentTok{\# Parámetros de la distribución hipergeométrica}
\NormalTok{M }\OperatorTok{=} \DecValTok{100}  \CommentTok{\# Tamaño total de la población}
\NormalTok{n }\OperatorTok{=} \BuiltInTok{int}\NormalTok{(}\FloatTok{0.6} \OperatorTok{*}\NormalTok{ M)  }\CommentTok{\# Número de elementos de éxito en la población}
\NormalTok{N }\OperatorTok{=} \DecValTok{10}  \CommentTok{\# Tamaño de la muestra extraída}

\CommentTok{\# Valores de la variable aleatoria}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{0}\NormalTok{, N}\OperatorTok{+}\DecValTok{1}\NormalTok{)}

\CommentTok{\# Función de masa de probabilidad (PMF)}
\NormalTok{pdf }\OperatorTok{=}\NormalTok{ hypergeom.pmf(x, M, n, N)}

\CommentTok{\# Función de distribución acumulativa (CDF)}
\NormalTok{cdf }\OperatorTok{=}\NormalTok{ hypergeom.cdf(x, M, n, N)}

\CommentTok{\# Crear la figura y los subgráficos}
\NormalTok{fig, axes }\OperatorTok{=}\NormalTok{ plt.subplots(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{))}

\CommentTok{\# Gráfico de la PMF}
\NormalTok{axes[}\DecValTok{0}\NormalTok{].bar(x, pdf, color}\OperatorTok{=}\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.6}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}PMF\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{0}\NormalTok{].set\_title(}\StringTok{\textquotesingle{}Función de Masa de Probabilidad (PMF) de una Variable Hipergeométrica\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{0}\NormalTok{].set\_xlabel(}\StringTok{\textquotesingle{}Número de éxitos en la muestra\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{0}\NormalTok{].set\_ylabel(}\StringTok{\textquotesingle{}Probabilidad\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{0}\NormalTok{].legend()}
\NormalTok{axes[}\DecValTok{0}\NormalTok{].grid(axis}\OperatorTok{=}\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{, linestyle}\OperatorTok{=}\StringTok{\textquotesingle{}{-}{-}\textquotesingle{}}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.7}\NormalTok{)}

\CommentTok{\# Gráfico de la CDF}
\NormalTok{axes[}\DecValTok{1}\NormalTok{].step(x, cdf, color}\OperatorTok{=}\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, where}\OperatorTok{=}\StringTok{\textquotesingle{}mid\textquotesingle{}}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}CDF\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{1}\NormalTok{].set\_title(}\StringTok{\textquotesingle{}Función de Distribución Acumulada (CDF) de una Variable Hipergeométrica\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{1}\NormalTok{].set\_xlabel(}\StringTok{\textquotesingle{}Número de éxitos en la muestra\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{1}\NormalTok{].set\_ylabel(}\StringTok{\textquotesingle{}Probabilidad acumulada\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{1}\NormalTok{].legend()}
\NormalTok{axes[}\DecValTok{1}\NormalTok{].grid(axis}\OperatorTok{=}\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{, linestyle}\OperatorTok{=}\StringTok{\textquotesingle{}{-}{-}\textquotesingle{}}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.7}\NormalTok{)}

\CommentTok{\# Ajustar el layout para evitar solapamientos}
\NormalTok{plt.tight\_layout()}

\CommentTok{\# Mostrar los gráficos}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/unnamed-chunk-20-1.pdf}
\end{center}

\section{Distribución binomial
negativa}\label{distribuciuxf3n-binomial-negativa}

Podemos volver al probalma de de la puerta pero en esta ocasión tiene
dos cerraduras. Supongamos que disponemos de 10 llaves distintas y
tenemos que abrir una puerta con \textbf{dos cerraduras}.

Comenzamos por la primera cerradura, de tal forma que cada vez olvidamos
qué llave hemos probado. Una vez abierta la primera cerradura probamos
de igual forma con la segunda hasta que también la abrimos.

Sea \(X=\) la v.a. que cuenta el número de fracasos hasta abrir la
puerta. Acertar una llave de la puerta es un experimento Bernoulli con
probabilidad de éxito \(p=0.1\). Lo repetiremos hasta obtener 2 éxitos.

En general tendremos un experimento de Bernoulli con probabilidad de
éxito \(0<p<1\) tal que:

Repetimos el experimento hasta obtener el \(n\)-ésimo éxito ¡¡abrir la
maldita puerta!!. Sea \(X\) la v.a. que cuenta el número fallos hasta
abrir la puerta, es decir, hasta conseguir el n-ésimo éxito. Notemos que
no contamos los éxitos, solo contamos los fracasos

Si representamos como es habitual un suceso como una cadena de F's y
E's, para \(n=2\), algunos sucesos elementales serán:
\[\small{\{EE,FEE,EFE, FFEE,FEFE,EFFE,FFFEE,FFEFE,FEFFE,EFFFE\}.}\]

Calculemos algunas probabilidades para \(n=2\): \[
\small{
\begin{array}{rl}
P(X=0) & =P(\{EE\})=p^2, \\
P(X=1) & =P(\{FEE,EFE\})=2\cdot (1-p)\cdot p^2, \\
P(X=2) & =P(\{FFEE,FEFE,EFFE\})=3\cdot (1-p)^2\cdot p^2, \\
P(X=3) & =P(\{FFFEE,FFEFE,FEFFE,EFFFE\})=4\cdot (1-p)^3\cdot p^2.
\end{array}
}
\]

\begin{Definicion}{Distribución binomial negativa}{}

Una v.a. con este tipo de distribución recibe el nombre de
\textbf{binomial negativa} y la denotaremos por \(BN(n,p)\).

Notemos que \(BN(1,p)=Ge(p)\).

\end{Definicion}

\begin{Proposicion}{Propiedade}{}

En general la función de probabilidad de una v.a. \(BN(n,p)\) es

\[
P_{X}(k)=P(X=k)=\left\{\begin{array}{ll}
 {k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n & \mbox{si } k=0,1,\ldots\\
 0 & \mbox{en otro caso}\end{array}\right.
\]

\end{Proposicion}

\textbf{Demostración}

Justifiquemos el resultado. Sea \(X\) una \(BN(n,p)\) y sea
\(k=0,1,2,\ldots\).

\[P(X=k)=P(\mbox{Todas las cadenas de E's y F' con $k$ F, con $n$ E y acabadas en E})\]

\[
\overbrace{\underbrace{\overbrace{EFFF\ldots EEF}^{n-1 \quad \mbox{Éxitos}.}}}_{k \quad\mbox{Fracasos}}^{k+n-1\mbox{ posiciones}}E
\]

De estas cadenas hay tantas como maneras de elegir de entre las
\(k+n-1\) primeras posiciones \(n-1\) para colocar los éxitos. Esta
cantidad es el número binomial \({k+n-1\choose n-1}.\)

\begin{Definicion}{Números binomiales negativos}{}

Dados dos enteros positivos \(n\) y \(k\) se define el número binomial
negativo como

\[\binom{-n}{k}=\frac{(-n)(-n-1)\cdots (-n-k+1)}{k!}.\]

\end{Definicion}

Los números binomiales negativos generalizan la fórmula de Newton para
exponentes negativos: \[
(t+1)^{-n}=\sum_{k=0}^{+\infty}\left(\begin{array}{c} -n
\\ k\end{array}\right) t^{k}
\]

\texttt{R} usa la función \texttt{choose} para calcular números
binomiales, sean negativos o no. Veámoslo con un ejemplo:

\[
\begin{array}{rl}
{-6\choose 4}&=\frac{-6\cdot (-6-1)\cdot \cdot (-6-2)\cdot (-6-3) }{4!}\\
&= \frac{-6\cdot(-7)\cdot (-8)\cdot (-9)}{24}\\
&= \frac{3024}{24}=126.
\end{array}
\]

Si realizamos el cálculo con \texttt{R} obtenemos el mismo resultado:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{6}\NormalTok{,}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 126
\end{verbatim}

\subsection{\texorpdfstring{Esperanza y varianza de una
\(BN(n,p)\)}{Esperanza y varianza de una BN(n,p)}}\label{esperanza-y-varianza-de-una-bnnp}

Su \textbf{esperanza es}

\[E(X)=\sum_{k=0}^{+\infty} k\cdot {k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n=n\cdot\frac{1-p}{p}.\]

La \textbf{esperanza de \(X^2\) es}

\[E(X^2)=\sum_{k=0}^{+\infty} k^2\cdot {k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n=n\cdot\frac{1-p}{p^2}+\left(n\cdot \frac{1-p}{p}\right)^2.\]

Por último la \textbf{varianza es}

\[
Var(X)=E(X^2)-E(X)^2=
\]

\[=n\cdot \frac{1-p}{p^2}+\left(n\cdot \frac{1-p}{p}\right)^2-\left(n\cdot \frac{1-p}{p}\right)^2=
n\cdot \frac{1-p}{p^2}.\]

y por tanto la desviación típica es

\[\sqrt{Var(X)} = \frac{\sqrt{n(1-p)}}{p}\]

\subsection{\texorpdfstring{Resumen distribución Binomial Negativa
\(BN(n,p)\)}{Resumen distribución Binomial Negativa BN(n,p)}}\label{resumen-distribuciuxf3n-binomial-negativa-bnnp}

\begin{table}
\centering
\begin{tabular}{|l|}
\hline\rowcolor{LightBlue}
 $X=$ Número de fracasos antes de conseguir el $n$-ésimo éxito, $P(\mbox{Éxito})=p$. $BN(n,p)$ 
\\\hline
$D_X=\{0,1,2,3\ldots\}$ \\\hline
$P_X(k)=P(X=k)=\left\{\begin{array}{ll} {k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n, & \mbox{si } k=0,1,\ldots \\ 0, & \mbox{en otro caso.}\end{array}\right.$\\\hline
$
F_X(x)=P(X\leq x)=
\left\{
\begin{array}{ll} 0, & \mbox{si } x<0\\\displaystyle\sum_{i=0}^{k} P(X=i) & \mbox{si }\left\{\begin{array}{l}k\leq x< k+1,\\k=0,1,2,\ldots\end{array}\right.\end{array}\right.$ 
\\\hline
$E(X)=n\cdot\frac{1-p}{p}$; $Var(X)=n\cdot \frac{1-p}{p^2}.$ \\\hline
\end{tabular}
\end{table}

\subsection{Ejemplo de la puerta con dos
cerraduras}\label{ejemplo-de-la-puerta-con-dos-cerraduras}

\begin{Ejemplo}{: Ejemplo: puerta con dos cerraduras}{}

Recordemos nuestra puerta con dos cerraduras que se abren
secuencialmente. Tenemos un manojo de 10 llaves casi idénticas de manera
que cada vez que probamos una llave olvidamos qué llave hemos usado.

Sea \(X\) la v.a. que nos da el número de intentos fallidos hasta abrir
abrir la puerta.

Estamos interesado en modelar este problema. La preguntas son:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  ¿Cuál es la distribución de probabilidad de \(X\) la v.a. que nos da
  el número fallos hasta abrir la puerta?
\item
  ¿Cuál es la función de probabilidad y de distribución de \(X\)?
\item
  ¿Cuál es la probabilidad de fallar exactamente 5 veces antes de abrir
  la puerta?
\item
  ¿Cuál es la probabilidad de fallar más de 4?
\item
  ¿Cuál es el número esperado de fallos? ¿Y su desviación típica?
\end{enumerate}

\textbf{Solución 1.} ¿Cuál es la distribución de probabilidad de \(X\)
la v.a. que nos da el número fallos hasta abrir la puerta?

Bajo estados condiciones tenemos que la probabilidad de ``éxito'' de
cada intento es \(p=\frac{1}{10}=0.1\). Como cada vez \emph{olvidamos}
qué llave hemos probado, cada intento será independiente del anterior.

Así que la variable \(X\) que queremos modelar cuenta el número fallos
de repeticiones sucesivas e independientes de un experimento
\(Ber(p=0.1)\) hasta conseguir 2 éxitos en un experimento.

Por lo tanto podemos asegurar que \(X\) sigue un distribución
\(BN(n=2,p=0.1).\)

\textbf{Solución 2.} ¿Cuál es la función de probabilidad y de
distribución del \(X\)?

En general la función de probabilidad de una \(BN(n,p)\) es

\[
P_X(k)=P(X=k)=
\left\{
\begin{array}{cc} 
{k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n & \mbox{si } k=0,1,\ldots \\ 0 & \mbox{en otro caso.}\end{array}\right.
\]

Si aplicamos la expresión anterior para \(n=2\) y \(p=0.1\), obtenemos:
\[
P_X(k)=P(X=k)=
\left\{
\begin{array}{cc} 
{k+2-1\choose 2-1} \cdot 0.9^{k}\cdot 0.1^2 & \mbox{si } k=0,1,2,\ldots \\ 0 & \mbox{en otro caso.}\end{array}\right.
\]

Simplificando

\[
P_X(X=k)=P(X=k)=
\left\{
\begin{array}{cc} 
0.01\cdot (k+1)\cdot 0.9^{k}, & \mbox{si } k=0,1,2,\ldots \\ 0 & \mbox{en otro caso.}\end{array}\right.
\]

La función de distribución en general es

\[
F_X(x)=P(X\leq x)=
\left\{
\begin{array}{ll}
0 & \mbox{si } x<0 \\
\displaystyle\sum_{i=0}^{k }{i+n-1\choose n-1} \cdot (1-p)^{i+n-1}\cdot p^n 
& \mbox{si }\left\{\begin{array}{l} k\leq x< k+1\\k=0,1,2,\ldots\end{array}\right. 
\end{array}
\right.
\]

Simplificando para \(n=2\), \(p=0.1\).

\[
F_X(x)=P(X\leq x)=
\left\{
\begin{array}{ll}
0, & \mbox{si } x<0, \\
\displaystyle\sum_{i=0}^{k }0.01\cdot (i+1) \cdot 0.9^{i+1},
& \mbox{si }\left\{\begin{array}{l} k\leq x< k+1,\\k=0,1,2,\ldots\end{array}\right. 
\end{array}
\right.
\]

\textbf{Solución 3.} ¿Cuál es la probabilidad de fallar exactamente 5
veces antes de abrir la puerta?

\[
P(X=5)= 0.01\cdot (5+1) \cdot 0.9^{5}= 0.06 \cdot 0.9^{5}= 0.0354294.
\]

\textbf{Solución 4.} ¿Cuál es la probabilidad de fallar más de 4?

Nos piden que \[
P(X>4)=1-P(X\leq 4).
\]

Calculemos primero \(P(X\leq 4):\)

\[
\begin{array}{rl}
P(X\leq 4) &= \displaystyle\sum_{x=0}^{4} P(X=x)=P(X=0)+P(X=1)+P(X=2)+P(X=3)+P(X=4)\\
&= 0.01\cdot (0+1) \cdot 0.9^{0}+0.01\cdot (1+1) \cdot 0.9^{1}+0.01\cdot (2+1) \cdot 0.9^{2} \\ &\ \ 
+0.01\cdot (3+1) \cdot 0.9^{3} + 0.01\cdot (4+1) \cdot 0.9^{4} \\ & =
0.01 +0.018+0.0243+0.02916+0.032805 = 0.114265.
\end{array}
\]

Por lo tanto

\[
P(X>4)=1-P(X\leq 4)=1-0.114265=
0.885735.
\]

\textbf{Solución 5.} ¿Cuál es el número esperado de fallos? ¿Y su
desviación típica?

Como \(X\) sigue una ley \(BN(n=2,p=0.1)\)

\[E(X)=n\cdot \frac{1-p}{p}=2\cdot \frac{1-0.1}{0.1}=18.\]

El número de fallos esperado es 18. La varianza es

\[
Var(X)=n\cdot\frac{1-p}{p^2}=2 \cdot \frac{1-0.1}{0.1^2}=180,
\]

y su desviación típica \(\sqrt{180}=13.41641.\)

\end{Ejemplo}

\subsubsection{\texorpdfstring{Cálculos de la distribución \(BN(n,p)\)
con
R}{Cálculos de la distribución BN(n,p) con R}}\label{cuxe1lculos-de-la-distribuciuxf3n-bnnp-con-r}

La función de \texttt{R} que calcula la función de probabilidad de la
binomial negativa con sus parámetros básicos es:

\begin{verbatim}
dnbinom(x, size, prob,...)`
\end{verbatim}

donde \texttt{size} (\(n\)) es el número de éxitos y \texttt{prob}
(\(p\)), la probabilidad de éxito.

Así en el ejemplo de la puerta con dos cerraduras, \(X\) es una
\(BN(n=size=2,p=prob=0.1)\). Por ejemplo, \(P(X=5)\) que hemos calculado
en el ejemplo anterior, vale:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dnbinom}\NormalTok{(}\DecValTok{5}\NormalTok{,}\AttributeTok{size=}\DecValTok{2}\NormalTok{,}\AttributeTok{p=}\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0354294
\end{verbatim}

De forma similar calculamos calculamos \(P(X\leq 4)\),
\(P(X>4)=1-P(X\leq 4)\) y \(P(X>4)\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnbinom}\NormalTok{(}\DecValTok{4}\NormalTok{,}\AttributeTok{size=}\DecValTok{2}\NormalTok{,}\AttributeTok{p=}\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.114265
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{pnbinom}\NormalTok{(}\DecValTok{4}\NormalTok{,}\AttributeTok{size=}\DecValTok{2}\NormalTok{,}\AttributeTok{p=}\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.885735
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnbinom}\NormalTok{(}\DecValTok{4}\NormalTok{,}\AttributeTok{size=}\DecValTok{2}\NormalTok{,}\AttributeTok{p=}\FloatTok{0.1}\NormalTok{,}\AttributeTok{lower.tail=}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.885735
\end{verbatim}

La función con Python es \texttt{nbinom.pmf(k,\ n,\ p,\ loc)}. Hay que
cargarla desde \texttt{scpi.stats}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ nbinom}
\end{Highlighting}
\end{Shaded}

Recordemos que de nuevo se cumple que

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nbinom.pmf(k, n, p, loc) }\OperatorTok{=}\NormalTok{ nbinom.pmf(k}\OperatorTok{{-}}\NormalTok{loc, n, p)\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nbinom.pmf(k}\OperatorTok{=}\DecValTok{5}\NormalTok{,n}\OperatorTok{=}\DecValTok{2}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.0354294
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nbinom.pmf(k}\OperatorTok{=}\DecValTok{5}\NormalTok{,n}\OperatorTok{=}\DecValTok{2}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.1}\NormalTok{,loc}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.0354294
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nbinom.cdf(k}\OperatorTok{=}\DecValTok{4}\NormalTok{,n}\OperatorTok{=}\DecValTok{2}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.11426500000000002
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{{-}}\NormalTok{nbinom.cdf(k}\OperatorTok{=}\DecValTok{4}\NormalTok{,n}\OperatorTok{=}\DecValTok{2}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.8857349999999999
\end{verbatim}

Generemos 100 observaciones aleatorias de una \(BN(n=2,0.1)\). Es decir
serán las veces que hemos fallado hasta abrir la puerta 100 veces.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nbinom.rvs(n}\OperatorTok{=}\DecValTok{2}\NormalTok{, p}\OperatorTok{=}\FloatTok{0.1}\NormalTok{, size}\OperatorTok{=}\DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
array([ 5,  8, 17, 40, 11, 12,  2, 26, 18, 19, 31, 75, 22, 59,  2, 25, 20,
        6, 22,  8, 21, 27, 17,  7, 35, 37, 12, 16, 40,  3, 15, 22,  4,  1,
        2,  9, 11, 10,  5, 25,  6, 12, 27, 22, 17,  5,  4, 23, 27, 38, 24,
       10,  5,  9,  6, 31, 20,  8, 30,  2, 13, 33, 14,  2,  9, 28, 12, 18,
       10, 13,  9, 34, 23, 23, 13, 11, 22, 16,  1, 19, 15,  9, 18, 37, 15,
       32, 11, 14,  2, 31, 20,  8, 11, 30, 18,  5, 41,  5, 20, 18],
=======
array([ 8, 24,  9, 10, 23,  3,  3, 12,  7, 12, 17, 54, 30, 16, 10, 10, 25,
       10, 19, 13, 16,  8, 31,  7, 11, 26, 11,  9, 23, 39,  6, 64, 20, 18,
       31,  7,  9,  9,  9, 19,  7, 13, 72,  2, 18,  9,  7, 21,  5, 10, 35,
        8, 14,  6, 28,  6, 28, 16, 22, 26, 14, 17, 10, 21, 16, 23, 49, 43,
       66,  3, 16, 14, 18, 14, 20, 17, 45, 22,  3, 27, 47,  7, 32,  5,  1,
       23, 12, 13, 25, 18,  2,  4, 29, 17, 58, 58, 15, 26,  7,  4],
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
      dtype=int64)
\end{verbatim}

\subsubsection{\texorpdfstring{Cálculos de la distribución \(BN(n,p)\)
con
Python}{Cálculos de la distribución BN(n,p) con Python}}\label{cuxe1lculos-de-la-distribuciuxf3n-bnnp-con-python}

La \textbf{esperanza} y la \textbf{varianza}de una \(BN(n=2,0.1)\)
valen:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n, p}\OperatorTok{=}\DecValTok{2}\NormalTok{,}\FloatTok{0.1}
\NormalTok{params }\OperatorTok{=}\NormalTok{ nbinom.stats(n,p,moments}\OperatorTok{=}\StringTok{\textquotesingle{}mv\textquotesingle{}}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"E(X)=}\SpecialCharTok{\{m\}}\StringTok{"}\NormalTok{.}\BuiltInTok{format}\NormalTok{(m}\OperatorTok{=}\NormalTok{params[}\DecValTok{0}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
E(X)=18.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"Var(X)=}\SpecialCharTok{\{v\}}\StringTok{"}\NormalTok{.}\BuiltInTok{format}\NormalTok{(v}\OperatorTok{=}\NormalTok{params[}\DecValTok{1}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Var(X)=179.99999999999997
\end{verbatim}

\subsubsection{Gráficas de la binomial negativa con
R}\label{gruxe1ficas-de-la-binomial-negativa-con-r}

El siguiente código de R dibuja las función de probabilidad y la de
distribución de una \(BN(n=2,p=0.1)\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{aux}\OtherTok{=}\FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{22}\NormalTok{)}
\NormalTok{aux[}\FunctionTok{seq}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{22}\NormalTok{,}\DecValTok{2}\NormalTok{)]}\OtherTok{=}\FunctionTok{dnbinom}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{10}\NormalTok{),}\AttributeTok{size=}\DecValTok{2}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.1}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(}\AttributeTok{x=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{10}\NormalTok{),}\AttributeTok{y=}\FunctionTok{dnbinom}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{10}\NormalTok{),}\AttributeTok{size=}\DecValTok{2}\NormalTok{,}\AttributeTok{prob=}\FloatTok{0.1}\NormalTok{),}
  \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{),}\AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{11}\NormalTok{),}\AttributeTok{xlab=}\StringTok{"x"}\NormalTok{,}
  \AttributeTok{main=}\StringTok{"Función de probabilidad}\SpecialCharTok{\textbackslash{}n}\StringTok{ BN(n=2,p=0.1)"}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\AttributeTok{x=}\FunctionTok{rep}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{10}\NormalTok{,}\AttributeTok{each=}\DecValTok{2}\NormalTok{),}\AttributeTok{y=}\NormalTok{aux, }\AttributeTok{type =} \StringTok{"h"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{,}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{)}
\FunctionTok{curve}\NormalTok{(}\FunctionTok{pnbinom}\NormalTok{(x,}\AttributeTok{size=}\DecValTok{2}\NormalTok{,}\AttributeTok{prob=}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{),}
  \AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{11}\NormalTok{),}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{,}
  \AttributeTok{main=}\StringTok{"Función de distribución}\SpecialCharTok{\textbackslash{}n}\StringTok{ BN(n=2,p=0.1)"}\NormalTok{)}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Y con \texttt{ggplot2}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}

\CommentTok{\# Parámetros de la distribución binomial negativa}
\NormalTok{size }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{prob }\OtherTok{\textless{}{-}} \FloatTok{0.1}
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{0}\SpecialCharTok{:}\DecValTok{10}

\CommentTok{\# Crear dataframes para PMF y CDF}
\NormalTok{df\_pmf }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =} \FunctionTok{dnbinom}\NormalTok{(x, size, prob))}
\NormalTok{df\_cdf }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =} \FunctionTok{pnbinom}\NormalTok{(x, size, prob))}

\CommentTok{\# Gráfico de PMF}
\FunctionTok{ggplot}\NormalTok{(df\_pmf, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.6}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{xend =}\NormalTok{ x, }\AttributeTok{y =} \DecValTok{0}\NormalTok{, }\AttributeTok{yend =}\NormalTok{ y), }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{color =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Función de probabilidad}\SpecialCharTok{\textbackslash{}n}\StringTok{ BN(n=2,p=0.1)"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Número de intentos hasta el segundo éxito"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Probabilidad"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/unnamed-chunk-31-1.pdf}
\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Gráfico de CDF}
\FunctionTok{ggplot}\NormalTok{(df\_cdf, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_step}\NormalTok{(}\AttributeTok{color =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{size =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Función de distribución}\SpecialCharTok{\textbackslash{}n}\StringTok{ BN(n=2,p=0.1)"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Número de intentos hasta el segundo éxito"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Probabilidad acumulada"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/unnamed-chunk-31-2.pdf}
\end{center}

\subsubsection{Gráficos de la binomial negativa con
Python}\label{gruxe1ficos-de-la-binomial-negativa-con-python}

Este es el código con Python que dibuja las función de probabilidad y la
de distribución de una \(BN(n=2,p=0.1)\)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ nbinom}

\CommentTok{\# Parámetros de la distribución binomial negativa}
\NormalTok{n }\OperatorTok{=} \DecValTok{2}  \CommentTok{\# Número de fracasos antes de alcanzar el éxito}
\NormalTok{p }\OperatorTok{=} \FloatTok{0.6}  \CommentTok{\# Probabilidad de éxito en cada intento}

\CommentTok{\# Valores de la variable aleatoria}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{0}\NormalTok{, }\DecValTok{20}\NormalTok{)}

\CommentTok{\# Función de masa de probabilidad (PMF)}
\NormalTok{pdf }\OperatorTok{=}\NormalTok{ nbinom.pmf(x, n, p)}

\CommentTok{\# Función de distribución acumulativa (CDF)}
\NormalTok{cdf }\OperatorTok{=}\NormalTok{ nbinom.cdf(x, n, p)}

\CommentTok{\# Crear la figura y los subgráficos}
\NormalTok{fig, axes }\OperatorTok{=}\NormalTok{ plt.subplots(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{))}

\CommentTok{\# Gráfico de la PMF}
\NormalTok{axes[}\DecValTok{0}\NormalTok{].bar(x, pdf, color}\OperatorTok{=}\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.6}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}PMF\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{0}\NormalTok{].set\_title(}\StringTok{\textquotesingle{}Función de Masa de Probabilidad (PMF) de una Variable Binomial Negativa\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{0}\NormalTok{].set\_xlabel(}\StringTok{\textquotesingle{}Número de intentos hasta el n{-}ésimo éxito\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{0}\NormalTok{].set\_ylabel(}\StringTok{\textquotesingle{}Probabilidad\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{0}\NormalTok{].legend()}
\NormalTok{axes[}\DecValTok{0}\NormalTok{].grid(axis}\OperatorTok{=}\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{, linestyle}\OperatorTok{=}\StringTok{\textquotesingle{}{-}{-}\textquotesingle{}}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.7}\NormalTok{)}

\CommentTok{\# Gráfico de la CDF}
\NormalTok{axes[}\DecValTok{1}\NormalTok{].step(x, cdf, color}\OperatorTok{=}\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, where}\OperatorTok{=}\StringTok{\textquotesingle{}mid\textquotesingle{}}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}CDF\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{1}\NormalTok{].set\_title(}\StringTok{\textquotesingle{}Función de Distribución Acumulada (CDF) de una Variable Binomial Negativa\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{1}\NormalTok{].set\_xlabel(}\StringTok{\textquotesingle{}Número de intentos hasta el n{-}ésimo éxito\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{1}\NormalTok{].set\_ylabel(}\StringTok{\textquotesingle{}Probabilidad acumulada\textquotesingle{}}\NormalTok{)}
\NormalTok{axes[}\DecValTok{1}\NormalTok{].legend()}
\NormalTok{axes[}\DecValTok{1}\NormalTok{].grid(axis}\OperatorTok{=}\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{, linestyle}\OperatorTok{=}\StringTok{\textquotesingle{}{-}{-}\textquotesingle{}}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.7}\NormalTok{)}

\CommentTok{\# Ajustar el layout para evitar solapamientos}
\NormalTok{plt.tight\_layout()}

\CommentTok{\# Mostrar los gráficos}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/unnamed-chunk-32-1.pdf}
\end{center}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/negativa_py_show-3.pdf}
\end{center}

\subsubsection{Caso práctico: Acceso aleatorio a un sistema con triple
clave}\label{caso-pruxe1ctico-acceso-aleatorio-a-un-sistema-con-triple-clave}

\textbf{Sistema con tres claves de acceso}

Supongamos que tenemos un sistema informático tiene un programa de
seguridad que genera accesos con claves de 3 dígitos
\(000,001,\ldots 999\). En total 1000 posibilidades.

Como una clave de tres dígitos es fácil de romper proponemos considerar
tres claves consecutivas de acceso al sistema, cada una de 3 dígitos.

Para acceder al sistema hay que dar las tres claves de forma consecutiva
y por orden.

Es decir hasta que no averiguamos la primera clave no pasamos a la
segunda clave.

Supongamos que cada vez que ponemos las dos claves olvidamos el
resultado y seguimos poniendo claves al azar hasta adivinar la
contraseña.

Así hasta conseguir entrar en el sistema.

Sea \(X\) la v.a. que nos da el número de fallos antes de entrar en el
sistema.

Estamos interesados en modelar este problema. La preguntas son:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  ¿Cuál es la distribución de probabilidad de \(X\), la v.a. que nos da
  el número de fallos antes de acceder al sistema.
\item
  ¿Cuál es la función de probabilidad y de distribución del \(X\)?
\item
  ¿Cuál es la probabilidad de fallar 150 veces antes de acceder en el
  sistema?
\item
  ¿Cuál es la probabilidad de fallar más de 150 veces antes de entrar en
  el sistema?
\item
  ¿Cuál es el número esperado de fallos antes de acceder al sistema? ¿Y
  su varianza?
\end{enumerate}

\textbf{Solución 1.} ¿Cuál es la distribución de probabilidad de \(X\),
la v.a. que nos da el número de fallos antes de acceder al sistema?

Bajo estados condiciones tenemos que la probabilidad de ``éxito'' de
cada intento es \(p=\frac{1}{1000}=0.001\). Y como cada vez
\emph{olvidamos} en los dígitos cada intento será independiente del
anterior.

Así que la variable \(X\) cuenta el número de fracasos independientes
hasta conseguir 3 éxitos en un experimento \(Ber(p=0.001)\) por lo tanto
\(X\) sigue un distribución \(BN(n=3,p=0.001).\)

\textbf{Solución 2.} ¿Cuál es la función de probabilidad y de
distribución del \(X\)

En general la función de probabilidad de una \(BN(n,p)\) es

\[
P_X(X=x)=P(X=x)=
\left\{
\begin{array}{cc} 
{x+n-1\choose n-1} \cdot (1-p)^{x}\cdot p^n & \mbox{si } x=0,1,\ldots \\ 0 & \mbox{en otro caso.}\end{array}\right.
\] En particular la función de probabilidad de una \(BN(n=3,p=0.001)\)
es

\[
P_X(X=x)=P(X=x)=
\left\{
\begin{array}{cc} 
{x+2\choose 2} \cdot 0.999^{x}\cdot 0.001^3 & \mbox{si } x=0,1,2,\ldots \\ 0 & \mbox{en otro caso.}\end{array}\right.
\]

\textbf{Solución 3.} ¿Cuál es la probabilidad de fallar 150 veces antes
de acceder en el sistema?

Nos piden

\[
\scriptsize{P(X=150)= {152\choose 2} \cdot 0.999^{150}\cdot 0.001^3.}
\]

Lo calcularemos operando con R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\DecValTok{152}\NormalTok{,}\DecValTok{2}\NormalTok{)}\SpecialCharTok{*}\FloatTok{0.999}\SpecialCharTok{\^{}}\DecValTok{150}\SpecialCharTok{*}\FloatTok{0.001}\SpecialCharTok{\^{}}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 9.876743e-06
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dnbinom}\NormalTok{(}\DecValTok{150}\NormalTok{,}\AttributeTok{size=}\DecValTok{3}\NormalTok{,}\AttributeTok{p=}\FloatTok{0.001}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 9.876743e-06
\end{verbatim}

\textbf{Solución 3.} ¿Cuál es la probabilidad de fallar 150 veces antes
de acceder en el sistema?

Nos piden, lo resolveremos con Python

\[
P(X=150)= {152\choose 2} \cdot 0.999^{150}\cdot 0.001^3
\]

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{  scipy.special }\ImportTok{import}\NormalTok{ binom}
\NormalTok{binom(}\DecValTok{152}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{*}\FloatTok{0.999}\OperatorTok{**}\DecValTok{150}\OperatorTok{*}\FloatTok{0.001}\OperatorTok{**}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
9.876743459670526e-06
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nbinom.pmf(}\DecValTok{150}\NormalTok{,n}\OperatorTok{=}\DecValTok{3}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.001}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
9.876743459670532e-06
\end{verbatim}

\textbf{Solución 4.} ¿Cuál es la probabilidad de fallar más de 150 veces
antes de entrar en el sistema?

\[P(X>150)=1-P(X\leq 150)\]

Calculemos \(P(X\leq 150)\)

\begin{align*}
P(X\leq 150) =& P(X=0)+P(X=1)+P(X=2)+\ldots+P(X=150)\\
=& \sum_{k=0}^{150} {k+3-1\choose 3-1} \cdot (0.999)^{k}\cdot 0.001^3\ldots 
= \ldots =\ensuremath{5.2320035\times 10^{-4}}
\end{align*}

Con R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnbinom}\NormalTok{(}\DecValTok{150}\NormalTok{,}\DecValTok{3}\NormalTok{,}\FloatTok{0.001}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.0005232003
\end{verbatim}

Con Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nbinom.cdf(}\DecValTok{150}\NormalTok{,n}\OperatorTok{=}\DecValTok{3}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.001}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.0005232003490824064
\end{verbatim}

El valor pedido será pues: \[
P(X>150)=1-P(X\leq 150)=1-\ensuremath{5.2320035\times 10^{-4}}=0.9994768.
\] Vemos que es muy probable que fallemos más de 150 veces antes de
entrar en el sistema.

\textbf{Solución 5.} ¿Cuál es el número esperado de fallos antes de
acceder al sistema? ¿Y su desviación típica?

Tenemos que
\(E(X)=n\cdot \frac{1-p}{p}=3\cdot \frac{1- 0.001}{0.001}=2997\) y
\(Var(X)=n\cdot \frac{1-p}{p^2}=3\cdot \frac{1- 0.001^2}{0.001^2}=\ensuremath{2.997\times 10^{6}}.\)

Con Python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{params }\OperatorTok{=}\NormalTok{ nbinom.stats(n}\OperatorTok{=}\DecValTok{3}\NormalTok{,p}\OperatorTok{=}\FloatTok{0.001}\NormalTok{,moments}\OperatorTok{=}\StringTok{\textquotesingle{}mv\textquotesingle{}}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"E(X) = }\SpecialCharTok{\{m\}}\StringTok{"}\NormalTok{.}\BuiltInTok{format}\NormalTok{(m}\OperatorTok{=}\NormalTok{params[}\DecValTok{0}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
E(X) = 2997.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"Var(X) = }\SpecialCharTok{\{v\}}\StringTok{"}\NormalTok{.}\BuiltInTok{format}\NormalTok{(v}\OperatorTok{=}\NormalTok{params[}\DecValTok{1}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Var(X) = 2997000.0
\end{verbatim}

\subsubsection{Caso práctico: ¿Tres claves de tres dígitos o una de 9
dígitos?}\label{caso-pruxe1ctico-tres-claves-de-tres-duxedgitos-o-una-de-9-duxedgitos}

Supongamos que hemos decidido tener una sola clave de 9 dígitos.
Estudiemos en este caso la variable aleatoria que da el número de fallos
antes de entrar en el sistema y comparemos los resultados.

Como en el caso anteriro supongamos que cada vez que alguien intenta
acceder lo hace con una contraseña al azar pero esta vez con una clave
de 9 dígitos. La probabilidad de éxito será ahora
\(p=\frac{1}{10^{9}}\).

Si llamamos \(X_9\) a la variable aleatoria que nos da el número de
fallos antes de entra en el sistema seguirá una distribución
\(Ge(p=\frac{1}{10^9}=0.000000001)\).

Qué da más seguridad ¿tres claves de tres dígitos o una de 9 dígitos?

Su valor esperado es

\[
E(X_9)=\frac{1-p}{p}=
\frac{1-0.000000001}{0.000000001}=\ensuremath{10\times 10^{8}}.
\]

\(1000 000 000\) son 1000 millones de fallos esperados hasta abrir la
puerta.

Recordemos que con tres contraseñas de 3 dígitos el valor esperado de
fallos es

\[3\cdot \frac{1-0.001}{0.001}=2997.\]

Por lo tanto, desde el punto de vista de la seguridad, es mejor una
clave larga de 9 dígitos que tres cortas si escribimos las contraseñas
al azar.

\section{Distribución de Poisson}\label{distribuciuxf3n-de-poisson}

Diremos que una v.a. discreta \(X\) con \(X(\Omega)=\mathbf{N}\) tiene
distribución de Poisson con parámetro \(\lambda>0\), y lo denotaremos
por \(Po(\lambda)\) si su función de probabilidad es:

\[
P_{X}(x)=P(X=x)=
\left\{\begin{array}{ll}
\frac{\lambda^x}{x!} e^{-\lambda}& \mbox{ si } x=0,1,\ldots\\
0 & \mbox{en otro caso}\end{array}\right..
\]

Usando que el desarrollo en serie de Taylor de la función exponencial es
\[
e^{\lambda}=\sum_{x=0}^{+\infty} \frac{\lambda^x}{x!},
\] es fácil comprobar que la suma de la función de probabilidad en todos
los valores del dominio de \(X\), o sea, los enteros positivos, vale 1.

Además recordemos que dado \(x\in\mathbb{R}-\{0\}\) se tiene que

\[
\lim_{n\to\infty} \left(1+\frac{x}{n}\right)^n=e^x.
\]

Usando la expresión anterior para \(x=-\lambda\), tenemos:

\[
\lim_{n\to\infty} \left(1-\frac{\lambda}{n}\right)^n=\lim_{n\to\infty} 
\left(1+\frac{-\lambda}{n}\right)^n=e^{-\lambda}.
\]

\subsection{La distribución de Poisson como ``límite'' de una
binomial}\label{la-distribuciuxf3n-de-poisson-como-luxedmite-de-una-binomial}

La distribución de Poisson
(\href{https://es.wikipedia.org/wiki/Sim\%C3\%A9on_Denis_Poisson}{Siméon
Denis Poisson}) aparece en el conteo de determinados eventos que se
producen en un intervalo de tiempo o en el espacio.

Supongamos que nuestra variable de interés es \(X\), el número de
eventos en el intervalo de tiempo \((0,t]\), como por ejemplo el número
de llamadas a un \emph{call center} en una hora donde suponemos que se
cumplen las siguientes condiciones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  El número promedio de eventos en el intervalo \((0,t]\) es
  \(\lambda>0\).
\item
  Es posible dividir el intervalo de tiempo en un gran número de
  subintervalos (denotemos por \(n\) al número de intervalos) de forma
  que:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  La probabilidad de que se produzcan dos o más eventos en un
  subintervalo es despreciable.
\item
  El número de ocurrencias de eventos en un intervalo es independiente
  del número de ocurrencias en otro intervalo.
\item
  La probabilidad de que un evento ocurra en un subintervalo es
  \(p_n=\frac{\lambda}{n}\)·
\end{itemize}

Bajo estas condiciones, podemos considerar que el número de eventos en
el intervalo \((0,t]\) será el número de ``éxitos'' en \(n\)
repeticiones independientes de un proceso Bernoulli de parámetro \(p_n\)

Entonces si \(n\to\infty\) y \(p_n\cdot n\) se mantiene igual a
\(\lambda\) resulta que la función de probabilidad de \(X\) se puede
escribir como

\[
\begin{array}{rl}
P(X_n=k)&=\left(\begin{array}{c} n\\ k\end{array}\right) \cdot p_n^k\cdot (1-p_n)^{n-k}
\\
&= {n\choose k}\cdot \left(\frac{\lambda}{n}\right)^{k}\cdot \left(1-\frac{\lambda}{n}\right)^{n-k}\\
&=
\frac{\lambda^k}{k!}\cdot\frac{n!}{(n-k)!\cdot n^k}\cdot
\left(1-\frac{\lambda}{n}\right)^{n}\cdot \left(1-\frac{\lambda}{n}\right)^{-k}.
\end{array}
\]

Si hacemos tender \(n\) hacia \(\infty\), obtenemos: \[
\lim_{n\to \infty} P(X_n=k) = \lim_{n\to \infty} \frac{\lambda^k}{k!}\cdot\frac{n!}{(n-k)!\cdot n^k} \cdot
\left(1-\frac{\lambda}{n}\right)^{n}\cdot \left(1-\frac{\lambda}{n}\right)^{-k}.
\]

Calculemos el límite de algunos de los factores de la expresión

\[
\displaystyle\lim_{n\to \infty}\frac{n!}{(n-k)!\cdot n^k}= \lim_{n\to \infty}\frac{n\cdot (n-1)\cdots (n-k-1)}{n^k}
=\lim_{n\to \infty}\frac{n^{k}+\cdots}{n^k}=1.
\]

\[
\lim_{n\to \infty} \left(1-\frac{\lambda}{n}\right)^{n}=e^{-\lambda}
\]

Y también teniendo en cuanta que \(k\) es constante.

\[
\lim_{n\to \infty} \left(1-\frac{\lambda}{n}\right)^{-k}=\lim_{n\to \infty} 1^{-k}=\lim_{n\to \infty} 1=1.
\]

Para acabar

\[
\displaystyle\lim_{n\to\infty} P(X_n=k)=
\lim_{n\to\infty} \left(\begin{array}{c} n\\ k\end{array}\right)
\cdot p_n^k \cdot (1-p_n)^{n-k}= \frac{\lambda^k}{k!}\cdot 1 \cdot e^{-\lambda}\cdot 1=\frac{\lambda^k}{k!}\cdot e^{-\lambda}.
\]

Lo que confirma que límite de una serie de variables
\(B(n,p_n=\frac{\lambda}{n})\) sigue una ley \(Po(\lambda)\).

\subsection{Procesos de Poisson}\label{procesos-de-poisson}

Lo interesante de las variables Poisson es que podemos modificar (si el
modelo lo permite) el intervalo de tiempo \((0,t]\) en el que contamos
los eventos.

Claro que esto no tiene que poder ser así.

Pero en general si la variable es poisson en \((0,t]\) también lo será
en cualquier subintervalo \((0,t']\) para todo \(t'\) tal que
\(0<t'<t\).

Así que podremos definir una serie de variables \(X_t\) de distribución
\(Po(\lambda\cdot t)\).

Definición procesos de Poisson

Consideremos un experimento \emph{Poisson} con \(\lambda\) igual al
promedio de eventos en una unidad de tiempo (u.t.).

Si \(t\) es una cantidad de tiempo en u.t., la v.a. \(X_{t}\)=numero de
eventos en el intervalo \((0,t]\) es una \(Po(\lambda\cdot t)\).

El conjunto de variables \(\{X_t\}_{t>0}\) recibe el nombre de
\textbf{proceso de Poisson}.

\subsection{\texorpdfstring{Resumen distribución Poisson
\(X\sim Po(\lambda)\)}{Resumen distribución Poisson X\textbackslash sim Po(\textbackslash lambda)}}\label{resumen-distribuciuxf3n-poisson-xsim-polambda}

\renewcommand{\arraystretch}{1.75}
\begin{table}
\centering
\begin{tabular}{|l|}
\hline\rowcolor{LightBlue}
$X$ con distribución Poisson de media o promedio $\lambda$, $Po(\lambda)$
\\\hline
$D_X=\{0,1,\ldots \}$ \\\hline
$P_X(x)=P(X=x)=\left\{\begin{array}{ll} \frac{\lambda^x}{x!}e^{-\lambda} & \mbox{ si } x=0,1,\ldots\\ 0 & \mbox{ en otro caso.}\end{array}\right.$\\\hline
$\scriptstyle F_X(x)=P(X\leq X)=\left\{\begin{array}{ll} 0 & \mbox{si } x<0\\\displaystyle\scriptstyle\sum_{i=0}^{k} P(X=i)= \displaystyle\scriptstyle\sum_{i=0}^{k} \frac{\lambda^i}{i!}\cdot e^{-\lambda} & \mbox{si }\left\{\begin{array}{l}\scriptstyle k\leq x< k+1\\\scriptstyle k=0,1,2,\ldots\end{array}\right.\end{array}\right.$
 \\\hline
$E(X)=\lambda$; $Var(X)=\lambda$\\\hline
\end{tabular}
\end{table}

\subsection{\texorpdfstring{Resumen proceso Poisson
\(X_t\sim Po(\lambda\cdot t)\)}{Resumen proceso Poisson X\_t\textbackslash sim Po(\textbackslash lambda\textbackslash cdot t)}}\label{resumen-proceso-poisson-x_tsim-polambdacdot-t}

\renewcommand{\arraystretch}{1.75}
\begin{table}
\centering
\begin{tabular}{|l|}
\hline\rowcolor{LightBlue}
$X_t=$ número de eventos en el intervalo $(0,t]$ $Po(\lambda\cdot t)$ donde $\lambda$ promedio por u.t. 
\\\hline
$D_X=\{0,1,\ldots \}$ \\\hline
$P_X(x)=P(X=x)=\left\{\begin{array}{ll} \frac{(\lambda\cdot t)^x}{x!}e^{-\lambda\cdot t} & \mbox{ si } x=0,1,\ldots\\ 0 & \mbox{ en otro caso.}\end{array}\right.$\\\hline
$\scriptstyle F_X(x)=P(X\leq X)=\left\{\begin{array}{ll} 0 & \mbox{si } x<0\\\displaystyle\scriptstyle\sum_{i=0}^{k} P(X=i)= \displaystyle\scriptstyle\sum_{i=0}^{k} \frac{(\lambda\cdot t)^i}{i!}\cdot e^{-\lambda\cdot t} & \mbox{si }\left\{\begin{array}{l}\scriptstyle k\leq x< k+1\\\scriptstyle k=0,1,2,\ldots\end{array}\right.\end{array}\right.$

 \\\hline
$E(X)=\lambda\cdot t$; $Var(X)=\lambda\cdot t$\\\hline
\end{tabular}
\end{table}

\subsubsection{Aproximación de la distribución binomial por la
Poisson}\label{aproximaciuxf3n-de-la-distribuciuxf3n-binomial-por-la-poisson}

Bajo el punto de vista anterior y si \(p\) es pequeño y \(n\)
suficientemente grande la distribución \(B(n,p)\) se aproxima a una
\(Po(\lambda=n\cdot p)\).

Existen distintos criterios (ninguno perfecto) de cuando la aproximación
es buena.

Por ejemplo si

\[n\geq 20\mbox{ o mejor }n\geq 30, n\cdot p < 10 \mbox{ y } p\leq 0.05,\]

la aproximación de una \(B(n,p)\) por una \(Po(n\cdot p)\) es buena.
Sobre todo para los valores cercanos a \(E(X)=\lambda\).

Condición deseable \(n\geq 20\), \(n\cdot p < 10\), \(p\leq 0.05\).

\subsection{Caso práctico: Trampa de
insectos}\label{caso-pruxe1ctico-trampa-de-insectos}

\textbf{Ejemplo}: Trampa insectos.

La conocida
\href{https://es.wikipedia.org/wiki/Insecticida_el\%C3\%A9ctrico}{lámpara
antiinsectos o insecticida eléctrico} atrae a los insectos voladores con
una luz ultravioleta y los mata por electrocución.

Consideremos la v.a. \(X\) que cuenta el número de insectos caídos en la
trampa en una hora. Supongamos que el número promedio de insectos que
captura la trampa en una hora es \(E(X)=20\) y que podemos admitir que
\(X\) sigue una ley de probabilidad \(Po(\lambda=20)\).

Nos piden

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Comentar de forma breve si se cumplen intuitivamente las condiciones
  para tener una distribución Poisson.
\item
  Escribir de forma explicita la función de probabilidad y de
  distribución de \(X\).
\item
  Calculad la probabilidad de que en una hora caigan en la trampa
  exactamente 21 insectos.
\item
  Calculad la probabilidad de que en una hora caigan en la trampa al
  menos 6 insectos.
\item
  ¿Cuál es el valor esperando, la varianza y la desviación típica de
  \(X\)?
\end{enumerate}

\textbf{Solución 1.} Comentar de forma breve si se cumplen
intuitivamente las condiciones para tener una distribución Poisson.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  El número promedio de eventos en el intervalo \((0,1]\), una hora es
  \(\lambda=20>0\).
\item
  Es posible dividir el intervalo de tiempo de una hora en un gran
  número de subintervalos (denotemos por \(n\) al número de intervalos)
  de forma que:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  La probabilidad de que se produzcan dos o más electrocuciones un
  subintervalo es despreciable. No es posible que dos mosquitos se
  electrocuten al mismo tiempo.
\item
  El número de ocurrencias, electrocuciones de insectos, en un intervalo
  es independiente del número de electrocuciones en otro intervalo.
\item
  La probabilidad de que un evento ocurra en un subintervalo es
  \(p_n=\frac{\lambda}{n}\)· Podemos dividir los 20 insectos promedio
  entre los \(n\) intervalos (trozo de hora) de forma que
  \(p_n=\frac{\lambda}{n}\).
\item
  Por ejemplo si \(n=60\) tenemos que \(p_n=\frac{20}{60}=\frac{1}{3}\).
  La probabilidad de que en un minuto la trampa chisporrotee es
  \(\frac{1}{3}\).
\end{itemize}

\textbf{Solución 2.} Escribid de forma explicita la función de
probabilidad y de distribución de \(X\).

La distribución de probabilidad de un \(Po(\lambda)\) es

\[
P_X(x)=P(X=x)=\left\{\begin{array}{ll} \frac{\lambda^x}{x!}e^{-\lambda} & \mbox{ si } x=0,1,\ldots\\ 0 & \mbox{ en otro caso.}\end{array}\right.
\]

En nuestro caso, \(\lambda =20\):

\[
P_X(x)=P(X=x)=\left\{\begin{array}{ll}\frac{20^x}{x!}e^{-20} & \mbox{ si } x=0,1,\ldots\\ 0 & \mbox{ en otro caso.}\end{array}\right.
\]

La función de distribución es

\[
F_X(x)=P(X\leq X)=
\left\{\begin{array}{ll} 
0 & \mbox{si } x<0\\
\displaystyle\sum_{i=0}^{k} P(X=i)=\sum_{i=0}^{k}\frac{\lambda^i}{i!}\cdot e^{-\lambda} & \mbox{si }
\left\{\begin{array}{l}
k\leq x< k+1\\k=0,1,2,\ldots
\end{array}
\right.
\end{array}
\right.
\]

En nuestro caso \[
F_X(x)=P(X\leq X)=
\left\{\begin{array}{ll} 
0 & \mbox{si } x<0\\
\displaystyle\sum_{i=0}^{k} P(X=i)=\sum_{i=0}^{k}\frac{20^i}{i!}\cdot e^{-20} & \mbox{si }
\left\{\begin{array}{l}
k\leq x< k+1\\k=0,1,2,\ldots
\end{array}
\right.
\end{array}
\right.
\]

\textbf{Solución 3.} Calculad la probabilidad de que en una hora caigan
en la trampa exactamente 21 insectos.

Nos piden la probabilidad siguiente: \[
P(X=21)=\frac{20^{21}}{21!} e^{-20}=0.0846051.
\]

Para realizar el cálculo anterior, podemos usar \texttt{R} como
calculadora o usar la función \texttt{dpois} que nos calcula la función
de distribución de la variable de Poisson:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{20}\SpecialCharTok{\^{}}\DecValTok{21}\SpecialCharTok{/}\FunctionTok{factorial}\NormalTok{(}\DecValTok{21}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.08460506
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dpois}\NormalTok{(}\DecValTok{21}\NormalTok{,}\AttributeTok{lambda =} \DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.08460506
\end{verbatim}

\textbf{Solución 4.} Calculad la probabilidad de que en una hora caigan
en la trampa al menos 6 insectos.

Nos piden la probabilidad siguiente: \[
\begin{array}{rl}
 P(X\geq 6)&=1- P(X<6)=1-P(X\leq 5)=1-F_X(5)=1-\displaystyle\sum_{x=0}^{5} \frac{20^{x}}{x!}\cdot e^{-20}\\
 &=
 1-\left(\frac{20^{0}}{0!}\cdot e^{-20}+\frac{20^{1}}{1!}\cdot e^{-20}+\frac{20^{2}}{2!}\cdot e^{-20}+\frac{20^{3}}{3!}\cdot e^{-20}+\frac{20^{4}}{4!}\cdot e^{-20}+\frac{20^{5}}{5!}\cdot e^{-20}\right)\\
 &=
 1-e^{-20}\cdot \left(1+20+\frac{400}{4}+\frac{8000}{6}+\frac{160000}{24}+\frac{3200000}{120}\right)\\
 &=
 1-e^{-20} \cdot \left(\frac{1 \cdot 120+20\cdot 120+400\cdot 30+8000\cdot 20+160000\cdot 24+3200000\cdot 1}{120}\right)\\
 &= 1-e^{-20}\cdot\left(\frac{4186520}{120}\right)=1-\ensuremath{7.1908841\times 10^{-5}} =0.9999281.
\end{array}
\]

\textbf{Solución 5.} ¿Cuál es el valor esperado, la varianza y la
desviación típica de \(X\)?

El valor esperado del número de insectos caídos en la trampa en una hora
es

\[E(X)=\lambda=20\]

Su varianza es \[Var(X)=\lambda=20\]

y su desviación típica vale
\[\sqrt{Var(X)}=+\sqrt{\lambda}=+\sqrt{20}=4.47214.\]

\subsection{Cálculos con R}\label{cuxe1lculos-con-r-1}

Consideremos por ejemplo una v.a. \(X\) con distribución
\(Po(\lambda=3)\). Calculemos \(P_X(0)=P(X=0), P_X(1)=P(X=1)\) con
\texttt{R}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dpois}\NormalTok{(}\DecValTok{0}\NormalTok{,}\AttributeTok{lambda =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.04978707
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dpois}\NormalTok{(}\DecValTok{1}\NormalTok{,}\AttributeTok{lambda =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1493612
\end{verbatim}

Si quisiéramos hallar la función de distribución en los mismos valores
anteriores, \(F_X(0)=P(X\leq 0), F_X(1)=P(X\leq 1)\), haríamos lo
siguiente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ppois}\NormalTok{(}\DecValTok{0}\NormalTok{,}\AttributeTok{lambda =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.04978707
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ppois}\NormalTok{(}\DecValTok{1}\NormalTok{,}\AttributeTok{lambda =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1991483
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dpois}\NormalTok{(}\DecValTok{0}\NormalTok{,}\AttributeTok{lambda =} \DecValTok{3}\NormalTok{)}\SpecialCharTok{+}\FunctionTok{dpois}\NormalTok{(}\DecValTok{1}\NormalTok{,}\AttributeTok{lambda =} \DecValTok{3}\NormalTok{) }\DocumentationTok{\#\# es igual a ppois(1,lambda=3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1991483
\end{verbatim}

A continuación, comprobemos que
\(F_X(10)=\sum\limits_{x=0}^{10} P_X(x)\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dpois}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{10}\NormalTok{,}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.0497870684 0.1493612051 0.2240418077 0.2240418077 0.1680313557
 [6] 0.1008188134 0.0504094067 0.0216040315 0.0081015118 0.0027005039
[11] 0.0008101512
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(}\FunctionTok{dpois}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{10}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9997077
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ppois}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9997077
\end{verbatim}

Si quisiéramos generar una secuencia de \(100\) observaciones para una
distribución de Poisson de parámetro \(\lambda=3\), \(Po(3)\),
tendríamos que hacer:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rpois}\NormalTok{(}\AttributeTok{n=}\DecValTok{100}\NormalTok{,}\AttributeTok{lambda =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  [1] 2 5 3 3 2 2 5 2 4 4 2 3 2 2 2 2 2 3 3 5 3 3 2 4 2 3 2 1 1 3 4 6 2 5 3
 [36] 4 1 1 6 3 4 1 4 3 4 3 0 2 1 4 3 0 2 4 2 3 5 2 1 3 3 4 2 5 0 3 1 1 4 6
 [71] 4 5 0 4 0 3 3 3 4 1 2 6 2 2 2 2 1 2 5 2 5 3 7 3 5 2 3 2 1 3
\end{verbatim}

\textbf{Ejercicio de la trampa para insectos (continuación)}

En el ejercicio de la trampa para insectos teníamos que \(X\) es una
\(Po(20)\). Responded con R a la preguntas 3 y 4 de este ejercicio

\textbf{Pregunta 3.} Calculad la probabilidad de que en una hora caigan
en la trampa exactamente 21 insectos.

Recordemos que la probabilidad pedida es \(P(X=21)\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dpois}\NormalTok{(}\DecValTok{21}\NormalTok{,}\AttributeTok{lambda=}\DecValTok{20}\NormalTok{)}\CommentTok{\# P(X=21)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.08460506
\end{verbatim}

\textbf{Pregunta 4.} Calculad la probabilidad de que en una hora caigan
en la trampa al menos 6 insectos.

Recordemos que la probabilidad pedida es
\(P(X\geq 6)=1-P(X<6)=1-P(X\leq 5)\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ppois}\NormalTok{(}\DecValTok{5}\NormalTok{,}\AttributeTok{lambda=}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 7.190884e-05
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{ppois}\NormalTok{(}\DecValTok{5}\NormalTok{,}\AttributeTok{lambda=}\DecValTok{20}\NormalTok{) }\CommentTok{\# es 1{-}P(X\textless{}=5)=P(X\textgreater{}=6)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9999281
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ppois}\NormalTok{(}\DecValTok{5}\NormalTok{,}\AttributeTok{lambda=}\DecValTok{20}\NormalTok{,}\AttributeTok{lower.tail =}\ConstantTok{FALSE}\NormalTok{ ) }\CommentTok{\# acumula hacia arriba }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9999281
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# P(X\textgreater{}5)=P(X\textgreater{}=6)=P(X=6)+P(X=7)+...}
\end{Highlighting}
\end{Shaded}

\subsubsection{Gráficos de la distribución Poisson con
R}\label{gruxe1ficos-de-la-distribuciuxf3n-poisson-con-r}

\begin{center}
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/graficosPOISON-1.pdf}
\end{center}

\subsection{Cálculos con Python}\label{cuxe1lculos-con-python-1}

Sea \(X\) un una v.a. \(Po(\lambda=3)\). Entonces

\(P_X(0)=P(X=0), P_X(1)=P(X=1)\) en este orden son

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ poisson}
\NormalTok{poisson.pmf(}\DecValTok{0}\NormalTok{,mu }\OperatorTok{=} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.049787068367863944
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poisson.pmf(}\DecValTok{1}\NormalTok{,mu }\OperatorTok{=} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.14936120510359185
\end{verbatim}

Sea \(X\) un una v.a. \(Po(\lambda=3)\). Entonces

\(F_X(0)=P(X\leq 0), F_X(1)=P(X\leq 1)\) en este orden son

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poisson.cdf(}\DecValTok{0}\NormalTok{,mu }\OperatorTok{=} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.04978706836786395
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poisson.cdf(}\DecValTok{1}\NormalTok{,mu }\OperatorTok{=} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.1991482734714558
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poisson.pmf(}\DecValTok{0}\NormalTok{,mu }\OperatorTok{=} \DecValTok{3}\NormalTok{)}\OperatorTok{+}\NormalTok{poisson.pmf(}\DecValTok{1}\NormalTok{,mu}\OperatorTok{=} \DecValTok{3}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.1991482734714558
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# es igual a poisson.cdf(1,lambda=3)}
\end{Highlighting}
\end{Shaded}

Por ejemplo podemos comprobar que
\(F_X(10)=\displaystyle\sum_{0}^{10} P_X(x)\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poisson.pmf(}\BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{),mu}\OperatorTok{=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
array([0.04978707, 0.14936121, 0.22404181, 0.22404181, 0.16803136,
       0.10081881, 0.05040941, 0.02160403, 0.00810151, 0.0027005 ])
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{sum}\NormalTok{(poisson.pmf(}\BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{),mu}\OperatorTok{=}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.9988975118698846
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poisson.cdf(}\DecValTok{10}\NormalTok{,mu}\OperatorTok{=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.9997076630493527
\end{verbatim}

En el ejercicio de la trampa para insectos teníamos que \(X\) es una
\(Po(20)\). Responded con Python a la preguntas 3 y 4 de este ejercicio

\textbf{Pregunta 3.} Calculad la probabilidad de que en una hora caigan
en la trampa exactamente 21 insectos.

La respuesta a la pregunta 3 es calcular \(P(X=21)\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poisson.pmf(}\DecValTok{21}\NormalTok{,mu}\OperatorTok{=}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.08460506418293791
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# P(X=21)}
\end{Highlighting}
\end{Shaded}

\textbf{Pregunta 4.} Calculad la probabilidad de que en una hora caigan
en la trampa al menos 6 insectos.

La pregunta 4 nos pide calcular \(P(X\geq 6)=1-P(X\leq 5)\)

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{{-}}\NormalTok{poisson.cdf(}\DecValTok{5}\NormalTok{,mu}\OperatorTok{=}\DecValTok{20}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.9999280911594716
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# es 1{-}P(X\textless{}=5)=P(X\textgreater{}=6)}
\end{Highlighting}
\end{Shaded}

Como ya hemos visto con \texttt{scipy.stats} podemos pedir los momentos
de una variable aleatoria \(Po(3)\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poisson.stats(mu}\OperatorTok{=}\DecValTok{3}\NormalTok{, moments}\OperatorTok{=}\StringTok{\textquotesingle{}mv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
(array(3.), array(3.))
\end{verbatim}

Y también generar secuencias de observaciones aleatorias de una
población \(Po(3)\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poisson.rvs(mu}\OperatorTok{=}\DecValTok{3}\NormalTok{,size}\OperatorTok{=}\DecValTok{40}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
array([5, 5, 1, 2, 4, 0, 0, 5, 4, 2, 2, 6, 2, 5, 4, 4, 2, 6, 3, 2, 6, 1,
       0, 6, 5, 2, 1, 2, 2, 5, 1, 2, 3, 1, 3, 2, 3, 4, 3, 2], dtype=int64)
=======
array([2, 2, 3, 3, 5, 3, 2, 4, 3, 4, 3, 1, 4, 6, 2, 1, 4, 4, 3, 1, 2, 2,
       1, 3, 3, 1, 3, 3, 1, 4, 3, 0, 4, 2, 4, 3, 2, 3, 1, 4], dtype=int64)
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

\subsubsection{Gráficos con Python}\label{gruxe1ficos-con-python}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ax }\OperatorTok{=}\NormalTok{ fig.add\_subplot(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{ax.plot(x, poisson.cdf(x, mu), }\StringTok{\textquotesingle{}bo\textquotesingle{}}\NormalTok{, ms}\OperatorTok{=}\DecValTok{5}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}poisson cdf\textquotesingle{}}\NormalTok{)}
\NormalTok{ax.vlines(x, }\DecValTok{0}\NormalTok{, poisson.cdf(x, mu), colors}\OperatorTok{=}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{, lw}\OperatorTok{=}\DecValTok{2}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.5}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ tick }\KeywordTok{in}\NormalTok{ ax.xaxis.get\_major\_ticks():}
\NormalTok{  tick.label.set\_fontsize(}\DecValTok{5}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ tick }\KeywordTok{in}\NormalTok{ ax.yaxis.get\_major\_ticks():}
\NormalTok{  tick.label.set\_fontsize(}\DecValTok{5}\NormalTok{)}
\NormalTok{fig.suptitle(}\StringTok{\textquotesingle{}Distribucion de Poisson\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/py_poiss2_plot-1.pdf}
\end{center}

\subsection{Caso práctico: Proceso Poisson visera de un
casco}\label{caso-pruxe1ctico-proceso-poisson-visera-de-un-casco}

\textbf{Número de impactos de insectos en la visera de un casco}

Un colega de trabajo, al que llamaremos JG, es muy aficionado a los
grandes premios de velocidad tanto en coches como en motos.

Como es tan aficionado está obsesionado con muchas de las más
extravagantes estadísticas de estos deportes. En particular le
propusimos que estudiara el número de insectos que chocan contra la
visera de un casco de un motorista GP o de un conductor de fórmula 1 .

La idea es que el número de insectos está igualmente repartido por todo
el circuito y de promedio impactan \(\lambda>0\) insectos por minuto.
También es razonable suponer que:

\begin{itemize}
\tightlist
\item
  podemos dividir la superficie de la visera en cuadrados
  suficientemente pequeños de forma que la probabilidad de que caigan
  dos insectos en la misma zona es prácticamente 0.
\item
  la probabilidad de que un insecto impacte en un cuadrado cualquiera de
  la visera es independiente de cualquier otro cuadrado.
\item
  si hemos dividido la visera en \(n\) cuadrados la probabilidad \(p_n\)
  de impacto de un cuadrado vale \(p_n=\frac{\lambda}{n}\).
\end{itemize}

Bajo estas condiciones, si denotamos por \(X_t\) como el número de
insectos que ha impactado en la visera en el intervalo \((0,t]\) (en
\(t\) minutos), podemos afirmar que \(X_t\) es un proceso de Poisson
\(Po(\lambda\cdot t)\).

Supongamos que nos dicen que \(\lambda=3\) insectos por minuto. Entonces
el proceso de poisson \(X_t\) seguirá un ley \(Po(3\cdot t).\)

Ahora estamos en condiciones de preguntar al proceso de Poisson.

¿Cuál es la probabilidad de que en 10 minutos impacten más de 25
insectos?

En este caso \(t=10\) \(X_{10}\)= número de insectos que impactan en 10
minutos, el intervalo \([0,10)\) que sigue una \(P(3\cdot 10=30)\). Por
lo tanto

\[P(X>25)=1-P(X\leq 25)\]

lo resolvemos con R

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{ppois}\NormalTok{(}\DecValTok{25}\NormalTok{,}\AttributeTok{lambda=}\DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.7916426
\end{verbatim}

Otra pregunta interesante es que tengamos que esperar más de 2 minutos
para observar el primer impacto

\[P(X_2=0)=\frac{(3\cdot 2)^0}{0!}\cdot e^{-3\cdot 2}= e^{-6}=0.002479.\]

Con R

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{6}\SpecialCharTok{\^{}}\DecValTok{0}\SpecialCharTok{/}\FunctionTok{factorial}\NormalTok{(}\DecValTok{0}\NormalTok{)}\SpecialCharTok{*}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.002478752
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ppois}\NormalTok{(}\DecValTok{0}\NormalTok{,}\AttributeTok{lambda=}\DecValTok{3}\SpecialCharTok{*}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.002478752
\end{verbatim}

\section{Distribución
hipergeométrica}\label{distribuciuxf3n-hipergeomuxe9trica}

\textbf{Modelo de la distribución hipergeométrica}

Supongamos que disponemos de una urna de de sorteos que contiene \(m\)
bolas blancas y \(n\) bolas rojas.

En total en esta urna hay \(m+n\) bolas, \(m\) blancas y \(n\) rojas. Si
extraemos dos bolas de la urna lo podemos hacer de dos formas:

\begin{itemize}
\tightlist
\item
  Extraer una anotar su color y reponerla. Sacar otra y anotar su color.
  Hemos extraído la bola con reposición.
\item
  Extraer simultáneamente dos bolas (sin reposición) y contar el número
  de bolas blancas.
\end{itemize}

Sea \(X\) es la v.a. que cuenta el número de bolas blancas extraídas.

\begin{itemize}
\tightlist
\item
  En el primer caso, \(X\) es una \(B(n=2,p=\frac{m}{m+n})\) ya que
  consiste en repetir dos veces el mismo experimento de Bernoulli.
\item
  En el segundo caso, \(X\) sigue una distribución hipergeométrica que
  estudiaremos en esta sección.
\end{itemize}

Distribución hipergeométrica

Sean \(n\), \(m\) y \(k\) tres número enteros positivos y tales que
\(k<m+n\).

Consideremos una urna que contiene \(m+n\) bolas de las que \(m\) son
blancas y las restantes \(n\) no (son no blancas).

El número total de bolas es \(m+n\). Extraemos de forma aleatoria \(k\)
bolas de la urna sin reemplazarlas.

Sea \(X\) la v.a. que cuenta el número de bolas blancas extraídas.
Diremos que la distribución de \(X\) es hipergeométrica de parámetros
\(m\), \(n\) y \(k\) y la denotaremos por \(H(m,n,k)\).

Su dominio es

\[D_X=\left\{x\in\mathbf{N}\mid \max\{0,k-n\}\leq x \leq \min\{m,k\}\right\}\]

Para explicarlo, veamos varios ejemplos:

\begin{itemize}
\tightlist
\item
  \(H(m=5,n=2,k=3)\). Tenemos \(m=5\) bolas blancas, \(n=2\) no blancas
  y sacamos \(k=3\) bolas sin reposición.
\item
  En este caso el mínimo de bolas blancas extraídas es \(1=k-n=3-2\), ya
  que sólo hay dos no blancas.
\item
  En cambio, el máximo si es \(k=3\), ya que tenemos bolas blancas de
  ``sobra''.
\end{itemize}

\[D_X=\left\{x\in\mathbf{N}\mid \max\{0,k-n\}\leq x \leq \min\{m,k\}\right\}\]

\begin{itemize}
\item
  \(H(m=2,n=5,k=3)\). Tenemos \(m=2\) bolas blancas, \(n=5\) no blancas
  y sacamos \(k=3\) bolas sin reposición.
\item
  En este caso el mínimo de bolas blancas es \(0\) ya que puedo sacar 3
  no blancas.
\item
  En cambio, el máximo si es \(m=2\), ya que aunque saquemos \(k=3\)
  bolas, al llegar a 2 ya hemos extraído todas las bolas blancas de la
  urna.
\item
  \(H(m=10,n=10,k=3)\). Tenemos \(m=10\) bolas blancas, \(n=10\) no
  blancas y sacamos \(k=3\) bolas sin reposición.
\item
  En este caso podemos obtener desde \(0\) blancas hasta \(k=3\)
  blancas.
\end{itemize}

Su función de probabilidad es:

Su función de probabilidad es: \[
P_{X}(x)=\left\{
\begin{array}{ll}
\frac{\binom{m}{x}\cdot \binom{n}{k-x}}{\binom{m+n}{k}}, & \mbox{ si }
\max\{0,k-n\}\leq x \leq \min\{m,k\}, \mbox { para } x\in \mathbf{N},\\
0, & \mbox{en otro caso.}\end{array}\right.
\]

\textbf{Observación: otras parametrizaciones}

En ocasiones se parametriza una v.a. hipergeométrica mediante \(N=m+n\),
número total de bolas, \(k\), número de extracciones y \(p\),
probabilidad de extraer una bola blanca.

Así podemos \textbf{parametrizar alternativamente} la distribución
hipergeométrica así

\[H(N,k,p)\mbox{ donde } p=\frac{m}{N}.\]

\subsection{\texorpdfstring{Resumen distribución Hipergeométrica
\(H(m,n,k)\)}{Resumen distribución Hipergeométrica H(m,n,k)}}\label{resumen-distribuciuxf3n-hipergeomuxe9trica-hmnk}

\renewcommand{\arraystretch}{1.75}
\begin{table}
\centering
\begin{tabular}{|l|}
\hline\rowcolor{LightBlue}
$X= \left\{\begin{array}{l}
\mbox{número de bolas blancas en $k$ extracciones}\\
\mbox{sin reposición de una urna con} $m$\\
\mbox{bolas blancas y }$n$ \mbox{ negras.}
\end{array}\right.$; $H(m,n,k)$
\\\hline
$D_X=\left\{x\in\mathbb{N}\mid \max\{0,k-n\}\leq x \leq \min\{m,k\}\right\}$\\\hline
$P_X(x)=P(X=x)=\left\{
\begin{array}{ll}
\frac{\binom{m}{x}\cdot \binom{n}{k-x}}{\binom{m+n}{k}}, & \mbox{ si }
\max\{0,k-n\}\leq x \leq \min\{m,k\}, \\
0, & \mbox{en otro caso.}\end{array}\right.$\\\hline
$F_X(x)=P(X\leq x)$.\\\hline
$E(X)=\frac{k\cdot m}{m+n}$; $Var(X)=k\cdot\frac{m}{m+n}\cdot\left(1-\frac{m}{m+n}\right) \cdot\frac{m+n-k}{m+n-1}$
\\\hline
\end{tabular}
\end{table}

\textbf{Urna con bolas blancas y rojas}

Tenemos una urna con 15 bolas blancas y 10 bolas rojas. Extraemos al
azar tres bolas de la urna sin reposición. Sea \(X\) el número de bolas
\textbf{blancas} extraídas. Bajo esta condiciones, la v.a. \(X\) sigue
una ley de distribución \(H(m=15,n=10,k=3)\).

La función de probabilidad es

\[
P_X(x)=P(X=x)=\left\{
\begin{array}{ll}
\frac{\binom{m}{x}\cdot \binom{n}{k-x}}{\binom{m+n}{k}} & \mbox{ si }
\max\{0,k-n\}\leq x \leq \min\{m,k\} \mbox { para } x\in \mathbf{N}\\
0 & \mbox{en otro caso}\end{array}\right.,
\]

\[\mbox{sustituyendo }\scriptsize{
P_X(x)=P(X=x)=\left\{
\begin{array}{ll}
\frac{\binom{15}{x}\cdot \binom{10}{3-x}}{\binom{25}{3}} & \mbox{ si }
0\leq x \leq 3 \mbox { para } x\in \mathbf{N}\\
0 & \mbox{en otro caso}\end{array}\right.
}\]

\subsection{\texorpdfstring{Ejemplo clásico urna \(m=15\) blancas,
\(n=10\) rojas y \(k=3\) extracciones sin
reposición}{Ejemplo clásico urna m=15 blancas, n=10 rojas y k=3 extracciones sin reposición}}\label{ejemplo-cluxe1sico-urna-m15-blancas-n10-rojas-y-k3-extracciones-sin-reposiciuxf3n}

La probabilidad de sacar 2 blancas será

\[
P(X=2)=\frac{\binom{15}{2}\cdot \binom{10}{3-2}}{\binom{25}{3}}
\]

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\FunctionTok{choose}\NormalTok{(}\DecValTok{15}\NormalTok{,}\DecValTok{2}\NormalTok{), }\FunctionTok{choose}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{1}\NormalTok{), }\FunctionTok{choose}\NormalTok{(}\DecValTok{25}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]  105   10 2300
\end{verbatim}

\(P(X=2)=\frac{105\cdot10 }{2300}=0.4565217.\)

La probabilidad de que saquemos más de 1 bola blanca es

\[
\begin{array}{rl}
P(X> 1)&= 1-P(X\leq 1)=1-(P(X=0)+P(X=1))\\
&=
1-\left(\frac{\binom{15}{0}\cdot \binom{10}{3}}{\binom{25}{3}}+
\frac{\binom{15}{1}\cdot \binom{10}{2}}{\binom{25}{3}}\right)\\
&=
1-\left(
\frac{1\cdot120 }{2300}+\frac{15\cdot45 }{2300}
\right)=1-\frac{120+15\cdot 45}{2300}=0.6543478.
\end{array}
\]

El número esperado de bolas blancas extraídas para una v.a. \(X\)
\(H(m=15,n=10,k=3)\) es

\[E(X)=\frac{k\cdot m}{m+n}=\frac{3\cdot 15}{15+10}=\frac{45}{35}=1.285714.\]

La varianza vale: \[
\begin{array}{rl}
Var(X)&=k\cdot\frac{m}{m+n}\cdot\left(1-\frac{m}{m+n}\right) \cdot\frac{m+n-k}{m+n-1}\\
&=3\cdot\frac{15}{15+10}\cdot\left(1-\frac{15}{15+10}\right) \cdot\frac{15+10-3}{15+10-1}\\
&=
3\cdot\frac{15}{25}\cdot\left(1-\frac{15}{25}\right) \cdot\frac{22}{24}= 
3\cdot\frac{15}{25}\cdot\frac{25-15}{25} \cdot\frac{22}{24}\\
&=
3\cdot\frac{15}{25}\cdot\frac{10}{25}\cdot\frac{22}{24}=0.66.
\end{array}
\]

Y por lo tanto su desviación típica es
\(+\sqrt{Var(X)}=+\sqrt{0.66}=0.812404.\)

\subsection{Cálculos con R}\label{cuxe1lculos-con-r-2}

Sea \(X\) una v.a. \(H(m,n,k)\). La función de \texttt{R} para calcular
la función de probabilidad en un valor \(x\), \(P(X=x)\), es
\texttt{dhyper(x,m,n,k)} y para calcular la función de distribución en
un valor \(q\), \(P(X\leq q)\), es \texttt{phyper(q,m,n,k)}. Para
generar una muestra de valores que siga la distribución \(H(m,n,k)\),
hay que usar la función \texttt{rhyper(nn,m,n,k)} donde \texttt{nn} es
el número de observaciones aleatorias deseado de la muestra.

Por ejemplo, si \(X\) es una \(H(m=15,n=10,k=3)\), los valores de
\(P(X=2)\) y que \(P(X>1)=1-P(X\leq 1)\) son:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dhyper}\NormalTok{(}\AttributeTok{x=}\DecValTok{2}\NormalTok{,}\AttributeTok{m=}\DecValTok{15}\NormalTok{,}\DecValTok{10}\NormalTok{,}\AttributeTok{k=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.4565217
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{phyper}\NormalTok{(}\AttributeTok{q=}\DecValTok{1}\NormalTok{,}\AttributeTok{m=}\DecValTok{15}\NormalTok{,}\AttributeTok{n=}\DecValTok{10}\NormalTok{,}\AttributeTok{k=}\DecValTok{3}\NormalTok{)}\CommentTok{\# sí, le han puesto q ya veremos el porqué}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3456522
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{phyper}\NormalTok{(}\AttributeTok{q=}\DecValTok{1}\NormalTok{,}\AttributeTok{m=}\DecValTok{15}\NormalTok{,}\AttributeTok{n=}\DecValTok{10}\NormalTok{,}\AttributeTok{k=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6543478
\end{verbatim}

Una muestra aleatoria de este experimento de tamaño 200 sería:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rhyper}\NormalTok{(}\AttributeTok{nn=}\DecValTok{200}\NormalTok{,}\AttributeTok{m=}\DecValTok{15}\NormalTok{,}\AttributeTok{n=}\DecValTok{10}\NormalTok{,}\AttributeTok{k=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  [1] 2 3 1 3 1 2 2 3 2 2 1 2 1 2 2 3 3 1 1 1 1 0 2 3 2 1 3 2 2 2 2 3 2 3 3
 [36] 2 0 1 2 1 3 2 2 3 2 3 2 2 3 2 3 1 2 2 2 2 3 2 2 1 3 2 2 3 1 2 2 2 2 2
 [71] 3 0 2 0 3 2 2 2 1 2 2 3 1 1 1 2 2 2 2 1 1 3 2 2 3 2 2 1 1 1 3 3 2 2 2
[106] 1 3 2 2 2 1 1 2 3 2 2 1 2 2 2 2 2 2 3 1 2 3 3 1 1 2 2 1 1 3 2 1 1 2 2
[141] 3 1 1 1 2 1 1 3 1 2 2 3 3 2 3 1 2 1 2 2 2 1 2 3 1 3 3 3 2 2 1 3 3 1 1
[176] 2 2 2 2 2 3 2 1 2 1 1 1 1 2 1 1 2 2 2 2 3 3 1 0 2
\end{verbatim}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/unnamed-chunk-52-1.pdf}
\end{center}

\subsection{Cálculos con Python}\label{cuxe1lculos-con-python-2}

Sea \(X\) una \(H(m,n,k)\), las funciones de \texttt{scipy.stats}
cambian los parámetros

\begin{itemize}
\tightlist
\item
  \(M\) es el número total de bolas. Con nuestra parametrización
  \(M=m+n\).
\item
  \(n\) es el número de bolas blancas. Con nuestra parametrización
  \(n=m\).
\item
  \(N\) es el número de extracciones. Con nuestra parametrización
  \(N=k\).
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ hypergeom}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hypergeom.pmf(}\DecValTok{1}\NormalTok{,M}\OperatorTok{=}\DecValTok{15}\OperatorTok{+}\DecValTok{10}\NormalTok{,n}\OperatorTok{=}\DecValTok{15}\NormalTok{,N}\OperatorTok{=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.2934782608695652
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hypergeom.cdf(}\DecValTok{1}\NormalTok{,M}\OperatorTok{=}\DecValTok{15}\OperatorTok{+}\DecValTok{10}\NormalTok{,n}\OperatorTok{=}\DecValTok{15}\NormalTok{,N}\OperatorTok{=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.3456521739130434
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{{-}}\NormalTok{hypergeom.cdf(}\DecValTok{1}\NormalTok{,M}\OperatorTok{=}\DecValTok{15}\OperatorTok{+}\DecValTok{10}\NormalTok{,n}\OperatorTok{=}\DecValTok{15}\NormalTok{,N}\OperatorTok{=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.6543478260869566
\end{verbatim}

Una muestra aleatoria de este experimento sería\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hypergeom.rvs(M}\OperatorTok{=}\DecValTok{15}\OperatorTok{+}\DecValTok{10}\NormalTok{,n}\OperatorTok{=}\DecValTok{15}\NormalTok{,N}\OperatorTok{=}\DecValTok{3}\NormalTok{,size}\OperatorTok{=}\DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
array([1, 1, 1, 2, 2, 3, 2, 1, 3, 3, 0, 3, 2, 2, 1, 3, 3, 2, 1, 3, 3, 2,
       1, 3, 3, 2, 1, 0, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 2, 1, 2, 2, 2, 2,
       1, 3, 1, 3, 2, 1, 2, 0, 1, 3, 1, 1, 2, 1, 2, 1, 2, 0, 1, 2, 1, 1,
       2, 2, 1, 3, 2, 2, 1, 1, 2, 2, 1, 3, 2, 2, 3, 1, 2, 1, 3, 1, 0, 1,
       3, 3, 1, 1, 2, 3, 3, 2, 2, 2, 1, 2], dtype=int64)
=======
array([2, 2, 2, 1, 3, 2, 0, 1, 1, 1, 2, 1, 2, 1, 2, 2, 3, 0, 1, 2, 2, 1,
       3, 0, 2, 1, 2, 2, 2, 1, 2, 3, 3, 1, 3, 0, 1, 3, 2, 2, 2, 1, 0, 2,
       2, 1, 1, 2, 2, 1, 3, 1, 0, 1, 1, 3, 2, 2, 3, 3, 1, 2, 2, 2, 2, 3,
       2, 0, 2, 2, 3, 1, 2, 0, 1, 3, 1, 0, 2, 1, 3, 2, 2, 2, 1, 3, 1, 0,
       1, 3, 0, 3, 1, 2, 2, 3, 2, 3, 2, 2], dtype=int64)
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ hypergeom}
\NormalTok{[M, n, N] }\OperatorTok{=}\NormalTok{ [}\DecValTok{20}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{12}\NormalTok{] }\CommentTok{\#\#20 elementos, 7 del tipo, extraemos 12}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.arange(}\BuiltInTok{max}\NormalTok{(}\DecValTok{0}\NormalTok{, N}\OperatorTok{{-}}\NormalTok{M}\OperatorTok{+}\NormalTok{n),}\BuiltInTok{min}\NormalTok{(n, N))}
\NormalTok{fig }\OperatorTok{=}\NormalTok{plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{5}\NormalTok{, }\FloatTok{2.7}\NormalTok{))}
\NormalTok{\_}\OperatorTok{=}\NormalTok{ax }\OperatorTok{=}\NormalTok{ fig.add\_subplot(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{\_}\OperatorTok{=}\NormalTok{ax.plot(x, hypergeom.pmf(x, M, n, N), }\StringTok{\textquotesingle{}bo\textquotesingle{}}\NormalTok{, ms}\OperatorTok{=}\DecValTok{5}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}hypergeom pmf\textquotesingle{}}\NormalTok{)}
\NormalTok{\_}\OperatorTok{=}\NormalTok{ax.vlines(x, }\DecValTok{0}\NormalTok{, hypergeom.pmf(x, M, n, N), colors}\OperatorTok{=}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{, lw}\OperatorTok{=}\DecValTok{2}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.5}\NormalTok{)}
\NormalTok{\_}\OperatorTok{=}\NormalTok{ax.set\_ylim([}\DecValTok{0}\NormalTok{, }\BuiltInTok{max}\NormalTok{(hypergeom.pmf(x, M, n, N))}\OperatorTok{*}\FloatTok{1.1}\NormalTok{])}
\ControlFlowTok{for}\NormalTok{ tick }\KeywordTok{in}\NormalTok{ ax.xaxis.get\_major\_ticks():}
\NormalTok{  \_}\OperatorTok{=}\NormalTok{tick.label.set\_fontsize(}\DecValTok{5}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ tick }\KeywordTok{in}\NormalTok{ ax.yaxis.get\_major\_ticks():}
\NormalTok{  \_}\OperatorTok{=}\NormalTok{tick.label.set\_fontsize(}\DecValTok{5}\NormalTok{) }
\NormalTok{ax }\OperatorTok{=}\NormalTok{ fig.add\_subplot(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{\_}\OperatorTok{=}\NormalTok{ax.plot(x, hypergeom.cdf(x, M, n, N), }\StringTok{\textquotesingle{}bo\textquotesingle{}}\NormalTok{, ms}\OperatorTok{=}\DecValTok{5}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}hypergeom cdf\textquotesingle{}}\NormalTok{)}
\NormalTok{\_}\OperatorTok{=}\NormalTok{ax.vlines(x, }\DecValTok{0}\NormalTok{, hypergeom.cdf(x, M, n, N), colors}\OperatorTok{=}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{, lw}\OperatorTok{=}\DecValTok{2}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.5}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ tick }\KeywordTok{in}\NormalTok{ ax.xaxis.get\_major\_ticks():}
\NormalTok{  \_}\OperatorTok{=}\NormalTok{tick.label.set\_fontsize(}\DecValTok{5}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ tick }\KeywordTok{in}\NormalTok{ ax.yaxis.get\_major\_ticks():}
\NormalTok{  \_}\OperatorTok{=}\NormalTok{tick.label.set\_fontsize(}\DecValTok{5}\NormalTok{)}
\NormalTok{\_}\OperatorTok{=}\NormalTok{fig.suptitle(}\StringTok{\textquotesingle{}Distribucion Hipergeometrica\textquotesingle{}}\NormalTok{)}
\NormalTok{\_}\OperatorTok{=}\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_1_files/figure-pdf/py_hyper2-1.pdf}
\end{center}

\chapter{Distribuciones notables 2: distribuciones
continuas}\label{distribuciones-notables-2-distribuciones-continuas}

\section{Introducción}\label{introducciuxf3n-2}

En esta segunda parte del tema de distribuciones notables veremos las
distribuciones continuas más usuales: uniforme, exponencial y normal.

El lector debe tener en cuenta que exiten muchas otras distribuciones
que deberá estudiar y algunas ya las hemos visto como la \(\chi^2\)

\section{Distribución uniforme}\label{distribuciuxf3n-uniforme}

\begin{Definicion}{Distribución uniforme}{}

Una v.a. continua \(X\) tiene una distribución uniforme sobre el
intervalo real \((a,b)\) ,con \(a<b\), si su función de densidad es

\[
f_X(x)=\left\{\begin{array}{ll}
\frac1{b-a}, & \mbox{si } a<x<b,\\ 0, & \mbox{en cualquier otro caso.}
\end{array}
\right. 
\]

\end{Definicion}

\begin{Ejercicio}{Ejercicio}{}

Comprobar que el área comprendida entre \(f_X\) y la horizontal vale 1.

\[
\int_{-\infty}^{+\infty} f_x(x)\cdot dx=\int_{a}^{b} \frac{1}{b-a} \cdot dx=\left.\frac{x}{b-a}\right]_{x=a}^{x=b}=\frac{b}{b-a}-\frac{a}{b-a}=
\frac{b-a}{b-a}=1.
\]

\end{Ejercicio}

Ahora calculemos su función de distribución

\[
F_X(x)=\left\{\begin{array}{ll} 0, & \mbox{si } x\leq a,\\
\frac{x-a}{b-a}, & \mbox{si } a<x<b,\\ 1, & \mbox{si } b\leq x.
\end{array}
\right. 
\]

\begin{itemize}
\tightlist
\item
  Si \(x\leq a\), entonces
  \[F_X(x)=\int_{-\infty}^{x} f(t)\cdot dt= \int_{-\infty}^{x} 0\cdot dt.\]
\item
  Si \(a<x<b\) entonces ,
\end{itemize}

\[
\begin{array}{rl}
F_X(x)&=\displaystyle\int_{-\infty}^{x} f(t)\cdot dt= \int_{-\infty}^{a} 0\cdot dt+\int_{a}^{x} \frac1{b-a} \cdot dt\\
&= \displaystyle 0 +\left.\frac{t}{b-a}\right]_{t=a}^{t=x}= \frac{x}{b-a}-\frac{a}{b-a}=\frac{x-a}{b-a}.
\end{array}
\]

\begin{itemize}
\tightlist
\item
  Por último si \(x\geq b\) entonces,
\end{itemize}

\[
\begin{array}{rl}
F_X(x)&=\displaystyle\int_{-\infty}^{x} f(t) dt=\int_{a}^{b} \frac{1}{b-a} dt=
 \left. \frac{t}{b-a} \right]_{t=a}^{t=b}
\\&=\displaystyle \frac{b}{b-a}-\frac{a}{b-a}=\frac{b-a}{b-a}=1.
\end{array}
\]

Denotaremos a la v.a. \(X\) uniforme en el intervalo \((a,b)\) por
\(U(a,b)\).

Calculemos la esperanza de \(X\)

\[
\begin{array}{rl}
E(X)&=\displaystyle\int_{-\infty}^{+\infty} x\cdot f_X(x) dx =\int_{a}^{b} x \cdot \frac{1}{b-a} dx =
\left.\frac{x^2}{2\cdot (b-a)}\right]_{x=a}^{x=b}\\
&=\displaystyle \frac{b^2}{2\cdot (b-a)}-\frac{a^2}{2\cdot (b-a)} =
\frac{b^2-a^2}{2\cdot (b-a)} \\ & =\displaystyle\frac{(b+a)\cdot (b-a)}{2\cdot (b-a)}=
\frac{b+a}{2}.
\end{array}
\]

De cara a calcular su varianza, calculemos primero la esperanza de
\(X^2\):

\[
\begin{array}{rl}
E(X^2)&=\displaystyle\int_{-\infty}^{+\infty} x^2 f_X(x) dx=\int_{a}^{b} x^2 \frac1{b-a}
dx =\left.\frac{x^3}{3\cdot (b-a)}\right]_{x=a}^{x=b} \\
&=\displaystyle\frac{b^3-a^3}{3\cdot (b-a)}=\frac{b^2+ab+a^2}{3}.
\end{array}
\]

\begin{Ejercicio}{Ejercicio}{}

\begin{itemize}
\item
  Demostrad que la igualdad \(b^3-a^3=(b-a)\cdot (b^2+ab+a^2)\) es
  cierta.
\item
  Utilizadla para el cálculo final del valor de \(E(X^2)\).
\end{itemize}

\end{Ejercicio}

Calculemos ahora \(Var(X)\).

\[
\begin{array}{rl}
Var(X)&=\displaystyle E(X^2)-(E(X))^2=\frac{b^2+ab+a^2}3-\left(\frac{b+a}2\right)^2\\&=\displaystyle
\frac{b^2+ab+a^2}{3}-\frac{b^2+2ab+a^2}{4}\\
&=\displaystyle
\frac{4\cdot (b^2+ab+a^2)-3\cdot (b^2+2ab+a^2)}{4\cdot 3}
\\
&=\displaystyle
\frac{b^2-2ab+a^2}{12}=
\frac{(b-a)^2}{12}.
\end{array}
\]

\subsection{\texorpdfstring{Gráficas
\(U(0,1)\)}{Gráficas U(0,1)}}\label{gruxe1ficas-u01}

El código en \texttt{R} para dibujar la función de densidad y la función
de distribución de una distribución \(U(0,1)\) es el siguiente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{a}\OtherTok{=}\DecValTok{0}\NormalTok{;b}\OtherTok{=}\DecValTok{1}
\FunctionTok{curve}\NormalTok{(}\FunctionTok{dunif}\NormalTok{(x,a,b),}\AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(a}\FloatTok{{-}0.25}\NormalTok{,b}\FloatTok{+0.25}\NormalTok{),}\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\FunctionTok{max}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{(b}\SpecialCharTok{{-}}\NormalTok{a)}\SpecialCharTok{+}\FloatTok{0.05}\NormalTok{,}\FloatTok{0.1}\NormalTok{)),}
      \AttributeTok{col=}\StringTok{"blue"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Función densidad  U("}\NormalTok{,a,}\StringTok{","}\NormalTok{,b,}\StringTok{")"}\NormalTok{),}
      \AttributeTok{ylab=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"dunif(x,"}\NormalTok{,a,}\StringTok{", "}\NormalTok{,b,}\StringTok{")"}\NormalTok{)}
\NormalTok{      )}
\FunctionTok{curve}\NormalTok{(}\FunctionTok{punif}\NormalTok{(x,a,b),}\AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(a}\DecValTok{{-}1}\NormalTok{,b}\SpecialCharTok{+}\DecValTok{1}\NormalTok{),}\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\FloatTok{1.1}\NormalTok{),}
      \AttributeTok{col=}\StringTok{"blue"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Función de distribución U("}\NormalTok{,a,}\StringTok{","}\NormalTok{,b,}\StringTok{")"}\NormalTok{),}
      \AttributeTok{ylab=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"punif(x,"}\NormalTok{,a,}\StringTok{", "}\NormalTok{,b,}\StringTok{")"}\NormalTok{,}\AttributeTok{cex.axis=}\FloatTok{0.8}\NormalTok{)}
\NormalTok{      )}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_2_files/figure-pdf/grafica_unif10_vista-1.pdf}
\end{center}

\subsection{Transformación lineal de la v.a.
uniforme}\label{transformaciuxf3n-lineal-de-la-v.a.-uniforme}

Si \(X\) sigue una distribución \(U(a,b)\) entonces
\(Z=\frac{X-a}{b-a}\) sigue una distribución \(U(0,1)\).

\begin{Proposicion}{Propiedad: Transformación lineal de la v.a. uniforme}{}

Sea \(X\) una v.a. \(U(a,b)\)

Si \(scale\not=0\) y \(loc\) son dos constantes reales entonces

\begin{itemize}
\tightlist
\item
  si \(scale>0\), \(T=scale\cdot X+loc\) sigue una ley
  \(U(scale\cdot a +loc,scale\cdot b +loc)\)
\item
  si \(scale<0\), \(T=scale\cdot X+loc\) sigue una ley
  \(U(scale\cdot b +loc,scale\cdot a +loc)\)
\end{itemize}

\end{Proposicion}

\textbf{Demostración}

Supongamos que \(X\) sigue una ley \(U(a,b)\), que \(scale>0\) y que
\(T=scale\cdot X+loc\). Dejamos el caso \(scale<0\) como ejercicio.

La función de distribución de \(X\) es: \[
F_X(x)=P(X\leq x)=\left\{\begin{array}{ll} 0 & \mbox{ si } x\leq a\\
\frac{x-a}{b-a} & \mbox{ si } a\leq x\leq b \\1 & \mbox{ si } b\leq x\end{array}\right.
\]

Si \(T\) vale \(T=scale\cdot X+loc\), su función de distribución será:
\[
\scriptsize
\begin{array}{rl}
F_T(t)&=P(T\leq t)= P(scale\cdot X+ loc\leq t)= P\left(X\leq \frac{t-loc}{scale}\right)=F_X\left(\frac{t-loc}{scale}\right)\\
&=
\left\{\begin{array}{ll} 0, & \mbox{ si } \frac{t-loc}{scale}\leq a\\\frac{\frac{t-loc}{scale}-a}{b-a}, & \mbox{ si } a\leq \frac{t-loc}{scale}\leq b,\\1, & \mbox{ si } b\leq \frac{t-loc}{scale},\end{array}\right.=
\left\{\begin{array}{ll} 0, & \mbox{ si } t\leq scale\cdot a +loc, \\
\frac{t-(scale\cdot a+loc)}{scale\cdot (b-a)}, & \mbox{ si } scale\cdot a+loc \leq t\leq scale\cdot b+loc, \\
1, & \mbox{ si } scale\cdot b+loc\leq t, \end{array}\right.\\
& = 
\left\{\begin{array}{ll} 0, & \mbox{ si } t\leq scale\cdot a +loc, \\
\frac{t-(scale\cdot a+loc)}{scale\cdot b+loc-(scale\cdot a+loc)}, & \mbox{ si } scale\cdot a+loc \leq t\leq scale\cdot b+loc, \\
1, & \mbox{ si } scale\cdot b+loc\leq t,\end{array}\right.
\end{array}
\] por lo que \(T\) sigue una ley
\(U(scale\cdot a +loc,scale\cdot b +loc)\).

\begin{Ejercicio}{Ejercicio}{}

Sea \(X\) una variable \(U(0,1)\) y sea \(T=scale\cdot X+loc\):

\begin{itemize}
\item
  Si \(T\) es \(U(-5,5)\) ¿qué valores toman \(scale\) y \(loc\)?
\item
  Si \(loc=-10\) y \(scale=10\) ¿qué distribución de probabilidad sigue
  \(T\)?
\item
  Si \(loc=0\) y \(scale=-1\) ¿qué distribución probabilidad sigue
  \(T\)?
\end{itemize}

\end{Ejercicio}

\subsection{\texorpdfstring{Resumen v.a. con distribución uniforme,
\(U(a,b)\)}{Resumen v.a. con distribución uniforme, U(a,b)}}\label{resumen-v.a.-con-distribuciuxf3n-uniforme-uab}

\renewcommand{\arraystretch}{1.8}
\begin{table}
\centering
\begin{tabular}{|l|}
\hline\rowcolor{LightBlue}
Distribución uniforme $U(a,b)$
\\\hline
Dominio $D_X=(a,b)$\\\hline
$f_{X}(x)\left\{\begin{array}{ll}\frac1{b-a}, & \mbox{si } a<x<b,\\ 0, & \mbox{en cualquier otro caso.}\end{array} \right.$\\\hline
$F_X(x)=P(X\leq X)=\left\{\begin{array}{ll} 0, & \mbox{ si } x\leq a\\\frac{x-a}{b-a}, & \mbox{ si } a\leq x\leq b,\\1, & \mbox{ si } b\leq x.\end{array}\right.$\\\hline
$E(X)=\frac{a+b}2$; $Var(X)=\frac{(b-a)^2}{12}$
\\\hline
\end{tabular}
\end{table}

\subsection{Cálculos con R}\label{cuxe1lculos-con-r-3}

Sea \(X\) una \(v.a.\) \(U(a,b)\). Las funciones \texttt{dunif(x,a,b)} y
\texttt{punif(x,a,b)} calculan la función de densidad y de distribución
de \(X\) en el valor \(X\). Por ejemplo, para \(a=-1\), \(b=1\) y
\(x=0.5\), los valores \(f_X(x)\) y \(F_X(x)\) valen:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dunif}\NormalTok{(}\AttributeTok{x=}\FloatTok{0.5}\NormalTok{, }\AttributeTok{min=}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\AttributeTok{max=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{punif}\NormalTok{(}\AttributeTok{q=}\FloatTok{0.5}\NormalTok{,}\AttributeTok{min=}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\AttributeTok{max=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.75
\end{verbatim}

La función \texttt{runif(n,a,b)} calcula un muestra de observaciones de
tamaño \(n\) que sigan la distribución \(U(a,b)\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{runif}\NormalTok{(}\AttributeTok{n=}\DecValTok{5}\NormalTok{,}\AttributeTok{min=}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\AttributeTok{max=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
[1] -0.5584915  0.7439996 -0.6570565 -0.8626793 -0.5517519
=======
[1]  0.9418577  0.1963104  0.8987921  0.9943518 -0.4394979
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

Por defecto, el valor de los parámetros \texttt{a} y \texttt{b} son 0 y
1, respectivamente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dunif}\NormalTok{(}\AttributeTok{x=}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{punif}\NormalTok{(}\AttributeTok{q=}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{runif}\NormalTok{(}\AttributeTok{n=}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
[1] 0.4312417 0.7356539 0.9338797 0.9037686 0.9695566
=======
[1] 0.7089507 0.2788081 0.7877320 0.9326447 0.4585226
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

\subsection{Cálculos con Python}\label{cuxe1lculos-con-python-3}

Sea \(X\) una \(v.a.\) \(U(-1,1)\). Tomando como ``base'' la v.a.
\(U(0,1)\), los parámetros \(loc\) y \(scale\) valen: \(loc=-1\) y
\(scale=2,\) ya que como hemos visto \(X=2*U(0,1)-1=U(-1,1)\).

En Python, hay que usar dichos parámetros para calcular la función de
densidad y de distribución:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ uniform}
\NormalTok{uniform.pdf(}\FloatTok{0.5}\NormalTok{,loc}\OperatorTok{={-}}\DecValTok{1}\NormalTok{,scale}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{uniform.ppf(}\FloatTok{0.5}\NormalTok{,loc}\OperatorTok{={-}}\DecValTok{1}\NormalTok{,scale}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.0
\end{verbatim}

Para generar una muestra de valores aleatorios, hay que usar la función
\texttt{uniform.rvs}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{uniform.rvs(size}\OperatorTok{=}\DecValTok{30}\NormalTok{,loc}\OperatorTok{={-}}\DecValTok{1}\NormalTok{,scale}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
array([ 0.33541561, -0.62460112,  0.11166066, -0.3012854 , -0.68287742,
       -0.29995617,  0.39343862,  0.48617175,  0.59662121, -0.5129402 ,
        0.71871414, -0.6925716 ,  0.98039402,  0.98407522, -0.81479936,
       -0.58325134,  0.1046107 ,  0.38884188, -0.4263951 , -0.06706708,
        0.31406986,  0.00689044,  0.6408363 , -0.27444479,  0.69315496,
        0.2068644 ,  0.07141915, -0.16016694,  0.43890956,  0.82267301])
=======
array([-0.45177402, -0.77071255,  0.22521442,  0.72099784, -0.66399182,
       -0.82060828, -0.30217959, -0.57622418, -0.30343533,  0.39245562,
       -0.91227801, -0.40051638, -0.90810392,  0.4786918 ,  0.50422214,
        0.44657054, -0.43264303, -0.92761551,  0.03655001,  0.93008122,
       -0.5782674 ,  0.10712824, -0.75260841,  0.13476907,  0.96169102,
        0.62446193,  0.43341972, -0.36046273,  0.86665433, -0.27432763])
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

Los valores de los parámetros por defecto son \texttt{loc=0,\ scale=1}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{uniform.pdf(}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
1.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{uniform.ppf(}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{uniform.rvs(size}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
array([0.27068656, 0.19860999, 0.91786307, 0.02163124, 0.24503844])
=======
array([0.65645053, 0.35262999, 0.61394266, 0.65135353, 0.85876612])
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

\section{Cuantiles de variables
aleatorias}\label{cuantiles-de-variables-aleatorias}

\begin{Definicion}{Definición Cuantiles}{}

Si \(X\) es una v.a. con dominio \(D_X\) y \(0<p<1\) llamaremos cuantil
de orden \(p\) al menor valor perteneciente al dominio \(x_p\in D_X\)
tal que

\[P(X\leq x_p)\geq p.\]

En \texttt{R}, cada distribución \(X\) tiene la función
\texttt{qX(p,...)} que devuelve precisamente el cuantil \(x_p\) tal que
\(P(X\leq x_p)\geq p.\)

\end{Definicion}

\begin{Ejemplo}{Ejemplo}{}

Consideremos una v.a. \(X\) de distribución \(B(5,0.5)\).

Los cuantiles \(x_{0.3}\), \(x_{0.6}\) y \(x_{0.8}\) son los siguientes:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qbinom}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.3}\NormalTok{,}\FloatTok{0.6}\NormalTok{,}\FloatTok{0.8}\NormalTok{),}\DecValTok{5}\NormalTok{,}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2 3 3
\end{verbatim}

Calculemos a mano, el valor \(x_{0.3}\) y verifiquemos que da el mismo
resultado que nos ha dado \texttt{R}.

La función de distribución de \(X\) es: \[
\small{
F_x(x)=P(X\leq x)=
\left\{
\begin{array}{ll}
0, & x< 0, \\
0.03125, & \mbox{ si } 0 \leq x< 1, \\
0.18750, & \mbox{ si } 1 \leq x< 2, \\
0.50000, & \mbox{ si } 2 \leq x< 3, \\
0.81250, & \mbox{ si } 3 \leq x< 4, \\
0.96875, & \mbox{ si } 4 \leq x< 5, \\
1.00000, & \mbox{ si } 5\leq x. \\
\end{array}
\right.}
\]

El cuantil \(p=0.3\) es el primer valor \(x\in D_X\) tal que
\(F_X(x)=P(X\leq x_{0.3})\geq 0.3\). Mirando la expresión anterior,
comprobamos que \(x_{0.3}=2\) ya que \(F_X(2)=P(X\leq 2)=0.5 \geq 0.3\).

\end{Ejemplo}

\begin{Proposicion}{Cálculo de cuantiles}{}

Dada una variable aleatoria \(X\), si existe la inversa de la función de
distribución de \(X\), \(F_X^{-1}\), el cuantil de orden \(p\) sería el
valor que tiene la función \(F_X^{-1}\) en \(p\): \(x_p=F^{-1}(p)\).

En caso de no existir la inversa, dado \(p\), definimos el conjunto
\(A_p\) como:

\[
A_p =\{x\in\mathbb{R},\ |\ F_X(x)\geq p\}.
\]

Entonces el cuantil \(p\) es el mínimo del conjunto \(A_p\) considerando
sólo valores del dominio de la variable:
\(x_p =\displaystyle\min_{x\in D_X}(A_p)\). Este mínimo siempre existirá
y nos da una fórmula explícita para calcular los cuantiles de cualquier
variable aleatoria.

\end{Proposicion}

\begin{Ejemplo}{Ejemplo: cuantiles en un un dado}{}

Sea \(X\) la variable aleatoria uniforme discreta que nos da el número
de puntos obtenidos en el lanzamiento de un dado (seis caras numeradas
del 1 al 6).

Su dominio es \(D_X=\{1,2,3,4,5,6\}\) y su función de probabilidad es \[
P_X(x)=P(X=x)=
\left\{
\begin{array}{ll}
 \frac{1}{6}, & \mbox{ si } x=1,2,3,4,5,6, \\
0, & \mbox{ en otro caso. }.
\end{array}
\right.
\]

Su función de distribución es:

\[
F_X(x)= P(X\leq x)=
\left\{
\begin{array}{ll}
0, & \mbox{ si } x<1, \\
\frac{k}{6} & \mbox{ si } k\leq x< k+1 \mbox{ para } x= 1,2,3,4,6, \\
 1, & \mbox{si } x \geq 6.
\end{array}
\right.
\]

La función siguiente llamada \texttt{ddado} nos define la función de
probabilidad de \(X\) para un dado de \(n\) caras:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ddado}\OtherTok{=}\ControlFlowTok{function}\NormalTok{(x,}\AttributeTok{n=}\DecValTok{6}\NormalTok{) \{}
  \FunctionTok{sapply}\NormalTok{(x,}\AttributeTok{FUN=}\ControlFlowTok{function}\NormalTok{(x) \{}
    \ControlFlowTok{if}\NormalTok{( x }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n))\{}\FunctionTok{return}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{n)\} }\ControlFlowTok{else}\NormalTok{ \{}\FunctionTok{return}\NormalTok{(}\DecValTok{0}\NormalTok{)\}\})}
\NormalTok{  \}}
\end{Highlighting}
\end{Shaded}

Por ejemplo, el valor de \(P_X(0.5)\) sería:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ddado}\NormalTok{(}\FloatTok{1.5}\NormalTok{,}\AttributeTok{n=}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0
\end{verbatim}

y los valores de \(P_X(i)\) para \(i=1,\ldots 10\) sería:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ddado}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{,}\AttributeTok{n=}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.0000000
 [8] 0.0000000 0.0000000 0.0000000
\end{verbatim}

La función \texttt{pdado} nos da la función de distribución de \(X\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pdado}\OtherTok{=}\ControlFlowTok{function}\NormalTok{(x,}\AttributeTok{n=}\DecValTok{6}\NormalTok{) }
\NormalTok{  \{}
  \FunctionTok{sapply}\NormalTok{(x,}\AttributeTok{FUN=}\ControlFlowTok{function}\NormalTok{(y)\{ }\ControlFlowTok{if}\NormalTok{ (y}\SpecialCharTok{\textless{}}\DecValTok{1}\NormalTok{)\{ }\FunctionTok{return}\NormalTok{(}\DecValTok{0}\NormalTok{)\}}\ControlFlowTok{else}\NormalTok{\{}\ControlFlowTok{if}\NormalTok{(y}\SpecialCharTok{\textgreater{}=}\NormalTok{n)\{}\FunctionTok{return}\NormalTok{(}\DecValTok{1}\NormalTok{)\} }\ControlFlowTok{else}
\NormalTok{  \{}\FunctionTok{return}\NormalTok{(}\FunctionTok{sum}\NormalTok{(}\FunctionTok{ddado}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{(}\FunctionTok{floor}\NormalTok{(y))),}\AttributeTok{n=}\NormalTok{n)))\}\}\})}
\NormalTok{  \}}
\end{Highlighting}
\end{Shaded}

Los valores de \(F_X(i)\) para \(i=0,\ldots, 11\) serían:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pdado}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{11}\NormalTok{,}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.0000000 0.1666667 0.3333333 0.5000000 0.6666667 0.8333333 1.0000000
 [8] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
\end{verbatim}

A continuación, construimos la función \texttt{qdado} que nos calcula el
cuantil \(p\), para \(0\leq p\leq 1\), de la variable \(X\) como el
mínimo de la antiimagen de \(p\) mediante la función de distribución
\(F_X^{-1}(p)\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qdado}\OtherTok{=}\ControlFlowTok{function}\NormalTok{(p,}\AttributeTok{n=}\DecValTok{6}\NormalTok{)\{}
\FunctionTok{sapply}\NormalTok{(p,}\AttributeTok{FUN=}\ControlFlowTok{function}\NormalTok{(}\AttributeTok{pp=}\NormalTok{p,}\AttributeTok{nn=}\NormalTok{n) }
\NormalTok{  \{}
  \ControlFlowTok{if}\NormalTok{(pp}\SpecialCharTok{\textless{}}\DecValTok{0} \SpecialCharTok{|}\NormalTok{ pp}\SpecialCharTok{\textgreater{}}\DecValTok{1}\NormalTok{) \{}\FunctionTok{return}\NormalTok{(}\ConstantTok{NA}\NormalTok{)\}}
  \ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{  aux}\OtherTok{=}\NormalTok{pp}\SpecialCharTok{\textgreater{}=}\FunctionTok{pdado}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n,nn)}
\NormalTok{  aux}
  \FunctionTok{ifelse}\NormalTok{(}\FunctionTok{all}\NormalTok{(}\SpecialCharTok{!}\NormalTok{aux),}\FunctionTok{return}\NormalTok{(}\DecValTok{1}\NormalTok{),}\FunctionTok{return}\NormalTok{(}\FunctionTok{max}\NormalTok{(}\FunctionTok{which}\NormalTok{(pp}\SpecialCharTok{\textgreater{}=}\FunctionTok{pdado}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n,nn)))))\}\}}
\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Efectivamente los cuantiles del dado \(X\) son

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qdado}\NormalTok{(}\FloatTok{1.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qdado}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qdado}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.6}\NormalTok{,}\DecValTok{1}\NormalTok{,}\FloatTok{1.01}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]  1  3  3  6 NA NA
\end{verbatim}

\end{Ejemplo}

\begin{Ejemplo}{Ejemplo: Cuantiles Binomial}{}

Por ejemplo si \(X\) es una \(B(n=10,p=0.3)\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2222}\NormalTok{)}
\NormalTok{(}\AttributeTok{q=}\FunctionTok{runif}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.36765818 0.18187591 0.82617679 0.58497444 0.95886983 0.10179894
 [7] 0.75688767 0.24369144 0.67806543 0.06275295
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qbinom}\NormalTok{(q,}\DecValTok{10}\NormalTok{,}\FloatTok{0.3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 2 2 4 3 6 1 4 2 4 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2222}\NormalTok{)}
\FunctionTok{rbinom}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{0.3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 2 2 4 3 6 1 4 2 4 1
\end{verbatim}

Por ejemplo si \(X\) es una \(BN(n=3,p=0.1)\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2222}\NormalTok{)}
\NormalTok{(}\AttributeTok{q=}\FunctionTok{runif}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.36765818 0.18187591 0.82617679 0.58497444 0.95886983 0.10179894
 [7] 0.75688767 0.24369144 0.67806543 0.06275295
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qnbinom}\NormalTok{(q,}\DecValTok{3}\NormalTok{,}\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 19 12 41 27 61  9 36 15 32  7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2222}\NormalTok{)}
\FunctionTok{rnbinom}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{3}\NormalTok{,}\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 18  9  6 46 66 49 24 44 19 26
\end{verbatim}

\end{Ejemplo}

\section{Distribución exponencial}\label{distribuciuxf3n-exponencial}

La distribución exponencial está asociadad al tiempo que transcurre
entre dos eventos Poisson consecutivos.

Supongamos que tenemos un proceso Poisson con parámetro \(\lambda\) en
una unidad de tiempo.

Dado un tiempo \(t\), definimos \(N_{t}\) como el número de eventos en
el intervalo de tiempo \((0,t]\). La distribución de \(N_t\) es una
\(Po(\lambda\cdot t)\). Consideremos la v.a. \(T\) como el tiempo
transcurrido entre dos eventos Poisson consecutivos.

Sea \(t>0\), entonces

\[
\begin{array}{rl}
P(T>t)&=P(\mbox{Cero eventos en el intervalo}(0,t])\\
&=P(N_{t}=0)=
 \frac{(\lambda t)^0}{0!} e^{-\lambda
 t}=e^{-\lambda t}.
\end{array}
\]

Tomando complementarios, la función de distribución de \(T\) será: \[
F_{T}(t)= P(T\leq t)=1-P(T>t)=\left\{\begin{array}{ll} 0, &\mbox{ si } t\leq 0,\\
 1-e^{-\lambda t},& \mbox{ si } t>0,\end{array}\right.
\]

Para hallar la función de densidad de \(T\), basta derivar la expresión
anterior: \[
f_{T}(t)=\left\{\begin{array}{ll}\lambda \cdot e^{-\lambda t}, & \mbox{ si } t>0,\\
0, & \mbox{ si } t\leq 0. \end{array}\right.
\]

Llamaremos a la variable \(T\) exponencial de parámetro \(\lambda\) y la
denotaremos por \(Exp(\lambda)\).

\subsection{Propiedad de la falta de
memoria}\label{propiedad-de-la-falta-de-memoria-1}

\begin{Proposicion}{Propiedad de la falta de memoria}{}

Sea \(X\) una v.a. \(Exp(\lambda)\) entonces

\[P(X>s+t\big|X>s)=P(X>t)\mbox{ para todo } s,t\in \mathbb{R}\]

\end{Proposicion}

\textbf{Demostración}

Si \(X\) es una v.a. \(Exp(\lambda)\) tenemos que
\(P(X>x)=1-P(X\leq x)=1-(1-e^{-\lambda\cdot x})=e^{-\lambda\cdot x}\)
para todo \(x>0\)

Por tanto, \[
\begin{array}{rl}
P(X>s+t\big|X>s) & =\frac{P(\{X>s+t\}\cap \{X>s\})}{P(X>s)}=\frac{P(X>s+t)}{P(X>s)}=\frac{e^{-\lambda\cdot (s+t)}}{e^{-\lambda\cdot s}}=
\frac{e^{-\lambda\cdot s}\cdot e^{-\lambda\cdot t} }{e^{-\lambda\cdot s}}\\ & =e^{-\lambda\cdot t}=P(X>t).
\end{array}
\]

\begin{Ejemplo}{Ejemplo: El clásico problema del peluquero.}{}

Una pequeña peluquería es regentada por un único peluquero. El peluquero
está esperando al próximo cliente mientras lee el periódico.

Supongamos que \(N_T=\) número de clientes que llegan en el intervalo
\([0,t)\) es una \(Po(\lambda\cdot t)\) entonces la variable \(T=\)
tiempo entre dos clientes consecutivos sigue una ley \(Exp(\lambda)\).

Supongamos que \(t\) se mide en horas y que \(\lambda=4\) es el promedio
de clientes por hora.

En este ejemplo la propiedad de la pérdida de memoria significa que si
el peluquero lleva ya esperando más de \(s>0.25\) un cuarto de hora la
probabilidad de que espere \(t=1/6\) de hora más (10 minutos) no cambia
sigue siendo \(P(T>0.25+1/6|T>0.25)=P(T>1/6).\)

El tiempo esperado (en horas) hasta el siguiente cliente es

\[
E(X)=\frac{1}{\lambda}=\frac{1}{4}=0.25.
\]

y la varianza es

\[
Var(X)=\frac{1}{\lambda^2}=\frac{1}{4^2}=0.0625.
\]

Por último ¿Cuál es la probabilidad de que nuestro peluquero esté sin
clientes (leyendo el periódico) más de 30 minutos (0.5 horas)?

\[
P(X>0.5)=1-P(X\leq 0.5)=1-(1-e^{-4\cdot 0.5 })=e^{-2}=0.1353353.
\]

Si queremos hacer los cálculos con R,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pexp}\NormalTok{(}\FloatTok{0.5}\NormalTok{,}\AttributeTok{rate=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.7768698
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{pexp}\NormalTok{(}\FloatTok{0.5}\NormalTok{,}\AttributeTok{rate=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2231302
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pexp}\NormalTok{(}\FloatTok{0.5}\NormalTok{,}\AttributeTok{rate=}\DecValTok{3}\NormalTok{,}\AttributeTok{lower.tail =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.2231302
\end{verbatim}

\end{Ejemplo}

\subsection{Cálculos con R y Python}\label{cuxe1lculos-con-r-y-python}

La función de densidad, de distribución y la generación aleatoria de
valores de una exponencial, se pueden obtener en R con:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dexp}\NormalTok{(}\FloatTok{0.001}\NormalTok{,}\AttributeTok{rate=}\DecValTok{3}\NormalTok{)}\CommentTok{\# no es una probabilidad es una densidad y puede ser \textgreater{}1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.991013
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pexp}\NormalTok{(}\FloatTok{0.5}\NormalTok{,}\AttributeTok{rate=}\DecValTok{3}\NormalTok{) }\CommentTok{\# P(X\textless{}0.5)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.7768698
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rexp}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{3}\NormalTok{)}\CommentTok{\# ocho tiempos de una exponencial}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.5069426 0.4497573 0.2876943 0.5514840 1.0552252 0.3168070 0.2488148
[8] 0.2377065
\end{verbatim}

Y en Python con:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ expon}
\NormalTok{expon.pdf(}\FloatTok{0.0001}\NormalTok{,scale}\OperatorTok{=} \FloatTok{1.}\OperatorTok{/}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
2.9991001349865014
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{expon.cdf(}\FloatTok{0.5}\NormalTok{,scale}\OperatorTok{=} \FloatTok{1.}\OperatorTok{/}\DecValTok{3}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.7768698398515702
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{expon.rvs(scale}\OperatorTok{=}\FloatTok{1.}\OperatorTok{/}\DecValTok{3}\NormalTok{,size}\OperatorTok{=}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
array([0.29793213, 0.80142213, 0.25189437, 0.41674714, 0.06895067,
       0.19993541, 0.45794563, 0.29778896, 0.17738571, 0.05870628])
=======
array([0.46511086, 0.676244  , 0.16936049, 0.42020546, 1.22093425,
       0.793023  , 0.02083158, 0.09260082, 0.14154005, 0.02614312])
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

\subsection{\texorpdfstring{Resumen v.a. con distribución exponencial
\(Exp(\lambda)\)}{Resumen v.a. con distribución exponencial Exp(\textbackslash lambda)}}\label{resumen-v.a.-con-distribuciuxf3n-exponencial-explambda}

\renewcommand{\arraystretch}{2}
\begin{table}
\centering
\begin{tabular}{|l|}
\hline\rowcolor{LightBlue}
$X$ sigue una distribución $Exp(\lambda)$
\\\hline
$D_X=(0,+\infty)$ \\\hline
$f_{X}(x)=\left\{\begin{array}{ll} \lambda\cdot e^{-\lambda x} & \mbox{ si } x>0\\ 0 & \mbox{ si } x\leq 0 \end{array}\right.$
\\\hline
$F_X(x)=P(X\leq X)= \left\{\begin{array}{ll} 0 &\mbox{si } x\leq 0\\1-e^{-\lambda x}& \mbox{si } x>0\end{array}\right.$
\\\hline
$E(X)=\frac{1}{\lambda}$; $Var(X)=\frac{1}{\lambda^2}$
\\\hline
\end{tabular}
\end{table}

\subsection{\texorpdfstring{Gráficas densidad y distribución
\(Exp(\lambda=10)\)}{Gráficas densidad y distribución Exp(\textbackslash lambda=10)}}\label{gruxe1ficas-densidad-y-distribuciuxf3n-explambda10}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda}\OtherTok{=}\DecValTok{10}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{curve}\NormalTok{(}\FunctionTok{dexp}\NormalTok{(x,}\AttributeTok{rate=}\NormalTok{lambda)}
      \AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.05}\NormalTok{,}\FunctionTok{round}\NormalTok{(}\FunctionTok{qexp}\NormalTok{(}\FloatTok{0.99}\NormalTok{,}\AttributeTok{rate=}\NormalTok{lambda,}\DecValTok{2}\NormalTok{),}\DecValTok{2}\NormalTok{)}\SpecialCharTok{+}\FloatTok{0.25}\NormalTok{),}
      \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\FunctionTok{dexp}\NormalTok{(}\DecValTok{0}\NormalTok{,lambda)}\SpecialCharTok{+}\FloatTok{0.1}\NormalTok{),}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{,}
      \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Función densidad Exp("}\NormalTok{,lambda,}\StringTok{")"}\NormalTok{),}
      \AttributeTok{ylab=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"dexp(x,rate="}\NormalTok{,lambda,}\StringTok{")"}\NormalTok{))}
\FunctionTok{curve}\NormalTok{(}\FunctionTok{pexp}\NormalTok{(x,}\AttributeTok{rate=}\NormalTok{lambda),}\AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.05}\NormalTok{,}\FunctionTok{qexp}\NormalTok{(}\FloatTok{0.999}\NormalTok{,}\DecValTok{10}\NormalTok{)),}
      \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\FloatTok{1.1}\NormalTok{),}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{,}
      \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Función de distribución Exp("}\NormalTok{,lambda,}\StringTok{")"}\NormalTok{),}
      \AttributeTok{ylab=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"pexp(x,rate="}\NormalTok{,lambda,}\StringTok{")"}\NormalTok{))}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_2_files/figure-pdf/unnamed-chunk-20-1.pdf}
\end{center}

\begin{Ejercicio}{Ejercicio}{}

Consultad en el manual de Python
\href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html}{scipy.stats}.

Dibujad la función de densidad y de distribución de una \(Exp(10).\)

\end{Ejercicio}

\begin{Ejercicio}{Ejercicio: las bombillas que no envejecen}{}

Supongamos que compramos una bombilla led que promete un \textbf{valor
esperado} de duración de 10000 (1.14 años) horas de funcionamiento
continuo. Además, nos aseguran que la distribución de \(X\), el número
de horas de funcionamiento continuo de una bombilla led, sigue una ley
exponencial.

\begin{itemize}
\tightlist
\item
  Si \(X\) es \(Exp(\lambda)\) ¿cuál es el valor del parámetro
  \(\lambda\)?.
\item
  ¿Cuál es la probabilidad de que una bombilla led ilumine más de 2
  años?
\item
  Supongamos que ya tengo una bombilla led funcionando 1 año ¿Cuál es la
  probabilidad de que dure dos años más?
\item
  ¿Cuál es la varianza de la duración en horas de este tipo de
  bombillas?
\end{itemize}

\end{Ejercicio}

\section{Distribución normal o
Gaussiana}\label{distribuciuxf3n-normal-o-gaussiana}

Una de las variables aleatorias continua más populares es la llamada
distribución normal o
\href{https://es.wikipedia.org/wiki/Distribuci\%C3\%B3n_normal}{Gaussiana}
.

Distribución normal o de Gauss Diremos que una v.a. \(X\) sigue una ley
normal de parámetros \(\mu\) y \(\sigma\) y la denotaremos por
\(N(\mu,\sigma)\) si tiene por función de densidad:

\[
f_{X}(x)=\frac1{\sqrt{2\cdot\pi\cdot\sigma^2}}
e^{-\frac{1}{2}\cdot\left(\frac{x-\mu}{\sigma}\right)^2},
\] para todo \(x\in \mathbb{R}.\)

La gráfica de esta función de densidad es conocida como \textbf{campana
de Gauss.}

La v.a. normal con \(\mu=0\) y \(\sigma=1\) recibe el nombre de normal
estándar y se suele denotar por la letra \(Z\) normal \(N(0,1)\). El
siguiente código la dibuja.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{curve}\NormalTok{(}\FunctionTok{dnorm}\NormalTok{(x),}
      \AttributeTok{main=}\StringTok{"Función de densidad de una normal estándar"}\NormalTok{,}
      \AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{3.9}\NormalTok{,}\FloatTok{3.9}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\section{Gráfica distribución normal o
Gaussiana}\label{gruxe1fica-distribuciuxf3n-normal-o-gaussiana}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_2_files/figure-pdf/normaldensidad1-1.pdf}
\end{center}

\subsection{Propiedades de la función de densidad de la distribución
normal}\label{propiedades-de-la-funciuxf3n-de-densidad-de-la-distribuciuxf3n-normal}

\begin{Proposicion}{Propiedades de la función de densidad de la distribución normal}{}

Sea \(X\) una v.a. \(N(\mu,\sigma)\) y sea \(f_{X}\) su función de
densidad. Entonces:

\begin{itemize}
\tightlist
\item
  La función \(f_{X}\) verifica todas las propiedades de las funciones
  de densidad: \(f_X(x)>0\), para todo \(x\in\mathbb{R}\) y
  \(\displaystyle\int_{-\infty}^\infty f_X(x)\,dx=1\).
\item
  La función \(f_X(x)\) es simétrica respecto de la recta \(x=\mu\):
  \(f_{X}(\mu-x)=f_{X}(\mu+x)\), para todo \(x\in\mathbb{R}\).
\item
  \(f_{X}\) tiene un único máximo absoluto en \(x=\mu\) que vale
  \(f_X(\mu)=\frac{1}{\sqrt{2\pi\sigma^2}}\).
\item
  Si \(F_{X}\) es la función de distribución de \(X\), entonces
  \(F_{X}(\mu+x)=1-F_{X}(\mu-x)\), para todo \(x\in\mathbb{R}\).
\item
  En particular si \(Z\) es una \(N(0,1)\) entonces
  \(F_{Z}(-x)=1-F_{Z}(x)\), para todo \(x\in\mathbb{R}\).
\item
  \(Z=\frac{X-\mu}{\sigma}\) es una v.a. \(N(0,1)\) y
  \(X=\sigma\cdot Z+\mu\) es una \(N(\mu,\sigma)\) donde \(Z\) es la
  normal estándar.
\end{itemize}

\[
F(x)=\displaystyle\int_{-\infty}^{x} {1\over{\sqrt{2\cdot \pi\cdot\sigma^2}}}
e^{-{1\over 2}{\left({t-\mu}\over{\sigma}\right)}^2} dt.
\]

La función \(F(x)\) no tiene ninguna expresión algebraica ``decente''.
Es por esta razón, y por comodidad, que esta función está tabulada o hay
que calcularla usando un software estadístico.

\end{Proposicion}

\subsection{\texorpdfstring{Resumen v.a. con distribución normal,
\(N(\mu,\sigma)\)}{Resumen v.a. con distribución normal, N(\textbackslash mu,\textbackslash sigma)}}\label{resumen-v.a.-con-distribuciuxf3n-normal-nmusigma}

\renewcommand{\arraystretch}{2}
\begin{table}
\centering
\begin{tabular}{|l|}
\hline\rowcolor{LightBlue}
$X$ sigue una distribución $N(\mu,\sigma)$ \\\hline
$D_X=\mathbb{R}=(-\infty,+\infty)$\\\hline
$f_{X}(x)=\frac{1}{\sqrt{2\pi\cdot\sigma^2}}\cdot e^{\frac{-(x-\mu)^2}{2\cdot \sigma^2}}\mbox{ para todo }x\in \mathbb{R}.$\\\hline
$\displaystyle F_X(x)=P(X\leq X)=\int_{-\infty}^x f_X(t) dt.$\\\hline
$E(X)=\mu$; $Var(X)=\sigma^2.$
\\\hline
\end{tabular}
\end{table}

\subsection{Cálculos con R}\label{cuxe1lculos-con-r-4}

Las funciones que calculan la función de densidad y de distribución de
una variable \(N(\mu,\sigma)\) en un valor \texttt{x} son
\texttt{dnorm(x,mean=mu,sd=sigma)} y \texttt{pnorm(x,mean=mu,sd=sigma)},
respectivamente. Por ejemplo, para una variable
\(X\sim N(\mu=1,\sigma=2)\) la función de densidad \(f_X(2)\) se puede
calcular de la forma siguiente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dnorm}\NormalTok{(}\DecValTok{2}\NormalTok{,}\AttributeTok{mean=}\DecValTok{1}\NormalTok{,}\AttributeTok{sd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1760327
\end{verbatim}

y la función de distribución \(F_X(2) = P(X\leq 2)\) de la forma
siguiente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{2}\NormalTok{,}\AttributeTok{mean=}\DecValTok{1}\NormalTok{,}\AttributeTok{sd=}\DecValTok{2}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6914625
\end{verbatim}

El cuantil \(x_{0.95}\) es el valor que cumple
\(P(X\leq x_{0.95})=0.95\) como

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.95}\NormalTok{,}\AttributeTok{mean=}\DecValTok{1}\NormalTok{,}\AttributeTok{sd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4.289707
\end{verbatim}

Y la generación aleatoria de valores según \(X\) como

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n=}\DecValTok{5}\NormalTok{,}\AttributeTok{mean=}\DecValTok{1}\NormalTok{,}\AttributeTok{sd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]  0.9806747  5.5415845  2.8174087 -2.4085639  0.8920435
\end{verbatim}

\subsection{Cálculos con Python}\label{cuxe1lculos-con-python-4}

De forma la forma habitual importaremos \texttt{norm} de
\texttt{scipy.stas} los parámetros son \texttt{loc} y \texttt{scale} la
media \(\mu\) y la desviación estándar \(\sigma\).

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ norm}
\end{Highlighting}
\end{Shaded}

Por ejemplo para una \(X\sim N(\mu=1,\sigma=2)\), la función de densidad
\(f_X(2)\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{norm.pdf(}\DecValTok{2}\NormalTok{,loc}\OperatorTok{=}\DecValTok{1}\NormalTok{,scale}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.17603266338214976
\end{verbatim}

y la función de distribución \(F_X(2) = P(X\leq 2)\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{norm.cdf(}\DecValTok{2}\NormalTok{,loc}\OperatorTok{=}\DecValTok{1}\NormalTok{,scale}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.6914624612740131
\end{verbatim}

El cuantil \(x_{0.95}\) es el valor que cumple
\(P(X\leq x_{0.95})=0.95\) como

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{norm.ppf(}\FloatTok{0.95}\NormalTok{,loc}\OperatorTok{=}\DecValTok{1}\NormalTok{,scale}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
4.289707253902945
\end{verbatim}

Y la generación aleatoria de valores según \(X\) como

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{norm.rvs(loc}\OperatorTok{=}\DecValTok{1}\NormalTok{,scale}\OperatorTok{=}\DecValTok{2}\NormalTok{,size}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<<<<<< HEAD
array([ 1.32636204,  1.0744936 ,  1.80795114, -1.43822087, -0.40919507])
=======
array([-3.57929946, -3.09487871,  0.91055999, -0.33974444,  0.6312333 ])
>>>>>>> c5bc480895a783fa1264d0ead48dc8d22eb1a858
\end{verbatim}

Consultad
\href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html}{SciPy.org}
para dibujar las funciones de densidad y de distribución con Python.

\subsection{Resumen de la distribución
normal}\label{resumen-de-la-distribuciuxf3n-normal}

\textbf{Propiedades de la función de densidad de la distribución normal}

La función de densidad de la distribución normal tiene las siguientes
propiedades:

\begin{itemize}
\tightlist
\item
  La función \(f_X\) es continua.
\item
  \(\int_{-\infty}^{+\infty} \frac{1}{\sqrt{2\cdot\pi\cdot \sigma^2}}\cdot
  e^{-\frac{1}{2}\cdot \left(\frac{x-\mu}{\sigma}\right)^2} dx =1.\)
  (propiedad de todas las densidades).
\item
  \(f(\mu+x)=f(\mu-x)\).
\item
  \(F(\mu-x)=1-F(\mu+x)\).
\end{itemize}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_2_files/figure-pdf/unnamed-chunk-26-1.pdf}
\end{center}

\begin{itemize}
\tightlist
\item
  \(\lim\limits_{x\to+\infty}f(x)=\lim\limits_{x\to-\infty}f(x)=0\) es
  decir tiene asíntota horizontal a derecha e izquierda.
\item
  \(f\) es estrictamente creciente si \(x<\mu\) y decreciente si
  \(x>\mu\).
\item
  Alcanza el máximo en \(x=\mu\) y en este punto vale
  \(f(\mu)=\frac1{\sqrt{2\pi}\sigma}\)
\item
  Tiene dos puntos de inflexión en \(x=\mu+\sigma\) y en
  \(x=\mu-\sigma\).
\end{itemize}

\begin{center}
\includegraphics[width=0.7\linewidth,height=\textheight,keepaspectratio]{distribuciones_notables_2_files/figure-pdf/unnamed-chunk-27-1.pdf}
\end{center}

\subsection{Transformaciones lineales de variables aleatorias
normales}\label{transformaciones-lineales-de-variables-aleatorias-normales}

\begin{Proposicion}{Propiedad: transformación lineal la distribución normal}{}

Sea \(X\) una variable \(N(\mu,\sigma)\) entonces la variable
\(Y=a X+b\) con \(a\not=0,b\in\mathbb{R}\) tiene distribución
\(N(a\mu+b, |a| \sigma)\)

En particular si \(X\) sigue una \(N(\mu,\sigma)\), tomando
\(a=\frac1{\sigma}\) y \(b=
\frac{-\mu}{\sigma}\) obtenemos la tipificación o estandarización de la
v.a.

\[Z={{X-\mu}\over {\sigma}}\] se distribuye \(N(0,1)\), es decir
\(E(X)=0\) y \(Var(X)=1\).

Esta propiedad es muy útil, ya que utilizándola sólo necesitaremos
tabular la \(N(0,1)\).

Si \(Z\) sigue una distribución \(N(0,1)\) diremos que \(Z\) sigue una
distribución normal estándar.

Por lo tanto podemos calcular cualquier distribución normal desde la
distribución normal estándar:

\[
F_X(x)=F_Z \left(\frac{x-\mu}{\sigma}\right).
\]

\end{Proposicion}

\subsection{Propiedades de la distribución normal
estándar}\label{propiedades-de-la-distribuciuxf3n-normal-estuxe1ndar}

\begin{Proposicion}{Proiedades normal estándar}{}

Sea \(Z\) una \(N(0,1)\).

En este caso, \(\mu=0\) y \(\sigma=1\). Podemos escribir algunas de las
propiedades vistas para una distribución normal cualquiera de la forma
siguiente:

\begin{itemize}
\tightlist
\item
  La propiedad \(f_X(\mu-x)=f_X(\mu+x)\) se traduce a \(f_Z(-x)=f_Z(x)\)
\item
  La propiedad \(F_X(\mu-x)=1-F_X(\mu+x)\) se traduce a
  \(F_Z(-x)=1-F(x).\)
\item
  Dado \(\delta>0\), \[
  P(-\delta\leq Z \leq \delta)=F_{Z}(\delta)-F_{Z}(-\delta)=F_Z(\delta)-(1-F_Z(\delta))=
  2\cdot F_Z(\delta)-1.
  \]
\end{itemize}

\end{Proposicion}

\begin{Ejercicio}{Ejercicio}{}

Cálculos con la distribución normal estándar

Sea \(Z\) una distribución \(N(0,1)\), calcular las siguientes
probabilidades en función de \(F_Z\).

\begin{itemize}
\tightlist
\item
  \(P(-4\leq Z \leq 4).\)
\item
  \(P(-2\leq Z \leq 2).\)
\item
  \(P(Z\leq -2).\)
\item
  \(P( Z \leq 2).\)
\item
  \(P( Z \geq 2).\)
\item
  \(P( Z > 2).\)
\item
  \(P( Z = 2).\)
\item
  \(P( Z \geq -2).\)
\end{itemize}

Resolución:

\begin{itemize}
\tightlist
\item
  \(P(-4\leq Z \leq 4)=F_{Z}(4)-F_{Z}(-4)=2\cdot F_Z(4)-1\).
\item
  \(P(-2\leq Z \leq 2)=F_{Z}(2)-F_{Z}(-2)=2\cdot F_Z(2)-1\).
\item
  \(P(Z\leq -2)=F_Z(-2)=1-F_Z(2)\).
\item
  \(P( Z \leq 2)=F_{Z}(2)\).
\item
  \(P( Z \geq 2)=1-P(Z<2)=1-F_{Z}(2)\).
\item
  \(P( Z > 2)=1-P(Z\leq 2)=1-F_{Z}(2)\).
\item
  \(P( Z = 2)=0\) ya que es una distribución continua.
\item
  \(P( Z \geq -2)=1-P(Z< -2)=1-F_{Z}(-2)=1-(1-F_Z(2))=F_Z(2).\)
\end{itemize}

\end{Ejercicio}

\subsection{Relación entre una distribución normal y la normal
estándar}\label{relaciuxf3n-entre-una-distribuciuxf3n-normal-y-la-normal-estuxe1ndar}

Para hallar la probabilidad de que \(X\) esté en un intervalo \((a,b)\)
cualquiera, podemos usar la función de distribución de \(Z\) de la
siguiente manera: \[
\begin{array}{ll}
P(a<X<b)&=P\left(\frac{a-\mu}{\sigma}<\frac{X-\mu}{\sigma}<\frac{b-\mu}{\sigma}\right)= \\
&=P\left(\frac{a-\mu}{\sigma}<Z<\frac{b-\mu}{\sigma}\right)=F_{Z}\left(\frac{b-\mu}{\sigma}\right)-
F_{Z}\left(\frac{a-\mu}{\sigma}\right).
\end{array}
\]

Para el caso particular en que el intervalo esté centrado en la media
\(\mu\), o sea existe un valor \(\delta>0\) tal que
\((a,b)=(\mu-\delta,\mu+\delta)\), obtenemos: \[
P\left(\mu-\delta\leq X \leq\mu+\delta\right)=2\cdot F_Z\left(\frac{\delta}{\sigma}\right)-1.
\]

\subsection{Ejemplo cálculo probabilidades
normal}\label{ejemplo-cuxe1lculo-probabilidades-normal}

\begin{Ejercicio}{Ejercicio}{}

Sea \(X\) una normal con media \(2\) y varianza \(4\). Calcular

\begin{itemize}
\tightlist
\item
  \(P(1< X< 2).\)
\item
  \(P(X>3).\)
\end{itemize}

\textbf{Solución}

La primera probabilidad se calcula de la forma siguiente: \[
\begin{array}{ll}
P(1< X< 2)&= P\left(\frac{1-2}{2}<\frac{X-2}{2}<\frac{2-2}{2}\right)= P\left(\frac{-1}{2}<Z<0\right)\\
&= F_{Z}(0)-F_{Z}(-0.5)=\frac12-1+F_{Z}(0.5)=-\frac12+F_Z(0.5).
\end{array}
\]

La segunda probabilidad se calcular de la forma siguiente: \[
P(X>3)=P\left(\frac{X-2}2>\frac{3-2}{2}\right)=P(Z>0.5)=1-F_{Z}(0.5).
\]

\end{Ejercicio}

\begin{Ejercicio}{Ejercicio}{}

Sea \(X\) una normal con media \(2\) y varianza \(4\). Calcular con R y
con Python las probabilidades

\begin{itemize}
\tightlist
\item
  \(P(1< X< 2).\)
\item
  \(P(X>3).\)
\end{itemize}

\textbf{Solución con R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{2}\NormalTok{,}\AttributeTok{mean=}\DecValTok{2}\NormalTok{,}\AttributeTok{sd=}\DecValTok{2}\NormalTok{)}\SpecialCharTok{{-}}\FunctionTok{pnorm}\NormalTok{(}\DecValTok{1}\NormalTok{,}\AttributeTok{mean=}\DecValTok{2}\NormalTok{,}\AttributeTok{sd=}\DecValTok{2}\NormalTok{) }\CommentTok{\#P(1\textless{} X\textless{} 2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.1914625
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{3}\NormalTok{,}\AttributeTok{mean=}\DecValTok{2}\NormalTok{,}\AttributeTok{sd=}\DecValTok{2}\NormalTok{,}\AttributeTok{lower.tail =}\ConstantTok{FALSE}\NormalTok{) }\CommentTok{\#P(X\textgreater{}3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3085375
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{pnorm}\NormalTok{(}\DecValTok{3}\NormalTok{,}\AttributeTok{mean=}\DecValTok{2}\NormalTok{,}\AttributeTok{sd=}\DecValTok{2}\NormalTok{,}\AttributeTok{lower.tail=}\ConstantTok{TRUE}\NormalTok{) }\CommentTok{\#P(X\textgreater{}3) = 1{-}P(X\textless{}=3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.3085375
\end{verbatim}

\textbf{Solución con Python}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{norm.cdf(}\DecValTok{2}\NormalTok{,loc}\OperatorTok{=}\DecValTok{2}\NormalTok{,scale}\OperatorTok{=}\DecValTok{2}\NormalTok{)}\OperatorTok{{-}}\NormalTok{norm.cdf(}\DecValTok{1}\NormalTok{,loc}\OperatorTok{=}\DecValTok{2}\NormalTok{,scale}\OperatorTok{=}\DecValTok{2}\NormalTok{) }\CommentTok{\#P(1\textless{} X\textless{} 2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.19146246127401312
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{{-}}\NormalTok{norm.cdf(}\DecValTok{3}\NormalTok{,loc}\OperatorTok{=}\DecValTok{2}\NormalTok{,scale}\OperatorTok{=}\DecValTok{2}\NormalTok{) }\CommentTok{\#P(X\textgreater{}3) = 1{-}P(X\textless{}=3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0.3085375387259869
\end{verbatim}

\end{Ejercicio}

\section{La distribución normal aproxima otras
distribuciones}\label{la-distribuciuxf3n-normal-aproxima-otras-distribuciones}

En los temas que siguen veremos como, bajo determinadas condiciones,

\begin{itemize}
\tightlist
\item
  la distribución normal puede aproximar la distribución binomial,
\item
  la distribución normal puede aproximar la distribución Poisson
\item
  la distribución normal es la distribución límite de la media
  aritmética de una muestra de variables aleatorias.
\end{itemize}




\end{document}
