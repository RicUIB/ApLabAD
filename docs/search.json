[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ApLabAD",
    "section": "",
    "text": "Prefacio\nEste libro en la web es una versión de las notas de clase de asignaturas introductorias al análisis de datos.\n\nHa sido elaborado con Quarto\n\nRStudio, PBC. (2022). Quarto (Version 1.0). Hemos utilizado el formato formato book.\n\n\n¿Quarto book o bookdown? https://yihui.org/en/2022/04/quarto-r-markdown/",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "probabilidad_y_variables_aleatorias.html",
    "href": "probabilidad_y_variables_aleatorias.html",
    "title": "Parte 1: Probabilidad y variables aleatorias",
    "section": "",
    "text": "En esta sección, veremos la teoría básica de la probabilidad y de las variables aleatorias. Resolveremos problemas prácticos para comprender mejor los conceptos y utilizaremos R para realizar cálculos y gráficos.\nTambién exploraremos los modelos de probabilidad discretos y continuos más conocidos.\nEn ocasiones, trabajaremos con problemas de cálculo más complejos.\nAdemás, introduciremos problemas sencillos de modelización con probabilidades. Estos consistirán en un enunciado, real o inventado, en el que se pedirá modelizar el problema mediante una variable aleatoria y responder a una serie de preguntas.",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias"
    ]
  },
  {
    "objectID": "preliminares.html",
    "href": "preliminares.html",
    "title": "1  Preliminares: conjuntos y combinatoria",
    "section": "",
    "text": "1.1 Teoría de conjuntos\nPara aprender cálculo de probabilidades son necesarios conocimientos de:\nPor experiencia sabemos que la mayoría de estudiantes tienen más conocimientos de cálculo, geometría y matrices.\nPero muchos tienen una falta de conocimientos en teoría básica de conjuntos y combinatoria (matemática discreta).\nLa definición de conjunto es una idea o noción primitiva. Es decir es una idea básica del pensamiento humano: un conjunto es una colección de objetos: números, imágenes… cualquier cosa, jugadores de fútbol, palabras, colores ….\nLa teoría de conjuntos básicas es simple y natural y es la que necesitamos para este curso.\nLa teoría de conjuntos matemática es más compleja y presenta varias paradojas como la paradoja de Russell.\nLa idea o noción práctica de conjunto es la de una colección de objetos de un cierto tipo.\nEstas colecciones o conjuntos se pueden definir por:",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preliminares: conjuntos y combinatoria</span>"
    ]
  },
  {
    "objectID": "preliminares.html#teoría-de-conjuntos",
    "href": "preliminares.html#teoría-de-conjuntos",
    "title": "1  Preliminares: conjuntos y combinatoria",
    "section": "",
    "text": "Definición de conjunto\n\n\nLa definición de conjunto es una idea o noción primitiva. Es decir es una idea básica del pensamiento humano: un conjunto es una colección de objetos: números, imágenes… cualquier cosa, jugadores de fútbol, palabras, colores ….\n\n\n\n\n\n\n\n\nComprensión: reuniendo los objetos que cumplen una propiedad \\(p\\)\nExtensión: dando una lista exhaustiva de los miembros del conjunto\n\n\n1.1.1 Conjuntos básicos\nLos conjuntos suelen tener un conjunto madre como por ejemplo\n\n\\(\\mathbb{N}=\\{0,1,2,\\ldots\\}\\)\n\\(\\mathbb{Z}=\\{\\ldots,-2,-1,0,1,2,\\ldots\\}\\)\n\\(\\mathbb{Q}=\\left\\{\\frac{p}{q}\\quad\\Big|\\quad p,q\\in \\mathbb{Z} \\mbox{ y } q \\not= 0.\\right\\}\\)\n\\(\\mathbb{R}=\\{\\mbox{Todos los puntos de una recta.}\\}\\)\n\\(\\mathbb{C}= \\left\\{a+b\\cdot i\\quad \\big|\\quad a,b\\in \\mathbb{R}\\right\\}\\mbox{ los números complejos}\\quad a+b\\cdot i.\\)\nAlfabeto = \\(\\{a,b,c,\\ldots, A,B,C,\\ldots\\}.\\)\nPalabras = \\(\\{paz, guerra, amor, probabilidad,\\ldots\\}.\\)\n\nRecordemos que \\(i\\) es la unidad imaginaria que cumple que \\(i=\\sqrt{-1}\\).\n\n\n1.1.2 Características y propiedades básicas de los conjuntos\nSi a cada objeto \\(x\\) de \\(\\Omega\\) le llamaremos elemento del conjunto \\(\\Omega\\) y diremos que \\(x\\) pertenece a \\(\\Omega\\). Lo denotaremos por \\(x\\in \\Omega\\).\nUn conjunto de un elemento, por ejemplo \\(\\{1\\}\\) recibe el nombre de conjunto elemental (o singleton del inglés).\nSea \\(A\\) otro conjunto diremos que \\(A\\) es igual a \\(B\\) si todos los elementos \\(A\\) están en \\(B\\) y todos los elementos de \\(B\\) están en \\(A\\). Por ejemplo \\(A=\\{1,2,3\\}\\) es igual a \\(B=\\{3,1,2\\}\\).\nSi \\(B\\) es otro conjunto, tal que si \\(x\\in A\\) entonces \\(x\\in B\\) diremos que \\(A\\) es un subconjunto de o que está contenido en \\(B\\). Lo denotaremos por \\(A\\subseteq B.\\)\nEl conjunto que no tiene elementos se denomina conjunto vacío y se denota por el símbolo \\(\\emptyset\\). Dado \\(A\\) un conjunto cualquiera obviamente \\(\\emptyset\\subseteq A.\\)\n\n\n Ejemplo\n\n\nTomemos como conjunto base \\(\\Omega=\\{1,2,3\\}\\)\n\n\\(\\Omega\\) es un conjunto de cardinal 3, se denota por \\(\\#(\\Omega)=3\\) o por \\(|\\Omega|=3\\)\nEl conjunto \\(\\Omega\\) tiene \\(2^3=8\\) subconjuntos.\n\nel vacío \\(\\emptyset\\) y los elementales \\(\\{1\\},\\{2\\},\\{3\\}\\)\nlos subconjuntos de dos elementos: \\(\\{1,2\\},\\{1,3\\},\\{2,3\\}\\)\nel conjunto total de tres elementos \\(\\Omega=\\{1,2,3\\}.\\)\n\n\n\n\nDado un conjunto \\(\\Omega\\) podemos construir el conjunto de todas sus partes (todos sus subconjuntos) al que denotamos por \\(\\mathcal{P}(\\Omega)\\). También se denomina de forma directa partes de \\(\\Omega\\).\n Cardinal de las partes de un conjunto \n\n\nPropiedad\n\n\nPor ejemplo \\(\\#\\left(\\mathcal{P}(\\{1,2,3\\})\\right)=2^{\\#(\\{1,2,3\\})}=2^3=8.\\)\n\n\nEfectivamente\n\\[\\mathcal{P}(\\{1,2,3\\})=\\{\\emptyset,\\{1\\},\\{2\\},\\{3\\},\\{1,2\\},\\{1,3\\},\\{2,3\\},\\{1,2,3\\}\\}.\\]\nDado un subconjunto \\(A\\) de \\(\\Omega\\) podemos construir la función característica de \\(A\\) \\[\\chi_A:\\Omega \\to \\{0,1\\}\\]\ndado un \\(\\omega\\in \\Omega\\)\n\\[\n\\chi_A(\\omega)=\n\\left\\{\n\\begin{array}{ll}\n1 &  \\mbox{si }\\omega \\in A\\\\\n0 &  \\mbox{si }\\omega \\not\\in A\n\\end{array}\n\\right.\n\\]\n\n\n1.1.3 Operaciones entre conjuntos\n\n\n Intersección\n\n\nSea \\(\\Omega\\) un conjunto y \\(A\\) y \\(B\\) dos subconjuntos de \\(\\Omega\\).\nEl conjunto intersección de \\(A\\) y \\(B\\) es el formado por todos los elementos que perteneces a \\(A\\) Y \\(B\\), se denota por \\(A\\cap B\\).\nMás formalmente\n\\[\nA\\cap B=\\left\\{x\\in\\Omega \\big| x\\in A \\mbox{ y } x\\in B\\right\\}.\n\\]\n\n\n \n\n\n Unión\n\n\nEl conjunto unión de \\(A\\) y \\(B\\) es el formado por todos los elementos que perteneces a \\(A\\) O pertenecen a \\(B\\), se denota por \\(A\\cup B\\).\nMás formalmente\n\\[\nA\\cup B=\\left\\{x\\in\\Omega \\big| x\\in A \\mbox{ o } x\\in B\\right\\}.\n\\]\n\n\n \n\n\n Diferencia.\n\n\nEl conjunto diferencia de \\(A\\) y \\(B\\) es el formado por todos los elementos que perteneces a \\(A\\) Y NO pertenecen a \\(B\\), se denota por \\(A-B=A-(A\\cap B)\\).\nMás formalmente\n\\[\nA- B=\\left\\{x\\in\\Omega \\big| x\\in A \\mbox{ y } x\\notin B\\right\\}.\n\\]\n\n\n \n\n\n Complementario\n\n\nEl complementario de un subconjunto \\(A\\) de \\(\\Omega\\) es \\(\\Omega-A\\) y se denota por \\(A^c\\) o \\(\\overline{A}\\).\nMás formalmente\n\\[\nA^c=\\left\\{x\\in\\Omega \\big| x\\not\\in A\\right\\}.\n\\]\n\n\n\n\n1.1.4 Más propiedades\nSea \\(\\Omega\\) un conjunto y \\(A\\), \\(B\\), \\(C\\) tres subconjuntos de \\(\\Omega\\)\n\nSe dice que dos conjuntos \\(A\\) y \\(B\\) son disjuntos si \\(A\\cap B=\\emptyset.\\)\n\\(\\Omega^c=\\emptyset\\).\n\\(\\emptyset^c=\\Omega\\).\n\\(A\\cup B=B \\cup A\\) , \\(A\\cap B=B\\cap A\\) conmutativas.\n\\((A\\cup B) \\cup C = A \\cup( B \\cup C)\\), \\((A\\cap B) \\cap C = A \\cap( B \\cap C)\\) asociativas.\n\\(A\\cup (B\\cap C)=(A\\cup B) \\cap (A\\cup C)\\), \\(A\\cap (B\\cup C)=(A\\cap B) \\cup (A\\cap C)\\) distributivas.\n\\(\\left(A^c\\right)^c=A\\) doble complementario.\n\\(\\left(A\\cup B\\right)^c=A^c \\cap B^c\\), \\(\\left(A\\cap B\\right)^c=A^c \\cup B^c\\) leyes de De Morgan.\n\n\n\n1.1.5 Con R, ejemplos.\nCon R los conjuntos de pueden definir como vectores\n\nOmega=c(1,2,3,4,5,6,7,8,9,10)\nA=c(1,2,3,4,5)\nB=c(1,4,5)\nC=c(4,6,7,8)\nOmega\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\nA\n\n[1] 1 2 3 4 5\n\nB\n\n[1] 1 4 5\n\nC\n\n[1] 4 6 7 8\n\n\n\\(A\\cap B\\)\n\nA\n\n[1] 1 2 3 4 5\n\nB\n\n[1] 1 4 5\n\nintersect(A,B)\n\n[1] 1 4 5\n\n\n\\(A\\cup B\\)\n\nA\n\n[1] 1 2 3 4 5\n\nB\n\n[1] 1 4 5\n\nunion(A,B)\n\n[1] 1 2 3 4 5\n\n\n\\(B-C\\)\n\nB\n\n[1] 1 4 5\n\nC\n\n[1] 4 6 7 8\n\nsetdiff(B,C)\n\n[1] 1 5\n\n\n\\(A^c=\\Omega-A\\)\n\nOmega\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nA\n\n[1] 1 2 3 4 5\n\nsetdiff(Omega,A)\n\n[1]  6  7  8  9 10\n\n\n\n\n1.1.6 Con python\n\nOmega=set([1,2,3,4,5,6,7,8,9,10])\nA=set([1,2,3,4,5])\nB=set([1,4,5])\nC=set([4,6,7,8])\nOmega\n\n{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n\n\n\nA\n\n{1, 2, 3, 4, 5}\n\nB\n\n{1, 4, 5}\n\nC\n\n{8, 4, 6, 7}\n\n\n\nA & B   # intersección (&: and/y)\n\n{1, 4, 5}\n\nA | B   # unión (|: or/o)\n\n{1, 2, 3, 4, 5}\n\n\n\nA - C   # diferencia \n\n{1, 2, 3, 5}\n\nOmega-C # complementario.\n\n{1, 2, 3, 5, 9, 10}",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preliminares: conjuntos y combinatoria</span>"
    ]
  },
  {
    "objectID": "preliminares.html#combinatoria",
    "href": "preliminares.html#combinatoria",
    "title": "1  Preliminares: conjuntos y combinatoria",
    "section": "1.2 Combinatoria",
    "text": "1.2 Combinatoria\nLa combinatoria es una rama de la matemática discreta que entre otras cosas cuenta distintas configuraciones de objetos de un conjunto.\nPor ejemplo si tenemos un equipo de baloncesto con 7 jugadores ¿cuántos equipos de 5 jugadores distintos podemos formar?\n\n1.2.1 Número Binonial\n\n\n Número combinatorio o número binomial\n\n\nNos da el número de subconjuntos de tamaño \\(k\\) de un conjunto de tamaño \\(n\\). Este número es\n\\[\nC_n^k={n\\choose k} = \\frac{n!}{k!\\cdot (n-k)!}.\n\\]\nRecordemos que \\[\nn!=1\\cdot 2\\cdot 3\\cdots n.\n\\]\n\n\n \n\n\n Ejercicio: el paquete gtools\n\n\nCarga el paquete gtools de R y investiga la función combinations(n, r, v, set, repeats.allowed) para calcular todas las combinaciones anteriores.\n\n\n\n\n1.2.2 Combinaciones con repetición\nEn combinatoria, las combinaciones con repetición de un conjunto son las distintas formas en que se puede hacer una selección de elementos de un conjunto dado, permitiendo que las selecciones puedan repetirse.\n\n\n Combinaciones con repetición\n\n\nEl número \\(CR_n^k\\) de multiconjuntos con \\(k\\) elementos escogidos de un conjunto con \\(n\\) elementos satisface:\n\nEs igual al número de combinaciones con repetición de \\(k\\) elementos escogidos de un conjunto con \\(n\\) elementos.\nEs igual al número de formas de repartir \\(k\\) objetos en \\(n\\) grupos.\n\n\\[CR_n^k = \\binom{n+k-1}{k} = \\frac{(n+k-1)!}{k!(n-1)!}.\\]\n\n\n \n\n\n Ejemplo: caramelos\n\n\nVamos a imaginar que vamos a repartir 12 caramelos entre Antonio, Beatriz, Carlos y Dionisio (que representaremos como A, B, C, D). Una posible forma de repartir los caramelos sería: dar 4 caramelos a Antonio, 3 a Beatriz, 2 a Carlos y 3 a Dionisio. Dado que no importa el orden en que se reparten, podemos representar esta selección como AAAABBBCCDDD.\nOtra forma posible de repartir los caramelos podría ser: dar 1 caramelo a Antonio, ninguno a Beatriz y Carlos, los 11 restantes se los damos a Dionisio. Esta repartición la representamos como ADDDDDDDDDDD\nRecíprocamente, cualquier serie de 12 letras A, B, C, D se corresponde a una forma de repartir los caramelos. Por ejemplo, la serie AAAABBBBBDDD corresponde a: Dar 4 caramelos a Antonio, 5 caramelos a Beatriz, ninguno a Carlos y 3 a Dionisio.\nDe esta forma, el número de formas de repartir los caramelos es:\n\\[CR_{n=4}^{k=12} = \\binom{4+12-1}{12}=455.\\]\n\n\n\n\n1.2.3 Variaciones.\nCon los número \\(\\{1,2,3\\}\\) ¿cuántos números de dos cifras distintas podemos formar sin repetir ninguna cifra?\nLa podemos escribir\n\\[12,13,21,23,31,32\\]\nLuego hay seis casos, estas son las variaciones de orden \\(k=2\\) de un conjunto de \\(n=3\\) elementos.\n\n\n Variaciones\n\n\nDenotaremos las variaciones (sin repetición) de \\(k\\) elementos (de orden \\(k\\)) de un conjunto de \\(n\\) elementos por \\(V_n^k\\) su valor es\n\\[\nV_n^k=\\frac{n!}{(n-k)!}=(n-k+1)\\cdot (n-k+2)\\cdots n.\n\\]\n\n\n \n\n\n Ejemplo\n\n\nEn nuestro ejemplo con \\(n=3\\) dígitos podemos escribir las siguientes variaciones de orden \\(k=2\\)\n\\[\nV^{k=2}_{n=3}=\\frac{3!}{(3-2)!}=\\frac{1\\cdot 2\\cdot 3}{1}=6.\n\\]\n\n\n \n\n\n Ejercicio\n\n\nCarga el paquete gtools de R y investiga la función permutations(n, r, v, set, repeats.allowed) para calcular todas las variaciones anteriores.\n\n\n\n\n1.2.4 Variaciones con repetición.\n¿Y si en el caso anterior permitimos que se repita algún dígito?\n\n\n Variaciones on repetición\n\n\nLas variaciones de orden \\(k\\) de un conjunto de \\(n\\) elementos permitiendo que se repitan los elementos. Las denotamos y valen:\n\\[VR_n^k=n^k\\]\n\n\n \n\n\n Ejemplo\n\n\nEfectivamente en nuestro caso\n\\[11,12,13,21,22,23,31,32,33\\]\n\\[\nVR^{k=2}_{n=3}=n^k=3^2=9.\n\\]\n\n\n\n\n1.2.5 Permutaciones\n\n\n Permutaciones\n\n\nLas permutaciones de un conjunto de cardinal \\(n\\) son todas las variaciones de orden máximo \\(n\\). Las denotamos y valen:\n\\[\nP_n=V_n^n=n!\n\\]\n\n\n \n\n\n Variaciones on repetición\n\n\nPor ejemplo todos los números que se pueden escribir ordenando todos los dígitos \\(\\{1,2,3\\}\\) sin repetir ninguno\n\nlibrary(combinat)\nfor(permutacion in permn(3)) print(permutacion)\n\n[1] 1 2 3\n[1] 1 3 2\n[1] 3 1 2\n[1] 3 2 1\n[1] 2 3 1\n[1] 2 1 3\n\n\nEfectivamente \\(P_3=3!=1\\cdot  2\\cdot 3.\\)\n\n\n \n\n\n Ejercicio\n\n\nCarga el paquete combinat de R e investiga la función permn para calcular todas las permutaciones anteriores.\nInvestiga también el paquete itertools y la función comb de scipy.misc de Python e investiga sus funciones para todas las formas de contar que hemos visto en este tema.\n\n\n \n\n\n Ejercicio\n\n\nLa función gamma de Euler, cobrará mucha importancia en el curso de estadística. Comprueba que la función gamma(x+1) da el mismo valor que la función factorial(x) en R para todo \\(x = \\{1,2,3,\\ldots,10\\}\\).\n\n\n\n\n1.2.6 Números multinomiales. Permutaciones con repetición.\n\n\n Ejercicio\n\n\nConsideremos un conjunto de elementos \\(\\{a_1, a_2, \\ldots, a_k\\}\\).\nEntonces, si cada uno de los objetos \\(a_i\\) de un conjunto, aparece repetido \\(n_i\\) veces para cada \\(i\\) desde 1 hasta \\(k\\), entonces el número de permutaciones con elementos repetidos es:\n\\[PR_n^{n_1,n_2,\\ldots,n_k} = {{n}\\choose {n_1\\quad n_2 \\quad\\ldots \\quad n_k}}=\\frac{n!}{n_1!\\cdot n_2!\\cdot \\ldots \\cdot n_k!},\\] donde \\(n=n_1+n_2+\\cdots+n_k\\).\n\n\n \n\n\n Ejercicio\n\n\n¿Cuantas palabras diferentes se pueden formar con las letras de la palabra PROBABILIDAD?\nEl conjunto de letras de la palabra considerada es el siguiente: \\(\\{A, B, D, I, L, O, P, R\\}\\) con las repeticiones siguientes: las letras A, B, D, e I, aparecen 2 veces cada una; y las letras L, O, P, R una vez cada una de ellas.\nPor tanto, utilizando la fórmula anterior, tenemos que el número de palabras (permutaciones con elementos repetidos) que podemos formar es\n\\[PR^{2,2,2,2,1,1,1,1}_{12} = \\frac{12!}{(2!)^4(1!)^4} = 29937600.\\]",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preliminares: conjuntos y combinatoria</span>"
    ]
  },
  {
    "objectID": "preliminares.html#para-acabar",
    "href": "preliminares.html#para-acabar",
    "title": "1  Preliminares: conjuntos y combinatoria",
    "section": "1.3 Para acabar",
    "text": "1.3 Para acabar\n\n1.3.1 Principios básicos para contar cardinales de conjuntos\n\n\n El principio de la suma\n\n\nSean \\(A_1, A_2,\\ldots, A_n\\) conjuntos disjuntos dos a dos, es decir \\(A_i\\cap A_j=\\emptyset\\) para todo \\(i\\not= j\\), \\(i,j=1,2,\\ldots n\\). Entonces\n\\[\\#(\\cup_{i=1}^n A_i)=\\sum_{i=1}^n \\#(A_i).\\]\n\n\n \n\n\n Principio de unión exclusión\n\n\nConsideremos dos conjuntos cualesquiera \\(A_1, A_2\\) entonces el cardinal de su unión es\n\\[\\#(A_1\\cup A_2)=\\#(A_1)+\\#(A_2)-\\#(A_1\\cap A_2).\\]\n\n\n \n\n\n El principio del producto\n\n\nSean \\(A_1,A_2,\\ldots A_n\\)\n\\[\n\\begin{array}{ll}\n\\#(A_1\\times A_2\\times \\cdots A_n)=&\\#\\left(\\{(a_1,a_2,\\ldots a_n)| a_i\\in A_i, i=1,2,\\ldots n\\}\\right)\\\\\n&=\\prod_{i=1}^n \\#(A_i).\n\\end{array}\n\\]\n\n\n\n\n1.3.2 Otros aspectos a tener en cuenta\nEvidentemente nos hemos dejado muchas otras propiedades básicas de teoría de conjuntos y de combinatoria como:\n\nPropiedades de los números combinatorios.\nBinomio de Newton.\nMultinomio de Newton.\n\nSi nos son necesarias las volveremos a repetir a lo largo del curso o bien daremos enlaces para que las podáis estudiar en paralelo.",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preliminares: conjuntos y combinatoria</span>"
    ]
  },
  {
    "objectID": "probabilidad.html",
    "href": "probabilidad.html",
    "title": "2  Teoría elemental de la probabilidad",
    "section": "",
    "text": "2.1 Definiciones básicas\nDaremos nombres a distintos tipos de sucesos:\nA continuación describimos el clásico experimento del lanzamiento de un dado.\nRecordemos la notación \\(\\mathcal{P}(\\Omega)\\) que usamos para referirnos al conjunto de todos los subconjuntos de \\(\\Omega\\). Este conjunto se llama conjunto de partes de \\(\\Omega\\).\nVeamos algún ejemplo menos clásico. Podemos considerar el experimento aleatorio que consiste en calcular los \\(n\\) gramas de una palabra escogida al azar.",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría elemental de la probabilidad</span>"
    ]
  },
  {
    "objectID": "probabilidad.html#definiciones-básicas",
    "href": "probabilidad.html#definiciones-básicas",
    "title": "2  Teoría elemental de la probabilidad",
    "section": "",
    "text": "Definición experimento aleatorio\n\n\nUn experimento que repetido en las mismas condiciones puede dar resultados diferentes, pero que a largo plazo son predecibles recibe el nombre de experimento aleatorio.\n\n\n\n\n\n Espacio muestral y tipos de sucesos\n\n\n\nLlamaremos suceso elemental a cada uno de los posibles resultados del experimento aleatorio.\nLlamaremos espacio muestral (\\(\\Omega\\),\\(E\\)) al conjunto formado por todos los sucesos elementales del experimento aleatorio.\nLlamaremos suceso a cualquier subconjunto del espacio muestral.\nSuceso seguro o cierto \\(A\\subseteq \\Omega\\)\nSuceso imposible o vacio: \\(\\emptyset\\)\nPartes de un conjunto: \\(\\mathcal{P}(\\Omega)\\): conjunto de todos los sucesos del experimento aleatorio (es decir, el conjunto de todos los subconjuntos de \\(\\Omega\\))\n\n\n\n\n\n\n Ejemplo\n\n\nConsideremos el experimento aleatorio que consiste en lanzar un dado. El espacio muestral de este experimento es \\(\\Omega=\\{1,2,3,4,5,6\\}\\) o las figuras de las caras del dado.\nSi lo representamos gráficamente, tendríamos:\n\n\n\n\n\n\n\n\n\nPor comodidad y conveniencia se opta por representar el espacio muestral por \\[\\Omega = \\{1,2,3,4,5,6\\}.\\]\n\n\n\n\n\n Ejercicio\n\n\n¿Cuantos elementos contiene el conjunto de partes de \\(\\Omega\\) del experimento anterior?\n\n\n\n\n\n Ejemplo \\(n\\)-gramas\n\n\nSe define un \\(n\\)-grama de una palabra como el conjunto de \\(n\\) letras consecutivas de la misma (contando los blancos de inicio y final de palabra que marcamos como “_”).\nConsideremos el experimento aleatorio que consiste en escoger al azar un 3-grama de la palabra “_Baleares_”. Vamos a escribir el espacio muestral y algunos sucesos elementales del mismo.\nEn este caso, si consideramos la palabra “_Baleares_”, el espacio muestral del experimento sería:\n\\[\\Omega=\\{\\_Ba, Bal, ale, lea, ear, are, res, es\\_\\}\\]\nAlgunos sucesos serían:\n\n3-gramas que empiezan por \\(a\\): \\(\\{ale,are\\}.\\)\n3-gramas de inicio y final de palabra: \\(\\{\\_Ba,es\\_\\}.\\)\n3-gramas que contengan una \\(l\\): \\(\\{Bal,ale,lea\\}.\\)\n\nEsiten bases de datos que estudián la frecuencias de \\(n\\)-grams de caracteres en textos en diferentes idiomas; generalmente de palabras. Por ejemplo, en español, los bigramas de sílabas más frecuentes son “EN” (3.01%) y “DE” (2.77%) y los trigramas de sílabas son “QUE” (1.66%) y “ENT” (1.38%). Podéis consultar más estadísticas en por ejemplo en Stefan Trost Media frecuencias de sílabas en español.\n\n\n\n2.1.1 Operaciones con sucesos\nSi tenemos dos sucesos \\(A,B\\subseteq \\Omega\\), podemos definir:\n\n\\(\\Omega\\): suceso total o seguro.\n\\(\\emptyset\\): suceso vacío o imposible.\n\\(A\\cup B\\): suceso unión; el que ocurre si sucede \\(A\\) o \\(B\\).\n\\(A\\cap B\\): suceso intersección; el que ocurre si sucede \\(A\\) y \\(B\\).\n\\(A^c\\): suceso complementario el que sucede si NO sucede \\(A\\).\n\\(A- B=A\\cap B^c\\): suceso diferencia, que acontece si sucede \\(A\\) y NO sucede \\(B\\).\n\n\n\n Sucesos incompatibles\n\n\nDos sucesos cualesquiera \\(A\\) y \\(B\\) son incompatibles (o disjuntos) cuando \\(A\\cap B=\\emptyset\\).\n\n\nOtro ejemplo se observa el sexo y la lateralidad de los estudiantes de una clase.\n\n\n Ejemplo\n\n\nSupongamos que el sexo se divide entre Mujeres y Hombres y la lateralirad en diestros y zurdos. Vamos a definir el espacio muestral, los sucesos elementales y a realizar algunas operaciones entre ellos.\nEstudiantes de esta clase: \\(\\Omega\\). - Mujeres de esta clase: \\(A\\). - Estudiantes que son zurdos \\(B\\).\n\n\nAlgunas operaciones entre los sucesos anteriores serían:\n\n\\(A\\cup B\\): Est. que son mujeres o que son zurdos.\n\\(A\\cap B\\): Mujeres de esta clase que son zurdas.\n\\(A^c\\): Hombres de esta clase.\n\\(A-B\\): Mujeres de la clases que NO son zurdas.\n\\(B-A\\): Hombres de la clase que son zurdos.\n ¡Cuidado!  No son incompatibles.\n\n\n\n2.1.2 Propiedades\n\n\n Propiedades\n\n\nConmutativas:\n\\[A\\cup B=B\\cup A, \\quad A\\cap B=B\\cap A\\]\nAsociativas:\n\\[\\begin{align*}\nA\\cup(B\\cup C)=(A\\cup B)\\cup C, \\\\\nA\\cap(B\\cap C)=(A\\cap B)\\cap C.\n\\end{align*}\\]\nDistributivas\n\\[\\begin{align*}\nA\\cap & (B\\cup C)=(A\\cap B)\\cup (A\\cap C),\\\\\nA\\cup & (B\\cap C)=(A\\cup B)\\cap (A\\cup C).\n\\end{align*}\\]\n\n\nVeamos algunos diagramas que nos ayuda a demostrar las propiedades anteriores.\n\n\n\n\n\n\n\n\n\\(A\\)\n\\(B\\cap C\\)\n\\(A\\cup (B\\cap C)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(A\\cup B\\)\n\\(A\\cup C\\)\n\\((A\\cup B)\\cap (A\\cup C)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n Complementario del complementario\n\n\n\\[(A^c)^c=A\\]\n\n\n\n\n\n\n\n\n\n\n\\(A\\)\n\\(A^c\\)\n\\((A^c)^c\\)\n\n\n\n\n\n\n\n\n\n\n\n\n Leyes de De Morgan\n\n\n\\[(A\\cup B)^c=A^c\\cap B^c\\]\n\n\n\n\n\n\n\n\\(A\\cup B\\)\n\\((A\\cup B)^c\\)\n\n\n\n\n\n\n\n\n\n\\[(A\\cup B)^c=A^c\\cap B^c\\]\n\n\n\n\n\n\n\n\n\\(A^c\\)\n\\(B^c\\)\n\\(A^c\\cap B^c\\)\n\n\n\n\n\n\n\n\n\n\n\\[(A\\cap B)^c=A^c\\cup B^c\\]\n\n\n\n\n\n\n\n\\(A\\cap B\\)\n\\((A\\cap B)^c\\)\n\n\n\n\n\n\n\n\n\n\\[(A\\cap B)^c=A^c\\cup B^c\\]\n\n\n\n\n\n\n\n\n\\(A^c\\)\n\\(B^c\\)\n\\(A^c\\cup B^c\\)",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría elemental de la probabilidad</span>"
    ]
  },
  {
    "objectID": "probabilidad.html#definición-de-probabilidad",
    "href": "probabilidad.html#definición-de-probabilidad",
    "title": "2  Teoría elemental de la probabilidad",
    "section": "2.2 Definición de probabilidad",
    "text": "2.2 Definición de probabilidad\nLa probabilidad de un suceso es una puntuación (score) numérico entre 0 y 1 que mide la verosimilitud de que este evento se produzca.\nEsta verosimilitud puede estar justificada por:\n\nEstimación personal\nEstimación de expertos\nLa frecuencia con la que se da\nCálculo formal\n\n\n\n Definición formal de probabilidad\n\n\nSea \\(\\Omega\\) el espacio muestral de un experimento aleatorio. Supongamos que el número de posibles resultados, por el momento, es finito.\nUna probabilidad sobre \\(\\Omega\\) es una aplicación \\(P:\\mathcal{P}(\\Omega)\\to [0,1]\\) con las siguientes propiedades:\n\n\\(0\\leq P(A)\\leq 1\\), para todo suceso \\(A\\).\n\\(P(\\Omega)=1\\).\nSi \\(\\{A_1,A_2,\\ldots,A_n\\}\\) son sucesos disjuntos dos a dos, entonces\n\n\\[\nP(A_1\\cup A_2\\cup \\cdots \\cup A_n)=P(A_1)+P(A_2)+\\cdots +P(A_n)\n\\]\nSi \\(a\\in \\Omega\\) es un suceso elemental cometeremos el abuso de notación de poner \\(P(a)\\) en lugar de \\(P(\\{a\\})\\).\n\n\nVeamos un ejemplo real de cómo se calcula la probabilidad de un suceso.\n\n\n Ejemplo\n\n\nEn la página de la Fundación Banco de Sangre y Tejidos de las Islas Baleares (17-08-2023) podemos encontrar información sobre los porcentajes de tipos de sangre de los donantes de las Islas Baleares:\n\\[A: 46\\%;\\  B: 7.5\\%;\\  AB: 3.5\\%;\\  O: 43\\%.\\]\n¿Cuál es la probabilidad de que un balear donante de sangre no sea del tipo O?\nExperimento aleatorio: tipo de sangre de un paciente humano:\n\\[\\Omega=\\{\\mbox{A,B,AB,O}\\}\\]\nProbabilidad de un suceso: se asimila al porcentaje observado de individuos.\nSuceso: \\(\\{\\mbox{O}\\}^c=\\{\\mbox{A,B,AB}\\}\\).\n\\[P(\\{\\mbox{O}\\}^c)\\!=\\!P(\\{\\mbox{A,B,AB}\\})\\!=\\!\nP(\\mbox{A})+P (\\mbox{B})+P(\\mbox{AB})\\!=\\!0.57.\\]\n\n\nNecesitaremos tener propiedades y fórmulas prácticas para poder calcular probabilidades de sucesos más complejos. Veamos algunas de ellas.\n\n\n Propiedades básicas de la probabilidad\n\n\n\n\\(P(\\emptyset)=0\\).\n\\(\\scriptsize{P(A-B)=P(A)-P(A\\cap B)}\\) porque \\(\\scriptsize{P(A)=P(A-B)+P(A\\cap B)}\\).\n\n\n\n\n\n\n\n\n\n\n\nSi \\(B\\subseteq A\\), entonces \\(0\\leq P(B)\\leq P(A)\\).\n\\(P(A^c)=1-P(A)\\).\n\n\n\nUna identidad muy utilizada es la de la probabilidad de la unión de dos sucesos cualesquiera.\n\n\n La Probabilidad de la unión de dos sucesos\n\n\n\\(P(A\\cup B)=P(A)+P(B)-P(A\\cap B)\\)\n\n\n\n\n\n\n\n\n\n\n\nLa demostración analítica de esta propiedad es la siguiente:\n\\[\\begin{eqnarray*}\nP(A)+P(B)-P(A\\cap B) &=& P(A-B)+P(A\\cap B)\\\\\n& & +P(B-A)+ P(A\\cap  B)-P(A\\cap  B)\\\\\n&=& P(A-B)+P(A\\cap B)+ P(B-A) \\\\\n&=& P(A\\cup B).\\\\\n\\end{eqnarray*}\\]\n\n\n Probabilidad de la unión de \\(n\\) conjuntos\n\n\nSean \\(A_1, A_2,\\ldots A_n\\) sucesos. Entonces:\n\\[\nP(\\cup_{i=1}^n A_i)=\\sum_{i=1}^n P(A_i)-\\sum_{1\\leq i&lt;j\\leq n}P(A_i\\cap A_j)+\\cdots +(-1)^{n-1}P(A_1\\cap A_2\\cap \\cdots \\cap A_n).\n\\]\n\n\nLa demostración es sencilla mediante inducción: partimos del caso base de dos sucesos, suponemos que es cierta para \\(n\\) sucesos y luego la extendemos al caso de \\(n+1\\) sucesos.\nComo comprobación, consideremos un ejemplo genérico con tres sucesos.\n\\(A=\\{1,4,5,6\\}\\), \\(B=\\{2,4,6,7\\}\\) y \\(C=\\{3,5,6,7\\}\\). En este caso la fórmula nos da\n\\[\nP(A\\cup B\\cup C)=  P(A)+P(B)+P(C)-P(A\\cap B)-P(A\\cap C)\n-P(B\\cap C)+P(A\\cap B\\cap C).\n\\]\nGráficamente tenemos esta situación:\n\n\n\n\n\n\n\n\n\nAhora podemos comprobar la fórmula para este caso.\n\\[\\begin{eqnarray*}\nP(A\\cup B\\cup C)&=&P(A)+P(B)+P(C)-P(A\\cap B) \\\\\n  & & - P(A\\cap C)-P(B\\cap C)+P(A\\cap B\\cap C).\\\\\n\\end{eqnarray*}\\]\nEfectivamente tenemos que:\n\\[P(A\\cup B\\cup C)=P(1)+P(2)+P(3)+P(4)+P(5)+P(6)+P(7).\\]\nUna de las formas más intuitiva de asignación de probabilidades es hacer el cociente entre los casos favorables a que acontezca el vento y los casos posibles del experimento; la llmadad fórmula de Laplace.\n\n\n Propiedad\n\n\n\nEn general dado un suceso \\(A=\\{a_1,a_2,\\ldots,a_k\\}\\), entonces \\[\nP(A)=P(a_1)+P(a_2)+\\cdots+P(a_k).\n\\]\nFórmula de Laplace: Si todos los sucesos elementales tienen la misma probabilidad, \\[\nP(A)=\\frac{|A|}{|\\Omega|}\\Big(=\\frac{\\mbox{casos favorables}}{\\mbox{casos posibles}}\\Big).\n\\]\n\n\n\nEn el procesamiento del lenguaje se suelen estudiar las frecucias de plabaras o letras de un determinado idioma. Veamos un ejemplo sobre las frecuencias de las vocales en castellano.\n\n\n Ejemplo: Frecuencia de vocales\n\n\nLos porcentajes de vocales de un determinado idioma (de alfabeto latino) según la Wikipedia son:\n\\[A: 18.7\\%;\\ E: 26.1\\%;\\ I: 25.7\\%;\\ O: 24.4\\%;\\ U: 5.1\\%.\\]\n¿Cuál es la probabilidad que una vocal escogida al azar de este idioma sea una E o una O?\nEl espacio muestral del experimento es \\(\\Omega=\\{A,E,I,O,U\\}\\).\nEl suceso que deseamos analizar es \\(\\{E,0\\}\\).\nY su probabilidad es\n\\[P(\\{E,O\\})=P(E)+P(O)=0.261+0.244=0.505.\\]\n\n\nOtro ejemplo en este caso es sobre un test de drogas en el que se analiza la presencia de cocaína y cannabis en la sangre de los conductores, inspirado en un caso real.\n\n\n Ejemplo: Consumo de drogas\n\n\nSegun un árticulo de El País, en un control especial de la policía el \\(0.1\\%\\) de todos los conductores analizados en un control de tráfico dan positivo en un el test en cocaína, y el \\(1\\%\\) da positivo en cannabis. Un \\(1.05\\%\\) da positivo en alguno de los dos test.\nPregunta: ¿Cuál es la probabilidad que un individuo analizado en el control de drogas escogido al azar no de positivo en ninguno de lo dos test?\nLos sucesos elementales del enunciado del problema son:\n\n\\(A\\): dar positivo en cocaína; \\(P(A)=0.001.\\)\n\\(B\\): dar positivo en cannabis; \\(P(B)=0.01.\\)\n\nEn este caso nos interesa estudiar los sucesos:\n\n\\(A\\cup B\\): dar positivo en alguno de los dos test; \\(P(A\\cup B)=0.0105.\\)\n\\((A\\cup B)^c\\): no dar positivo en ninguno de los test,por tanto:\n\n\\[P((A\\cup B)^c)=1-P(A\\cup B)=1-0.0105=0.9895.\\]\nPregunta: ¿Cuál es la probabilidad que un analizado al azar de positivo en los dos test en cocaína y cannabis?\nLos sucesos elementales son:\n\n\\(A\\): dar positivo en cocaína; \\(P(A)=0.001.\\)\n\\(B\\): dar positivo en cannabis; \\(P(B)=0.01.\\)\n\nEn este caso nos interesa estudiar los sucesos:\n\n\\(A\\cup B\\): dar positivo en algún de los dos test; \\(P(A\\cup B)=0.0105.\\)\n\\(A\\cap B\\): dar positivo en los dos test\n\nde donde, por tanto:\n\\[\\begin{array}{rl}\n{P(A\\cap B)} &{=P(A)+P(B)-P(A\\cup B)}\\\\ &{=0.001+0.01-0.0105=0.0005}.\n\\end{array}\\]\nPregunta: ¿Cuál es la probabilidad de que un conductor analizado de positivo en cocaína pero no en cannabis?\nLos sucesos elementales son:\n\n\\(A\\): dar positivo en cocaína; \\(P(A)=0.001.\\)\n\\(B\\): dar positivo en cannabis; \\(P(B)=0.01.\\)\n\nEn este caso nos interesa estudiar los sucesos:\n\n\\(A\\cap B\\): dar positivo en los dos test; \\(P(A\\cap B)=0.0005.\\)\n\\(A-B\\): dar positivo en cocaína pero no en cannabis, por lo tanto tenemos que :\n\n\\[P(A-B) =P(A)-P(A\\cap B) =0.001-0.0005=0.0005.\\]",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría elemental de la probabilidad</span>"
    ]
  },
  {
    "objectID": "probabilidad.html#probabilidad-condicionada",
    "href": "probabilidad.html#probabilidad-condicionada",
    "title": "2  Teoría elemental de la probabilidad",
    "section": "2.3 Probabilidad condicionada",
    "text": "2.3 Probabilidad condicionada\n\n\n Probabilidad condicionada\n\n\nDados dos sucesos \\(A\\) y \\(B\\), con \\(P(A)&gt;0\\), la probabilidad \\(P(B|A)\\) de \\(B\\) condicionado a \\(A\\) es la probabilidad\n\nde que suceda \\(B\\) suponiendo que pasa \\(A\\),\nde que si pasa \\(A\\), entonces suceda \\(B\\),\nde que un resultado de \\(A\\) también pertenezca a \\(B\\).\n\nSe calcula a través de la definición:\n\\[\nP(B|A)=\\frac{P(A\\cap B)}{P(A)}.\n\\]\n\n\n\n\n Ejemplo\n\n\nEn una clase de 20 hombres y 30 mujeres, 15 hombres y 18 mujeres llevan gafas. Contestemos las siguientes preguntas:\n¿Cuál es la probabilidad de que un alumno lleve gafas?\n\\[\n\\frac{33}{50}\n\\]\n¿Cuál es la probabilidad de que un alumno sea mujer y lleve gafas?\n\\[\n\\frac{18}{50}\n\\]\n¿Cuál es la probabilidad de que un chica lleve gafas?\n\\[\n\\frac{18}{30}=\\frac{18/50}{30/50}=\\frac{P(\\mbox{mujer  y gafas})}{P(\\mbox{mujer})}.\n\\]\nSi escogemos un estudiante al azar ¿Cuál es la probabilidad que si es mujer, entonces lleve gafas?\n\\[\n\\frac{18}{30}.\n\\]\n¿Cuál es la probabilidad de que un alumno que lleve gafas sea mujer?\n\\[\n\\frac{18}{33}=\\frac{18/50}{33/50}=\\frac{P(\\mbox{mujer y gafas})}{P(\\mbox{gafas})}.\n\\]\nSi escogemos un estudiante al azar ¿Cuál es la probabilidad de que si lleva gafas, entonces sea mujer? \\[\n    \\frac{18}{33}\n    \\]\n\n\n\n\n ¡Atención!\n\n\nHay que distinguir bien entre\n\n\\(P(A\\cap B)\\): probabilidad de \\(A\\) \\(\\color{red}{\\text{y}}\\) \\(B\\).\n\nProbabilidad de que sea mujer y lleve gafas.\n\n\\(P(A|B)\\): probabilidad de que \\(\\color{red}{\\text{si}}\\) pasa \\(B\\), \\(\\color{red}{\\text{entonces}}\\) pase \\(A\\).\n\nProbabilidad de que, si es mujer, lleve gafas.\nCuando utilizamos probabilidad condicional \\(P(A|B)\\) estamos restringiendo el espacio muestral a \\(B\\).\n\n\n\n2.3.1 Probabilidad condicionada. Propiedades\nLa probabilidad condicionada es una probabilidad, en el setido de la siguiente propiedad.\n\n\n Propiedad\n\n\nSea \\(A\\subseteq \\Omega\\) un suceso tal que \\(P(A)&gt;0\\), entonces\n\\[\n\\begin{array}{rccl}\nP(-|A):& \\mathcal{P}(\\Omega) & \\to & [0,1]\\\\\n&B & \\mapsto & P(B|A).\n\\end{array}\n\\] satisface las propiedades de las probabilidades, como por ejemplo:\n\\[\n\\begin{array}{l}\nP(B^c|A)=1-P(B|A),\\\\\nP(B_1\\cup B_2|A)=P(B_1|A)+P(B_2|A)-P(B_1\\cap B_2|A).\n\\end{array}\n\\]\n\n\nTambién se cumpliran el resto de propiedades miestras condiciones todas ellas al mismo suceso \\(A\\).\n\n\n Ejercicio\n\n\nEscribid el resto de propiedades que cumpliría una probabilidad condicionada al evento \\(A\\).\n\n\nVeamos un ejemplo donde se aplica la probabilidad condicionada, en este caso, para calcular la probabilidad de que un adulto sea hipertenso, dado que cree que lo es.\n\n\n Ejemplo\n\n\nUn 15% de los adultos son hipertensos, un 25% de los adultos creen que son hipertensos, y un 9% de los adultos son hipertensos y creen que lo son.\nSi un adulto cree que es hipertenso, ¿cuál es la probabilidad que lo sea?\nSean los sucesos\n\n\\(A\\): ser hipertenso, \\(P(A)=0.15\\) ,\n\\(B\\): creer ser hipertenso, \\(P(B)=0.25\\),\n\nAhora podemos definir el suceso:\n\n\\(A\\cap B\\): ser hipertenso y creerlo, \\(P(A\\cap B)=0.09\\).\n\nde donde, la probabilidad condicionada de ser hipertenso creyéndonos que lo somos es:\n\\[\\scriptsize P(A|B)=\\dfrac{P(A\\cap B)}{P(B)}=\\dfrac{0.09}{0.25}=0.36.\\]\nOtra pregunta es, si un adulto es hipertenso, ¿cuál es la probabilidad que crea que lo es?\nSi tenemos los sucesos:\n\n\\(A\\): ser hipertenso,\n\\(B\\): creer ser hipertenso\n\nentonces buscamos la probabilidad \\(P(B|A)\\):\n\\[\n\\begin{array}{rl}\nP(B|A) & =\\dfrac{P(A\\cap B)}{P(A)}=\\dfrac{0.09}{0.15}=\n0.6\n\\end{array}\n\\]\n\n\n\n\n Ejemplo\n\n\nOtro ejemplo de probabilidad condicionada en este caso un ejemplo simple de dígito de control de error.\nUn dígito de control de error toma el valor 0 en el 99% de los casos en que hay un error. Si la probabilidad de error en un mensaje es del \\(0.5\\%\\). ¿cuál es la probabilidad de que el mensaje sea erróneo y el código de error tenga valor 0?\n\n\\(B\\): mensaje con error; \\(P(B)=0.005\\),\n\\(A\\): código de error vale 0,\n\\(P(A|B)=0.99\\),\n\nentonces: \\[P(A\\cap B)=P(B)\\cdot P(A|B)=0.005\\cdot 0.99=0.00495.\\]\n\n\nLa probabilidad condicional también es útil en la resolución de problemas de clasificación, como el siguiente ejemplo.\n\n\n Ejemplo: SPAM\n\n\nUn 50% de correos recibidos en un servidor llevan adjuntos y un 65% son publicidad no deseada (SPAM). Sólo un 15% de estos correos no llevan adjuntos y no son SPAM.\n\n¿Cuál es la probabilidad que un correo lleve adjunto si es SPAM?\n¿Cuál es la probabilidad que un correo no tenga adjuntos si no es SPAM?\n¿Cuál es la probabilidad que un correo lleve adjunto si es SPAM?\n\nAsignemos sucesos y probabilidades\n\n\\(A\\): llevar adjuntos; \\(P(A)=0.5\\), - \\(S\\): SPAM; \\(P(S)=0.65\\), - \\(A^c\\cap S^c=(A\\cup S)^c\\): no llevar adjunto y no ser SPAM; \\(P((A\\cup S)^c)=0.15\\),\n\n\\[P(A|S)=\\dfrac{P(A\\cap S)}{P(S)}=?\\]\n\n¿Cuál es la probabilidad que un correo lleve adjunto si es SPAM?\n\\(P(A)=0.5, P(S)=0.65, P(A^c\\cap S^c)=P((A\\cup S)^c)=0.15\\),\n\\(P(A\\cup S)=1-P((A\\cup S)^c)=0.85\\),\n\\(P(A\\cap S)=P(A)+P(S)-P(A\\cup S)=0.3\\),\n\n\\[P(A|S)=\\dfrac{P(A\\cap S)}{P(S)}=\\dfrac{0.3}{0.65}\\approx 0.46.\\]\n\nOtra pregunta es ¿Cuál es la probabilidad de que un correo no lleve adjuntos si no es SPAM?\n\\(P(A)=0.5, P(S)=0.65, P(A^c\\cap S^c)=P((A\\cup S)^c)=0.15.\\)\n\n\\[P(A^c|S^c)=\\dfrac{P(A^c\\cap S^c)}{P(S^c)}=\\dfrac{P(A^c\\cap S^c)}{1-P(S)}=\\dfrac{0.15}{0.35}\\approx 0.43.\\]",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría elemental de la probabilidad</span>"
    ]
  },
  {
    "objectID": "probabilidad.html#teorema-de-la-probabilidad-total",
    "href": "probabilidad.html#teorema-de-la-probabilidad-total",
    "title": "2  Teoría elemental de la probabilidad",
    "section": "2.4 Teorema de la probabilidad total",
    "text": "2.4 Teorema de la probabilidad total\n\n\n Teorema de la probabilidad total\n\n\nDados dos sucesos \\(A\\) y \\(B\\) se tiene que\n\\[\n\\begin{array}{rl}\nP(B)&= P(B\\cap A) +P(B\\cap A^c)\\\\\n& =P(A)\\cdot P(B|A)+ P(A^c)\\cdot P(B|A^c).\n\\end{array}\n\\]\n\n\nVamos a generalizar el resultado anterior a una colección de sucesos \\(A_1,A_2,\\ldots,A_n\\) que forman una partición del espacio muestral \\(\\Omega\\).\n\n\n Partición del espacio espacio muestral\n\n\nLos sucesos \\(A_1,A_2,\\ldots, A_n\\) son una partición del espacio muestral \\(\\Omega\\) de un determinado experimento aleatorio, si cumplen las condiciones siguientes:\n\n\\(A_1\\cup A_2\\cup\\ldots\\cup A_n=\\Omega\\),\n\\(A_1,A_2,\\ldots,A_n\\) son incompatibles dos a dos (\\(A_i\\cap A_j=\\emptyset\\)).\n\n\n\nAhora podemos volver a enunciar el teorema anterior pero en esta ocasión para particiones arbitrarias.\n\n\n Teorema de la probabilidad total generalizado\n\n\nSea \\(A_1,A_2,\\ldots,A_n\\) una partición de \\(\\Omega\\). Sea \\(B\\) un suceso cualquiera. Entonces\n\\[\n\\begin{array}{rl}\nP(B)&= P(B\\cap A_1)+\\cdots +P(B\\cap A_n)\\\\\n& =P(A_1)\\cdot P(B|A_1)+\\ldots+P(A_n)\\cdot P(B|A_n).\n\\end{array}\n\\]\n\n\nRevisitemos el ejemplo de los mensajes con dígitos de control de error.\n\n\n Ejemplo\n\n\nUn dígito de control de error toma el valor 0 en un \\(99\\%\\) de los casos en que hay un error y en un \\(5\\%\\) de los mensajes sin error. La probabilidad de error en un mensaje es del \\(0.5\\%\\).\n¿Cuál es la probabilidad de que un mensaje escogido al azar tenga el dígito de control a 0?\nSean los sucesos del enunciado:\n\n\\(B\\): mensaje con error; \\(P(B)=0.005\\),\n\\(A\\): código de error vale 0,\n\nentonces obtenemos las probabilidades a partir del enunciado:\n\n\\(P(A|B)=0.99,\\)\n\\(P(A|B^c)= 0.05\\)\n\ny por tanto,\n\\[\n\\begin{array}{rl}\nP(A)=& P(B)\\cdot P(A|B)+P(B^c)\\cdot P(A|B^c)\\\\\n& =0.005\\cdot 0.99+0.995\\cdot 0.05=0.0547.\n\\end{array}\n\\]",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría elemental de la probabilidad</span>"
    ]
  },
  {
    "objectID": "probabilidad.html#clasificación-o-diagnostico-caso-binario",
    "href": "probabilidad.html#clasificación-o-diagnostico-caso-binario",
    "title": "2  Teoría elemental de la probabilidad",
    "section": "2.5 Clasificación o diagnostico caso binario",
    "text": "2.5 Clasificación o diagnostico caso binario\nConsideremos alguna de las siguientes situaciones:\n\nUn algoritmo detecta si una transacción con tarjeta de crédito es fraude o no.\nUn algoritmo detecta si tiene o no que mostrar un anuncio en una web.\nUn prueba de embarazo.\nUna prueba médica para una enfermedad concreta.\n\nNos ceñiremos a la casuística más elemental el algoritmo de clasificación o la diagnosis solo da dos resultado Positivo (sí tienes la enfermedad, sí es un fraude) o Negativo (en caso contrario).\nSPAM continuación\nEn todas estas situaciones podemos calcular lo que se llama matriz de confusión que representa todas las situaciones posibles. En el caso de estudiar una condición de tipo binario,\n\n\n\n\nEl Test da Positivo\nEl Test da Negativo\n\n\n\n\nCondición Positiva\nCorrecto\nError\n\n\nCondición Negativa\nError\nCorrecto\n\n\n\nEn general los modelos y algoritmos de clasificación suelen aportar puntuaciones (scores) que determinan el grado de pertenencia a una clase, o que miden si dos objetos están en la misma clase.\nAsí el resultado del clasificador o del diagnóstico puede ser:\n\nun número real, en cuyo caso debe clasificador entre cada clase debe determinarse por un valor umbral (threshold) por ejemplo para determinar si una persona está estresado podemos dar un scores entre 0 y 1 (1 máximo estrés 0 estrés nulo),\nun resultado discreto que indica directamente una de las clases (esto es necesario si es un algoritmo que debe decidir qué hacer con el objeto.\n\n\n\n Falsos Positivos y Negativos\n\n\nConsideremos un problema de predicción de clases binario, en la que los resultados se etiquetan positivos (P) o negativos (N). Hay cuatro posibles resultados a partir de un clasificador binario como el propuesto.\n\nSi el resultado de una exploración es P y el valor dado es también P, entonces se conoce como un Verdadero Positivo (VP).\nSin embargo si el valor real es N entonces se conoce como un Falso Positivo (FP).\nDe igual modo, tenemos un Verdadero Negativo (VN) cuando tanto la exploración como el valor dado son N.\nUn Falso Negativo (FN) cuando el resultado de la predicción es N pero el valor real es P.\n\n\n\nVeamos el siguiente ejemplo:\n\n\n Falsos Positivos y Negativos\n\n\nUn ejemplo aproximado de un problema real es el siguiente: consideremos una prueba diagnóstica que persiga determinar si una persona tiene una cierta enfermedad.\n\nUn falso positivo en este caso ocurre cuando la prueba predice que el resultado es positivo, cuando la persona no tiene realmente la enfermedad.\nUn falso negativo, por el contrario, ocurre cuando el resultado de la prueba es negativo, sugiriendo que no tiene la enfermedad cuando realmente sí la tiene.\n\nEn un diagnósticos de una cierta condición (por ejemplo, test embarazo, test de enfermedad), tenemos dos tipos de sucesos:\n\n\\(T\\): el test da positivo,\n\\(M\\): el sujeto satisface la condición.\n\n\n\nNecesitamos algunas denominaciones adicionales:\n\n\n Falsos Positivos y Negativos\n\n\n\nFalsos positivos \\(T\\cap M^c\\): El test da positivo, pero la condición no se da,\nCoeficiente de falsos positivos \\(P(T|M^c)\\),\nFalsos negativos \\(T^c\\cap M\\): El test da negativo, pero la condición sí que se da,\nCoeficiente de falsos negativos: \\(P(T^c|M)\\).\n\n\n\n \n\n\n Falsos Positivos y Negativos\n\n\nUn test diseñado para diagnosticar una determinada enfermedad tiene un coeficiente de falsos negativos de 0.06, y un coeficiente de falsos positivos de 0.04. En un estudio masivo se observa que un 15% de la población da positivo al test.\n¿Cuál es la probabilidad que una persona escogida aleatoriamente tenga esta enfermedad?\nLos datos del problema son:\n\n\\(T\\): dar positivo al test; \\(P(T)=0.15\\),\n\\(M\\): tener la enfermedad,\n\\(P(T)=0.15\\), \\(P(T^c|M)=0.06\\), \\(P(T|M^c)=0.04\\),\n¿\\(P(M)\\)?\n\n\\[\nP(T) =P(M)\\cdot P(T|M)+P(M^c)\\cdot P(T|M^c).\n\\]\ndonde\n\\[\n\\begin{array}{l}\nP(T|M)=1-P(T^c|M)=0.94 \\\\\nP(M^c)=1-P(M).\n\\end{array}\n\\]\nPor lo tanto\n\\[\n\\begin{array}{rl}\n0.15 & = P(M)\\cdot 0.94+(1-P(M))\\cdot 0.04\\\\\n& =0.04+0.9\\cdot P(M)\\\\\nP(M) & =\\dfrac{0.11}{0.9}\\approx 0.1222.\n\\end{array}\n\\]",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría elemental de la probabilidad</span>"
    ]
  },
  {
    "objectID": "probabilidad.html#sucesos-independientes-vs-disjuntos",
    "href": "probabilidad.html#sucesos-independientes-vs-disjuntos",
    "title": "2  Teoría elemental de la probabilidad",
    "section": "4.1 Sucesos independientes vs disjuntos",
    "text": "4.1 Sucesos independientes vs disjuntos\n\n\n sucesos disjuntos e independencia\n\n\n\nDos sucesos \\(A\\) y \\(B\\) disjuntos, ¿son necesariamente independientes?\nDos sucesos \\(A\\) y \\(B\\) independientes, ¿son necesariamente disjuntos?\n\\(\\emptyset\\) y un suceso cualquiera \\(A\\), ¿son necesariamente independientes?\n\\(\\Omega\\) y un suceso cualquiera \\(A\\), ¿son necesariamente independientes?\n¿Qué condiciones se tienen que dar para que un suceso \\(A\\) sea independiente de si mismo?",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Teoría elemental de la probabilidad</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html",
    "href": "variables_aleatorias.html",
    "title": "3  Variables aleatorias",
    "section": "",
    "text": "3.1 Introducción\nHasta ahora nuestros sucesos han sido de varios tipos: \\(\\{C,+\\}\\) en la moneda, nombres de periódicos, ángulos en una ruleta, número de veces que sale cara en el lanzamiento de una moneda etc.\nNecesitamos estandarizar de alguna manera todos estos sucesos. Una solución es asignar a cada suceso un cierto conjunto de números reales, es decir, convertir todos los sucesos en sucesos de números reales para trabajar con ellos de forma unificada.\nPara conseguirlo utilizaremos unas funciones que transformen los elementos del espacio muestral en números; esta funciones son las variables aleatorias.",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#definición-de-variable-aleatoria",
    "href": "variables_aleatorias.html#definición-de-variable-aleatoria",
    "title": "3  Variables aleatorias",
    "section": "3.2 Definición de variable aleatoria",
    "text": "3.2 Definición de variable aleatoria\nComenzaremos dando una definición poco rigurosa, pero suficiente, de variable aleatoria.\n Variable Aleatoria (definición práctica) \nUna variable aleatoria (v.a.) es una aplicación que toma valores numéricos determinados por el resultado de un experimento aleatorio\n\n\n Notación \n\n\n\nNormalmente representaremos las v.a. por letras mayúsculas \\(X,Y,Z\\ldots\\)\nLos valores que “toman” las v.a. los representaremos por letras minúsculas (las mismas en principio) \\(x,y,z\\ldots\\)\n\n\n\n \n\n\n Ejemplo\n\n\nLanzamos un dado convencional de parchís el espacio muestral del experimento es\n\\[\\Omega=\\{1,2, 3, 4,  5, 6\\}.\\]\nUna v.a \\(X:\\Omega\\to\\mathbb{R}\\) sobre este espacio queda definida por\n\\[X(1)=1, X(2)=2, X(3)=3, (4)=4, X(5)=5, X(6)=6.\\]\n\nAhora el suceso \\(A=\\{2, 4, 6\\}\\), es decir “salir número par”, es equivalente a \\(\\{X=2,X=4,X=6\\}\\).\nEl suceso \\(B=\\{1,2,3\\}\\), es decir “salir un número inferior o igual a \\(3\\)” es en términos de la v.a. \\(\\{X=1,X=2,X=3\\}\\) o también \\(\\{X\\leq\n3\\}\\).\n\nConsideremos el experimento lanzar una anilla al cuello de una botella. Si acertamos a ensartar la anilla en la botella el resultado del experimento es éxito y fracaso en caso contrario.\nEl espacio muestral asociado a este experimento será \\(\\Omega=\\{\\mbox{éxito, fracaso}\\}\\). Construyamos la siguiente variable aleatoria:\n\\[X:\\{\\mbox{éxito, fracaso}\\}\\to\\mathbb{R}\\]\ndefinida por\n\\[X(\\mbox{éxito})=1 \\mbox{ y } X(\\mbox{fracaso})=0.\\]",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#tipos-de-variables-aleatorias",
    "href": "variables_aleatorias.html#tipos-de-variables-aleatorias",
    "title": "3  Variables aleatorias",
    "section": "3.3 Tipos de variables aleatorias",
    "text": "3.3 Tipos de variables aleatorias\nHay dos tipos fundamentales de variables aleatorias, las discretas y las continuas.\nDamos a continuación una definición informal.\n\n\nVariables Aleatorias Discretas y Continuas\n\n\n\nUna variable aleatoria es discreta si sólo puede tomar una cantidad numerable de valores con probabilidad positiva.\nLas variables aleatorias continuas toman valores en intervalos.\nTambién existen las variables aleatorias mixtas; con una parte discreta y otra continua.",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#ejemplo",
    "href": "variables_aleatorias.html#ejemplo",
    "title": "3  Variables aleatorias",
    "section": "3.4 Ejemplo",
    "text": "3.4 Ejemplo\n\n\nEjemplo\n\n\nSon variables aleatorias discretas:\n\nNúmero de artículos defectuosos en un cargamento.\nNúmero de clientes que llegan a una ventanilla de un banco en una hora.\nNúmero de errores detectados en las cuentas de una compañía.\nNúmero de reclamaciones de una póliza de un seguro médico.\n\nSon variables aleatorias continuas:\n\nRenta anual de una familia.\nCantidad de petróleo importado por un país.\nVariación del precio de las acciones de una compañía de telecomunicaciones.\nPorcentaje de impurezas en un lote de productos químicos.",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#variables-aleatorias-discretas",
    "href": "variables_aleatorias.html#variables-aleatorias-discretas",
    "title": "3  Variables aleatorias",
    "section": "3.5 Variables aleatorias discretas",
    "text": "3.5 Variables aleatorias discretas\nPasamos ahora a describir el comportamiento de la v.a. Para ello utilizaremos distintas funciones que nos darán algunas probabilidades de la variable aleatoria.\nEn el caso discreto estas funciones son la de probabilidad, y la función de distribución o de probabilidad acumulada.\nEn el caso discreto la función de probabilidad es la que nos da las probabilidades de los sucesos elementales de la v.a. que definimos a continuación.",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#distribuciones-de-probabilidad-discretas",
    "href": "variables_aleatorias.html#distribuciones-de-probabilidad-discretas",
    "title": "3  Variables aleatorias",
    "section": "3.6 Distribuciones de probabilidad discretas",
    "text": "3.6 Distribuciones de probabilidad discretas\n\n\nFunción de Probabilidad\n\n\nLa función de probabilidad (probability mass function o incluso abusando de notación probability density function) de una variable aleatoria discreta \\(X\\) a la que denotaremos por \\(P_{X}(x)\\) está definida por\n\\[P_{X}(x)=P(X=x),\\]\nes decir la probabilidad de que \\(X\\) tome el valor \\(x\\).\nSi \\(X\\) no asume ese valor \\(x\\), entonces \\(P_{X}(x)=0\\).\nDominio de una variable aleatoria discreta\nEl conjunto \\[D_X=\\{ x\\in\\mathbb{R} \\mid P_X(x)&gt;0\\}\\] recibe el nombre de dominio de la v.a. y son los valores posibles de esta variable.\nEn el caso discreto lo más habitual es que \\(X(\\Omega)=D_X\\).\n\n\n \n\n\n Ejemplo: Dado de parchís\n\n\nLanzamos un dado de parchís una vez, en esta ocasión representaremos los sucesos elementales por el número de puntos de la cara obtenida, tenemos que \\[\\Omega=\\{\\mbox{1-puntos,2-puntos,3-puntos,4-puntos,5-puntos,6-puntos}\\}\\] y la variable aleatoria \\(X:\\Omega\\to \\mathbb{R}\\) viene definida por\n\\[X(\\mbox{i-puntos})=i\\mbox{ para } i=1,2,3,4,5,6.\\]\nSupongamos que el dado está bien balanceado. Entonces \\[\\scriptsize{P_{X}(1)=P_{X}(2)=P_{X}(3)=P_{X}(4)=P_{X}(5)=P_{X}(6)=\\frac16; \\mbox{  concretamente}.}\\]\n\\[\\scriptsize{\nP_{X}(x)=\n  \\left\\{\n  \\begin{array}{ll}\n   \\frac16 ,& \\mbox{si } x=1,2,3,4,5,6.\\\\\n  0 & \\mbox{en otro caso.}\n  \\end{array}\n  \\right.}\n\\]\nSu dominio es \\[D_X=\\{1,2,3,4,5,6\\}.\\]\n\n\n \n\n\n Ejemplo: lanzamiento moneda \n\n\nSea \\(X\\) la v.a. asociada al lanzamiento de una moneda. Su espacio muestral es \\(\\Omega=\\{c,+\\}\\), la v.a. queda definida por:\n\\[X(\\omega)=\\left\\{\\begin{array}{ll} 1 & \\mbox{si } \\omega=c \\\\\n0 & \\mbox{si }\\omega=+\\end{array}\\right.\\] Su función de probabilidad es:\n\\[P_{X}(x)=P(X=x)=\\left\\{\\begin{array}{ll} \\frac12, & \\mbox{si } x=0,1,\\\\\n0, & \\mbox{en otro caso}.\\end{array}\\right.\\]\nFinalmente su dominio es \\(D_X=\\{0,1\\}.\\)\n\n\n \n\n\n Ejemplo: urna con bolas\n\n\nTenemos una urna con tres bolas rojas, una negra y dos blancas. Realizamos una extracción y observamos el color de la bola entonces un espacio muestral es \\[\\Omega=\\{roja, blanca, negra\\}.\\]\nUna variable aleatoria asociada al experimento es:\n\\[X(\\omega)=\\left\\{\\begin{array}{ll} 1, & \\mbox{si } \\omega=roja,  \\\\\n2, & \\mbox{si }\\omega=negra ,\\\\ 3, & \\mbox{si } \\omega=blanca.\\end{array}\\right.\\]\nLa función de probabilidad es\n\\[P_{X}(x)=\\left\\{\\begin{array}{ll} \\frac36, & \\mbox{si } x=1,\\\\[0.5ex]\n\\frac16, & \\mbox{si } x=2,\\\\ \\frac26, & \\mbox{si } x=3,\\\\ 0 & \\mbox{en otro\ncaso.}\\end{array}\\right.\\]\nEl dominio de la v.a. \\(X\\) es \\(D_X=\\{1,2,3\\}.\\)",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#propiedades-de-la-función-de-probabilidad.",
    "href": "variables_aleatorias.html#propiedades-de-la-función-de-probabilidad.",
    "title": "3  Variables aleatorias",
    "section": "3.7 Propiedades de la función de probabilidad.",
    "text": "3.7 Propiedades de la función de probabilidad.\n\n\n Propiedades básicas de la función de probabilidad\n\n\nSea \\(X\\) una v.a. discreta \\(X:\\Omega:\\to\\mathbb{R}\\) con dominio \\(D_X\\). Su función de probabilidad \\(P_{X}\\) verifica las siguientes propiedades:\n\n\\(0\\leq P_{X}(x)\\leq 1\\) para todo \\(x\\in\\mathbb{R},\\)\n\\(\\sum\\limits_{x\\in D_X} P_{X}(x)=1.\\)\n\n\n\n\n\nEjemplo: urna con bolas\n\n\nLanzamos al aire tres veces, de forma independiente, una moneda perfecta. El espacio muestral de este experimento es \\[\\Omega=\\{ccc,cc+,c+c,+cc,c++,+c+,++c,+++\\}\\] (expresados en orden de aparición).\nEste espacio tiene todos los sucesos elementales equiprobables.\nConsideremos la variable aleatoria asociada a este experimento:\n\\[X=\\mbox{ número de caras en los tres lanzamientos}.\\]\nSu función de probabilidad es:\n\\[\n\\begin{array}{l}\nP(X=0)=P(\\{+++\\})=\\frac18,\\\\ P(X=1)=P(\\{c++,+c+,++c\\})=\\frac38,\\\\\n    P(X=2)=P(\\{cc+,c+c,+cc\\})=\\frac38,\\\\\n    P(X=3)=P(\\{ccc\\})=\\frac18.\n\\end{array}\n\\]\nPodemos reescribir la función de probabilidad de \\(X\\) de forma simplificada:\n\\[P_{X}(x)=\\left\\{\\begin{array}{ll} \\frac18, & \\mbox{si } x=0, 3,\\\\[0.5ex]\n\\frac38, & \\mbox{si } x=1,2,\\\\ 0, & \\mbox{en otro caso}.\\end{array}\\right.\\]\nEfectivamente los valores de la función de distribución suman 1:\n\\[\\sum_{x=0}^3 P_X(x)= \\frac18+\\frac38+\\frac38+\\frac18=1.\\]",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#función-de-distribución-de-variables-aleatorias",
    "href": "variables_aleatorias.html#función-de-distribución-de-variables-aleatorias",
    "title": "3  Variables aleatorias",
    "section": "3.8 Función de distribución de variables aleatorias",
    "text": "3.8 Función de distribución de variables aleatorias\n\n\n Función de distribución de Probabilidad (acumuladada)\n\n\nLa función de distribución de probabilidad (acumulada) de la v.a. \\(X\\) (de cualquier tipo; discreta o continua) \\(F_{X}(x)\\) representa la probabilidad de que \\(X\\) tome un menor o igual que \\(x\\), es decir,\n\\[F_{X}(x)=P(X\\leq x).\\]\nEsta función también se denomina función de distribución de probabilidad o simplemente función de distribución de una v.a., y en inglés cumulative distribution function por lo que se abrevia con el acrónimo cdf.\n\n\n \n\n\n Propiedades de la Función de Distribución \n\n\nSea \\(X\\) una v.a. y \\(F_{X}\\) su función de distribución:\n\n\\(P(X&gt;x)=1-P(X\\leq x)=1-F_{X}(x).\\)\nSea a y b tales que \\(a&lt;b\\), \\(P(a&lt;X\\leq b)=P(X\\leq b)-P(X\\leq a)=F_{X}(b)-F_{X}(a).\\)\n\n\n\nDemostración:\nTenemos que el complementario de \\(X\\) mayor que \\(x\\) es: \\(\\overline{\\left\\{X&gt;x\\right\\}}=\\left\\{X&gt;x\\right\\}^c=\\left\\{X\\leq x\\right\\}\\). Además,\n\\[P(X&gt;x)=1-P(\\overline{\\left\\{X&gt;x\\right\\}})=1-P(X\\leq x)=1-F_{X}(x),\\]\nlo que demuestra la primera propiedad.\nPor otro lado, si \\(X\\) se encuentra entre dos valores \\(a\\) y \\(b\\) \\(\\left\\{a&lt; X \\leq b\\right\\}= \\left\\{X\\leq b\\right\\}-\\left\\{X\\leq  a\\right\\}\\). Ahora podemos hacer\n\\[\\begin{eqnarray*}\nP(a&lt;X\\leq b)&=&P(\\left\\{X\\leq b\\right\\}-\\left\\{X\\leq a\\right\\})\\\\\n&=& P(\\left\\{X\\leq b\\right\\})-P(\\left\\{X\\leq a\\right\\})\\\\\n&=& F_{X}(b)-F_{X}(a).\n\\end{eqnarray*}\\]\nLo que finaliza la demistración de la propiedad.\n\n\n Propiedades de la Función de Distribución \n\n\nSea \\(F_{X}\\) la función de distribución de una v.a. \\(X\\) entonces:\n\n\\(0\\leq F_{X}(x)\\leq 1\\).\nLa función \\(F_{X}\\) es no decreciente.\nLa función \\(F_{X}\\) es continua por la derecha.\nSi denotamos por \\(F_X(x_0^{-})=\\displaystyle \\lim_{x\\to x_0^{-}} F(x)\\), entonces se cumple que \\(P(X&lt; x_0)=F_X(x_0^{-})\\) y que \\(P(X=x_0)=F_X(x_0)-F_X(x_0^{-})\\).\nSe cumple que \\(\\displaystyle \\lim_{x\\to\\infty} F_{X}(x)=1\\); \\(\\displaystyle \\lim_{x\\to-\\infty}F_{X}(x)=0\\).\nToda función \\(F\\) verificando las propiedades anteriores es función de distribución de alguna v.a. \\(X\\).\n\n\n\n \n\n\n Advertencia: Desigualdades estrictas \n\n\nEn las propiedades anteriores no se pueden cambiar en general las desigualdades de estrictas o no estrictas.\nVeamos que propiedades tenemos cuando se cambian estas desigualdades.\nDada una \\(F_{X}\\) una función de distribución de la v.a. \\(X\\) y denotamos por \\[F_{X}(x_0^{-})=\\displaystyle \\lim_{x\\to x_0^{-}} F_{X}(x),\\],\nentonces se cumplen las siguientes igualdades:\n\n\\(P(X=x)=F_{X}(x)-F_{X}(x^{-})\\).\n\\(P(a&lt; X&lt; b)=F_{X}(b^{-})-F_{X}(a)\\).\n\\(P(a\\leq X&lt; b)=F_{X}(b^{-})-F_{X}(a^{-})\\).\n\\(P(X&lt;a)=F_{X}(a^{-})\\),\n\\(P(a\\leq X\\leq b)=F_{X}(b)-F_{X}(a^{-})\\).\n\\(P(X\\geq a)=1-F_{X}(a^{-})\\).\n\n\n\n \n\n\n Más propiedades de la función de distribución \n\n\n\nSi \\(F_X\\) es continua en \\(x\\) se tiene que \\(P(X=x)=0\\). Así que si la v.a. es continua \\(P(X\\leq a)=P(X&lt; a)+P(X=a)=P(X&lt;a)\\) y propiedades similares.\nSea \\(X\\) una variable aleatoria discreta que con dominio \\(D_X\\) y que tiene por función de probabilidad \\(P_{X}(x)\\) entonces su función de distribución \\(F_{X}(x_0)\\) es \\[F_{X}(x_0)=\\sum_{x\\leq x_0} P_{X}(x),\\] donde \\(\\sum\\limits_{x\\leq x_0}\\) indica que sumamos todos los \\(x \\in D_X\\) tales que \\(x\\leq\nx_0.\\)\n\n\n\nDemostración:\nSi \\(X\\) es continua, \\[P(X=a)=F(a)-F(a^{-})=F(a)-F(a)=0\\] por lo tanto\n\\[P(X\\leq a)=P(X&lt;a)+P(X=a)= P(X&lt;a)+0= P(X&lt;a),\\]\nlo que demuestra la primera propiedad.\nPara demostrar la segunda basta hacer\n\\[\nF_{X}(x_0)= P(X\\leq x_0)=P\\left(\\bigcup_{x\\leq\nx_0; x\\in D_X} \\{x\\}\\right)= \\sum_{x\\leq x_0}P(X=x)= \\sum_{x\\leq x_0}P_{X}(x).\n\\] Lo que demuestra estas dos propiedades.\n\n\n Ejemplo: dado (continuación)\n\n\nEn el experimento del dado se tiene que:\n\\[P_{X}(x)=\\left\\{\\begin{array}{ll} \\frac16, & \\mbox{si } x=1,2,3,4,5,6\\\\ 0, & \\mbox{en el resto de casos.}\\end{array}\\right.\\]\npor lo tanto\n\\[\\scriptsize{F_{X}(x)=P(X\\leq x)=\\left\\{\\begin{array}{ll}\n   0, & \\mbox{si } x&lt;1,\\\\\n   \\frac16, &\\mbox{si } 1\\leq x&lt;2,\\\\[1ex]\n   \\frac26, &\\mbox{si } 2\\leq x&lt;3,\\\\\n   \\frac36, &\\mbox{si } 3\\leq x&lt;4,\\\\\n   \\frac46, &\\mbox{si } 4\\leq x&lt;5,\\\\\n   \\frac56, &\\mbox{si } 5\\leq x&lt;6,\\\\\n   1, &\\mbox{si } 6\\leq x.\\end{array}\\right.}\\]\nCalculemos más detalladamente algún valor de \\(F_{X}\\), por ejemplo:\n\\[\\begin{eqnarray*}\nF_{X}(3.5) & = & P(X\\leq 3.5)=  P(\\{X=1\\}\\cup\\{X=2\\}\\cup \\{X=3\\})\\\\\n&=& P(\\{X=1\\})+P(\\{X=2\\})+P(\\{X=3\\})\\\\\n&=& \\frac16+\\frac16+\\frac16=\\frac36 =\\frac12,\n\\end{eqnarray*}\\]\no de otra forma\n\\[F_{X}(3.5)=\\sum_{x\\leq 3.5} P_X(x)=\\sum_{x=1}^3 P(X=x)=\\sum_{x=1}^3 \\frac16= 3 \\cdot\n   \\frac16=\\frac12.\n\\]\n\n\n \n\n\n Propiedades\n\n\nSea \\(X\\) una variable con función de distribución \\(F_{X}\\) entonces:\n\n\\(0\\leq F_{X}(x)\\leq 1\\) para todo \\(x\\),\nSi \\(x&lt;x'\\), entonces \\[F_{X}(x)\\leq F_{X}(x').\\] Es una función creciente,es decir, no necesariamente estrictamente creciente.\n\\(\\displaystyle \\lim_{x\\to -\\infty}F_{X}(x)=0\\) y \\(\\displaystyle \\lim_{x\\to +\\infty}F_{X}(x)=1.\\)\nEs continua por la derecha \\(\\displaystyle \\lim_{x\\to x_0^{+}}F_{X}(x)=F_{X}(x_0)\\).",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#momentos-de-variables-aleatorias-discretas",
    "href": "variables_aleatorias.html#momentos-de-variables-aleatorias-discretas",
    "title": "3  Variables aleatorias",
    "section": "3.9 Momentos de variables aleatorias discretas",
    "text": "3.9 Momentos de variables aleatorias discretas\nAl igual que en la estadística descriptiva se utilizan distintas medidas para resumir los valores centrales y para medir la dispersión de una muestra, podemos definir las correspondiente medidas para variables aleatorias.\nA estas medidas se les suele añadir el adjetivo poblacionales mientras que a las que provienen de la muestra se las adjetiva como muestrales.\nPor ejemplo podemos buscar un valor que resuma toda la variable. Este valor es el que “esperamos” que se resuma la v.a. o esperamos que las realizaciones de la v.a. queden cerca de él. Demos su definición formal.\n\n3.9.1 Esperanza de un variable aleatoria discreta\n\n\n Esperanza de una variable aleatoria discreta\n\n\nEl valor esperado o esperanza (expected value en inglés) \\(E(X)\\) de una v.a. discreta \\(X\\), se define como\n\\[\nE(X)=\\sum_{x\\in X(\\Omega)} x\\cdot P_{X}(x).\n\\]\nEn ocasiones se denomina media (mean en inglés, mitjana en catalán) poblacional o simplemente media y muy frecuentemente se la denota \\(\\mu_{X}=E(X)\\) o simplemente \\(\\mu=E(X)\\).\n\n\n \n\n\n Ejemplo: Intepretación de de la media\n\n\nEjemplo: lanzamiento de un dado \\(n\\) veces\nSupongamos que lanzamos un dado \\(n\\) veces y obtenemos unas frecuencias absolutas \\(n_{i}\\) para el resultado \\(i\\) con \\(i=1,\\ldots,6\\). Sea \\(X\\) la v.a. que nos representa el valor de una tirada del dado.\nCalculemos la media aritmética (o media muestral) de los datos\n\\[\n\\overline{x}=\\frac{1\\cdot n_1+2\\cdot  n_2+3\\cdot  n_3+4\\cdot  n_4+5\\cdot  n_5+6 \\cdot\nn_6}{n}=\\sum_{x=1}^6 x \\cdot \\frac{n_{x}}{n}.\n\\]\nSi \\(n\\to \\infty\\) se tiene que \\(\\displaystyle\\lim_{n\\to \\infty} \\frac{n_{x}}{n}=P_{X}(x).\\) Por lo tanto \\(E(X)=\\displaystyle \\lim_{n\\to\\infty}\\sum_{x=1}^6x \\cdot \\frac{n_{x}}{n}.\\)\nEntonces el valor esperado en una v.a. discreta puede entenderse como el valor promedio que tomaría una v.a. en un número grande de repeticiones.\n\n\n \n\n\n Ejemplo: Erratas en un texto\n\n\nSea \\(X\\)= número de erratas en una página de un texto con dominio \\(D_X=\\{0,1,2\\}\\).\nResulta que\n\\[\\begin{align*}\nP(X=0)&= 0.42,\\ P(X=1)=0.4,\\ P(X=2)=0.18, \\mbox{ por lo tanto, }\\\\\nE(X)&= 0\\cdot 0.42+ 1\\cdot 0.4 + 2 \\cdot 0.18=0.76.\n\\end{align*}\\]\nElegida una página del texto al azar esperamos encontrar \\(0.76\\) errores por página.\nSupongamos que el editor nos paga \\(2\\) euros por cada página que encontremos con \\(1\\) error y \\(3\\) euros por cada página con dos errores (y nada por las páginas correctas) ¿Cuánto esperamos cobrar si analizamos una página?\n\n\n\n\n Propiedad: Esperanzas de funciones de variables aleatorias discretas\n\n\nSea \\(X\\) una v.a. discreta con función de probabilidad \\(P_{X}\\) y de distribución \\(F_{X}\\). Entonces el valor esperado de una función \\(g(x)\\) es:\n\\[E(g(X))=\\sum_{x}g(x) \\cdot  P_{X}(x).\\]\n\n\n\n\n Propiedades\n\n\n\n\\(E(k)=k\\) para cualquier constante \\(k\\).\nSi \\(a\\leq X\\leq b\\) entonces \\(a\\leq E(X)\\leq b\\).\nSi \\(X\\) es una v.a. discreta que toma valores enteros no negativos entonces \\(E(X)=\\sum_{x=0}^{+\\infty}(1- F_X(x)).\\)\n\n\n\nLa demostración de las propiedades anteriores se deja como ejercicio.\n\n\n Ejemplo: paleta de colores aleatoria\n\nSupongamos que estamos sentados delante de nuestro ordenador con un amigo y le decimos que en dos minutos podemos programar una paleta para poner colores a unos gráficos.\nQueremos que la paleta tenga dos botones con las opciones color rojo y color azul. Como hemos programado a gran velocidad resulta que el programa tiene un error; cada vez que se abre la paleta los colores se colocan al azar (con igual probabilidad) en cada botón, así que no sabemos en qué color hemos de pinchar.\nAdemás, como nos sobraron \\(15\\) segundos para hacer el programa y pensando en la comodidad del usuario, la paleta se cierra después de haber seleccionado un color y hay que volverla a abrir de nuevo.\nLa pregunta es ¿cuál es el valor esperado del número de veces que hemos pinchar el botón de color azul antes de obtener este color?\nLlamemos \\(X\\) al número de veces que pinchamos en el botón azul (y nos sale rojo) hasta obtener el primer azul. La variable \\(X\\) toma valores en los enteros no negativos. Su función de probabilidad queda determinada por\n\\[\nP_X(x)=P(X=x)=P(\\stackrel{x \\mbox{ veces}}{\\overbrace{rojo, rojo,\\ldots,rojo},azul})\n=\\left(\\frac12\\right)^{x+1}.\n\\]\n\n:::::",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#series-geométricas",
    "href": "variables_aleatorias.html#series-geométricas",
    "title": "3  Variables aleatorias",
    "section": "3.10 Series geométricas",
    "text": "3.10 Series geométricas\nSeries geométricas\n\nUna progresión geométrica de razón \\(r\\) es una sucesión de la forma\n\\[\nr^0, r^1,\\ldots,r^n,\\ldots.\n\\]\nLa serie geométrica es la suma de todos los valores de la progresión geométrica \\(\\displaystyle\\sum_{k=0}^{+\\infty} r^k\\).\nLas sumas parciales desde el término \\(n_0\\) al \\(n\\) de una progresión geométrica valen \\[\n\\sum_{k=n_0}^n r^k=\\frac{r^{n_0}- r^n r}{1-r}.\n\\]\n\n\n\n Propiedades \n\n\n\nSi \\(|r|&lt;1\\) la serie geométrica es convergente y \\[\\sum_{k=0}^{+\\infty }\nr^k=\\frac1{1-r}\\].\nEn el caso en que se comience en \\(n_0\\) se tiene que \\[\\sum_{k=n_0}^{+\\infty} r^k=\\frac{r^{n_0}}{1-r}.\\]\nSi \\(|r|&lt;1\\) también son convergentes las derivadas, respecto de \\(r\\), de la serie geométrica y convergen a la derivada correspondiente. Así tenemos que\n\n\\[\\begin{eqnarray*}\n\\left(\\sum_{k=0}^{+\\infty} r^k\\right)'= & \\sum_{k=1}^{+\\infty}k\nr^{k-1}; \\qquad  \\left(\\frac1{1-r}\\right)'=\\frac1{(1-r)^2}\\\\\n\\left(\\sum_{k=0}^{+\\infty} r^k\\right)^{''}=&\\sum_{k=2}^{+\\infty}k (k-1)\nr^{k-2}  ;\\qquad  \\left(\\frac1{1-r}\\right)^{''}=\\frac2{(1-r)^3}\n\\end{eqnarray*}\\].\n\n\n \n\n\n Ejemplo: paleta de colores (continuación)\n\n\nSi seguimos con el ejemplo de la paleta de colores, su esperanza es:\n\\[E(X)=\\sum_{x=0}^{+\\infty} x\\cdot  P(X=x)=\\sum_{x=0}^{+\\infty} x\\cdot\n\\left(\\frac12\\right)^{x+1}=  \\left(\\frac12\\right)^2\\sum_{x=1}^{+\\infty} x\\cdot\n\\left(\\frac12\\right)^{x-1}=\\left(\\frac12\\right)^2\\cdot\n\\frac1{\\left(1-\\frac12\\right)^2}=1.\n\\]\nAhora calculemos su función de distribución\n\\[F_X(x)= P(X\\leq x)=\\sum_{k=0}^x P(X=k)=\\sum_{k=0}^x\n\\left(\\frac12\\right)^{k+1}= \\frac{\\frac12-\\frac12^{x+1}\\cdot\n\\frac12}{1-\\frac12}=1-\\left(\\frac12\\right)^{x+1}.\n\\] Como la variable toma valores enteros positivos, podemos calcular su valor esperado de esta otra manera\n\\[E(X)=\\sum_{x=0}^{+\\infty} (1-F_X(x))=\\sum_{x=0}^{+\\infty}\\left(\\frac12\\right)^{x+1}=\\frac12\\cdot\n\\frac1{1-\\frac12}=1.\\]\nCalculad el valor esperado de la variable\n\\[\nY=\\mbox{número de intentos para conseguir el color azul.}\n\\]",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#momentos-de-una-variable-aleatoria.-varianza",
    "href": "variables_aleatorias.html#momentos-de-una-variable-aleatoria.-varianza",
    "title": "3  Variables aleatorias",
    "section": "3.11 Momentos de una variable aleatoria. Varianza",
    "text": "3.11 Momentos de una variable aleatoria. Varianza\n\n\nDefinición: Momentos de orden \\(m\\) \n\n\nLlamaremos momento de orden \\(m\\) respecto al punto \\(C\\) a \\[E\\left((X-C)^m\\right).\\]\n\nCuando \\(C=0\\) los momentos reciben el nombre de momentos respecto al origen.\nCuando \\(C=E(X)\\) reciben el nombre de momentos centrales o respecto de la media. Luego la esperanza es el momento de orden \\(1\\) respecto al origen. Estos momentos son la versión poblacional de los momentos que vimos en el curso de estadística descriptiva, recibiendo estos último el nombre de momentos muestrales.\n\n\n\nResumen de conceptos:\n\nHemos descrito el comportamiento aleatorio de una v.a. discreta mediante sus funciones de probabilidad \\(P_{X}\\) y de distribución \\(F_{X}\\).\nTambién tenemos un valor central; el valor esperado \\(E(X)\\).\nComo medida básica nos queda definir una medida de lo lejos que están los datos del valor central \\(E(X)\\) una de estas medidas es la varianza de \\(X\\).",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#medidas-de-la-variabilidad",
    "href": "variables_aleatorias.html#medidas-de-la-variabilidad",
    "title": "3  Variables aleatorias",
    "section": "3.12 Medidas de la variabilidad",
    "text": "3.12 Medidas de la variabilidad\n\n\nDefinición: Varianza\n\n\nSea \\(X\\) una v.a. Llamaremos varianza de \\(X\\) a\n\\[Var(X)=E((X-E(X))^2).\\]\nPor lo tanto, la varianza es el momento central de orden \\(2\\).\nDe forma frecuente se utiliza la notación \\[\\sigma_{X}^2=Var(X).\\]\nA la raíz cuadrada positiva de la varianza \\[\\sigma_{X}=+\\sqrt{Var(X)}.\\]\nse la denomina desviación típica o estándar de \\(X\\).\n\n\n\n\n&gt; Propiedad \n\n\n\nSi \\(X\\) es una v.a. discreta con función de probabilidad \\(P_X\\) su varianza es \\[\\sigma_{X}^2=Var(X)=E((X-E(X))^2)=\\sum_{x}(x-E(X))^2\\cdot  P_{X}(x).\\]\nSea \\(X\\) una v.a. \\[Var(X)=E(X^2)-(E(X))^2=\\sum_{x} x^2\\cdot  P_{X}(X)-(E(X))^2\\]\n\n\n\nDemostración\nDemostración de b)\n\\[\\begin{eqnarray*}\nVar(X)&= & \\sum_{x}(x-E(X))^2 P_{X}(x) = \\sum_{x}(x^2 -2\\cdot x\\cdot E(X)+(E(X)^2)\\cdot P_{X}(x)\\\\\n&=& \\sum_{x}x^2\\cdot P_{X}(x) -  E(X)\\sum_{x}2\\cdot x \\cdot P_{X}(x) + (E(X)^2)\\cdot\\sum_{x} P_{X}(x)\\\\\n&=& E(X^2)- 2 E(X)\\cdot E(X) + (E(X))^2=E(X^2)-(E(X))^2.\n\\end{eqnarray*}\\]\nSe deja como ejercicio la primera afirmación.\n\n\nEjemplo: número de errores (continuación) \n\n\nCalculemos en el ejemplo del contero de errores la varianza de estos.\nRecordemos que:\n\\[\nP(X=0)=0.42,\\quad P(X=1)=0.4, \\quad P(X=2)=0.18,\n\\]\ny que\n\\[\nE(X)=0.76.\n\\]\nEntonces:\n\\[\nVar(X)=E(X^2)-(E(X))^2 = E(X^2)-(0.76)^2.\n\\]\nAhora necesitamos calcular\n\\[E(X^2)= 0^2 (0.41)+ 1^2 (0.4)+ 2^2 (0.18)=0.4+0.72=1.12\\] y por lo tanto\n\\[Var(X)= E(X^2)-(0.76)^2=1.12-0.5776=0.542\\] y \\[\\sqrt{Var(X)}=\\sqrt{0.542}\\]\nEn resumen \\(\\sigma_{X}^2=0.542\\) y \\(\\sigma_{X}=\\sqrt{0.542}\\)",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#propiedades-de-la-varianza",
    "href": "variables_aleatorias.html#propiedades-de-la-varianza",
    "title": "3  Variables aleatorias",
    "section": "3.13 Propiedades de la varianza",
    "text": "3.13 Propiedades de la varianza\n Propiedades de la varianza\n\n\\(Var(X)\\geq 0\\).\n\\(Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0\\).\nEl mínimo de \\(E((X-C)^2)\\) se alcanza cuando \\(C=E(X)\\) y es \\(Var(X)\\). Esta propiedad es una de las que hace útil a la varianza como medida de dispersión.\n\n\nEjercicio\nSe deja como ejercicio la demostración de estas propiedades.",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#se-la-denomina-desviación-t",
    "href": "variables_aleatorias.html#se-la-denomina-desviación-t",
    "title": "3  Variables aleatorias",
    "section": "3.14 se la denomina desviación t",
    "text": "3.14 se la denomina desviación t\n\n\n Transformación lineal \n\n\nUn cambio de variable lineal o transformación lineal de una v.a. \\(X\\) es otra v.a. \\(Y= a+ b\\cdot  X\\) donde \\(a,b\\in\\mathbb{R}\\).\n\n\n \n\n\nEPorpiedad: Esperanza de una trnaformación lineal \n\n\nSea \\(X\\) una v.a. con \\(E(X)=\\mu_{X}\\) y \\(Var(X)=\\sigma_{X}^2\\) y \\(a,b\\in\\mathbb{R}\\). Entonces si \\(Y=a+b\\cdot  X\\):\n\n\\(E(Y)=E(a + b X)=a+ b E(X)= a + b \\cdot \\mu_{X}\\).\n\\(Var(Y)=Var(a+bX)=b^2 Var(X)= b^2\\cdot  \\sigma_{X}^2\\)-\n\\(\\sigma_{Y}=\\sqrt{Var(Y)}=\\sqrt{b^2 Var(X)}=|b| \\cdot \\sigma_{X}\\)-\n\n\n\nDemostración:\n\\[\\begin{eqnarray*}\nE(Y)&=& E(a+bX)=\\sum_{x}(a+b\\cdot x)\\cdot P_{X}(x)\\\\\n&=& a \\sum_{x} P_{X}(x) + b \\sum_{x} x\\cdot P_{X}(x)\\\\\n&=& a + b\\cdot E(X)=a + b\\cdot\\mu_{X}.\n\\end{eqnarray*}\\]\nLo que demuestra esta propiedad, las emás se dejan comom ejercicio.",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#variables-aleatorias-continuas.",
    "href": "variables_aleatorias.html#variables-aleatorias-continuas.",
    "title": "3  Variables aleatorias",
    "section": "3.15 Variables aleatorias continuas.",
    "text": "3.15 Variables aleatorias continuas.\nComo ya hemos dicho las variables aleatorias continuas toman valores en intervalos o áreas.\nLo más habitual es que estas variables tengan función de distribución continua y derivable (salvo a los más en una cantidad finita o numerable de puntos:-)).\nEn lo que sigue supondremos que la función de distribución de variables aleatorias continuas cumplen estas propiedades.\nNotemos que si \\(X\\) es una v.a. con función de distribución continua se tiene que \\(P(X=x_0)=F_X(x_0)-F(x_0^{-})=0\\). Por lo que no tiene sentido definir función de probabilidad.\nEn general tendremos que \\(P(X&lt;x_0)=P(X\\leq x_0)\\).\nPor otra parte podemos utilizar una regla parecida del cociente entre casos favorables y casos posibles de Laplace pero en este caso el conteo se hace por la medida de los casos posibles partida por la medida de los casos favorables.\nVeamos un ejemplo de v.a. continua, que ampliaremos en el tema siguiente, en el que se utilizan todos estos conceptos.\n\n\n Ejemplo: Distribución uniforme en \\([0,1]\\)\n\n\nEjemplo: distancia dardo centro de la diana\nSupongamos que lanzamos un dardo a una diana de radio \\(1\\), de forma que sea equiprobable cualquier distancia al centro (¡Cuidado! esto no es equivalente que cualquier punto de la diana sea equiprobable).\nConsideremos la v.a. continua \\(X=\\) distancia al centro de la diana.\nSu función de distribución es\n\\[\nF_{X}(x)=\n\\left\\{\n\\begin{array}{ll}\n0, & \\mbox{si } x\\leq 0,\\\\\nx, & \\mbox{si } 0&lt;x&lt;1,\\\\\n1, & \\mbox{si } x\\geq 1.\n\\end{array}\n\\right.\n\\]\nconsideremos\n\nC.F. longitud favorable que es \\(x-0\\),\nC.P. longitud posible que es \\(1-0\\),\n\nluego\n\\[P(X\\leq x)=\\frac{C.F.}{C.P.}=\\frac{x-0}{1-0}=x.\\]\nel siguente código grafica la función de distribución uniforme\n\ncurve(punif(x,0,1),xlim=c(-1,2),col=\"blue\",\n      main=\"Función de distribución de una v.a. \\n\n      uniforme en el intervalo unidad.\")\n\n\n\n\n\n\n\n\n\n\n\n\n Propiedades\n\n\nEn las variables continuas los sucesos del tipo \\(\\{X\\leq x \\}\\) y \\(\\{X&lt; x \\}\\) tendrán la misma probabilidad. Otras identidades similares son :\n\n\\(P(X\\leq b)=P(X&lt;b)\\).\n\\(P(X&lt;b)=P(X&lt;a)+P(a&lt;X&lt;b)\\).\n\\(P(a&lt;X&lt;b)=P(X&lt;b)-P(X&lt;a)\\).\n\n\n\nDemostración:\nAlgunas identidades son evidentes \\(P(X\\leq b)=P(X&lt;b)+P(X=b)=P(X&lt;b).\\)\nPara otras, como la siguiente, podemos hacer\n\\[\\{X\\leq a\\}\\cap \\{a&lt;X&lt;b\\}=\\emptyset\\] \\[\\{X\\leq a\\}\\cup \\{a&lt;X&lt;b\\}=\\{X&lt;b\\},\\]\nentonces\n\\(P(X&lt; b)= P(\\{X\\leq a\\}\\cup \\{a&lt;X&lt;b\\}) = P(X\\leq a)+P(a&lt;X&lt;b)= P(X&lt; a)+P(a&lt;X&lt;b).\\)\nLa demostración de las otras propiedades las dejamos como ejercicio.\n \n\n\nPropiedades de la Función de Distribución \n\n\nLas propiedades anteriores y combinaciones de ellas se pueden escribir utilizando la función de distribución de \\(X\\):\nDada una variable aleatoria continua se tiene que:\n\n\\(F_{X}(b)=F_{X}(a)+P(a&lt;X&lt;b)\\).\n\\(P(a&lt;X&lt;b)=F_{X}(b)-F_{X}(a)\\).\n\\(P(a\\leq X\\leq b)=F_{X}(b)-F_{X}(a)\\).\n\n\n\nSe deja la demostración como ejercicio.\n\n\n Ejemplo  Ejemplo\n\n\nEjemplo: diana (continuación)\nEn el ejemplo de la diana:\n\\[P(0.25&lt;X&lt;0.3)=F_{X}(0.3)-F_{X}(0.25)=0.3-0.25=0.05.\\]\n\n\n \n\n\n Definición: Función de densidad\n\n\nUna función \\(f:\\mathbb{R}\\to\\mathbb{R}\\) es una función de densidad sobre \\(\\mathbb{R}\\) si cumple que\n\n\\(f_{X}(x)\\geq 0\\) para todo \\(x \\in\\mathbb{R}.\\)\n\\(f\\) es continua salvo a lo más en una cantidad finita de puntos sobre cada intervalo acotado de \\(\\mathbb{R}\\).\n\\(\\displaystyle\\int\\limits_{-\\infty}^{+\\infty} f_{X}(x) dx=1.\\)\n\n\n\n\n\n Propiedad: relación entre la función de distribcuión y la densidad\n\n\nSea \\(X\\) una v.a. con función de distribución \\(F_X\\). Sea \\(f:\\mathbb{R}\\to\\mathbb{R}\\) una función de densidad tal que\n\\[F_X(x)=\\displaystyle\\int_{-\\infty}^{x} f_X(t) dt.\\mbox{ para todo } x\\in\\mathbb{R},\\]\nEntonces \\(X\\) es una variable aleatoria continua y \\(f_X\\) es la densidad de la v.a. \\(X\\).\nAdemás el los valores de \\(F_X\\) son continuos y derivables en los puntos donde \\(f_X\\) es continua y la derivada de la función de distribución es una densidad \\(F'_x(x)=f_X(x)\\).\n\n\n \n\n\n Definición: Dominio de una variable aleatoria continua\n\n\nEl conjunto \\(D_X=\\{x\\in\\mathbb{R}| f_x(x)&gt;0\\}\\) recibe el nombre de  soporte o dominio de la variable aleatoria continua y se interpreta como su conjunto de resultados posibles.\n\n\n \n\n\n Ejemplo: diana (continuación) \n\n\nEn nuestra ejemplo de la diana, la función \\(f\\) es una densidad\n\\[\nf_{X}(x)=\\left\\{\n\\begin{array}{ll}\n0, & \\mbox{si } x\\leq 0,\\\\\n1, & \\mbox{si } 0 &lt; x &lt; 1,\\\\\n0, & \\mbox{si } 1\\leq x.\n\\end{array}\\right.\n\\]\nque es la densidad de \\(X\\), en efecto:\n\\[\nf_{X}(x)=\\left\\{\n\\begin{array}{ll}\n0, & \\mbox{si } x\\leq 0,\\\\\n1, & \\mbox{si } 0 &lt; x &lt; 1,\\\\\n0, & \\mbox{si } 1\\leq x.\n\\end{array}\\right.\n\\]\n\nSi \\(x \\leq 0\\) entonces \\(\\displaystyle\\int_{-\\infty}^x f_X(t) dt = 0.\\)\nSi \\(0\\leq x\\leq 1\\) entonces \\(\\displaystyle\\int_{-\\infty}^x f_X(t) dt = \\int_0^x 1 dt = x.\\)\nSi \\(x\\geq 1\\) entonces \\(\\displaystyle\\int_{-\\infty}^x f_X(t) dt = \\int_0^1 1 dt = 1.\\)\n\nPor lo tanto, \\(F_X(x)=\\displaystyle\\int_{-\\infty}^x f_X(t) dt\\) para todo \\(x\\in\\mathbb{R}.\\)\n\ncurve(dunif(x,0,1),xlim=c(-0.5,1.5),col=\"blue\",\n      main=\"Densidad de la distribución uniforme en [0,1]\")\n\n\n\n\n\n\n\n\n\n\n \n\n\n Propiedades \n\n\nLa función de densidad nos permite calcular diversas probabilidades.\nPropiedades de la función de densidad \n\nSea \\(X\\) una v.a. continua con función de distribución \\(F_X\\) y de densidad \\(f_X\\), entonces \\[\\begin{eqnarray*}\nP(a&lt; X&lt; b) &=&  P(a&lt;X\\leq b)= P(a\\leq X&lt; b)=\\\\\n& & P(a\\leq X\\leq b)= \\displaystyle\\int_{a}^b f_X(x) dx.\n\\end{eqnarray*}\\]\nSi \\(A\\) es un subconjunto adecuado de \\(\\mathbb{R}\\) entonces \\[P(X\\in A)=\\displaystyle\\int_{A} f(x) dx=\\displaystyle\\int_{A\\cap D_X} f(x) dx.\n\\]\n\nPropiedades de la función de densidad \nSea \\(X\\) una v.a. continua con función de distribución \\(F_X\\) y de densidad \\(f_X\\), entonces:\n\nSi \\(f_x\\) es continua en un punto \\(x\\), \\(F_X\\) es derivable en ese punto y \\(F_X'(x)=f_X(x).\\)\n\\(P(X=x)=0\\) para todo \\(x\\in\\mathbb{R}.\\)\n\n\n\n \n\n\n Ejercicio \n\n\nComprobar estas propiedades en el ejemplo de la diana.\n\n\n \n\n\n Ejemplo tiempo ejecución de un proceso\n\n\nSea \\(X=\\) tiempo de ejecución de un proceso. Se supone que \\(X\\) sigue una distribución uniforme en dos unidades de tiempo, si tarda más el proceso se cancela.\nCalculemos la función de densidad y de distribución de la v.a \\(X\\).\nEntonces\n\\[\nF_{X}(x)=P(X\\leq x)=\\frac{CF}{CP}=\\frac{x}2.\n\\]\nLuego su función de distribución es:\n\\[\nF_{X}(x)=\\left\\{\\begin{array}{ll}\n0, & \\mbox{si } x\\leq 0,\\\\\n\\frac{x}2 & \\mbox{si } 0&lt;x&lt;2,\\\\\n1, & \\mbox{si } 2\\leq x.\n\\end{array}\\right.\n\\]\nSu función de densidad por su lado es: \\[\nf_{X}(x)=F_{X}'(x)=\\left\\{\\begin{array}{ll}\n0 & \\mbox{si } x\\leq 0\\\\\n\\frac12 & \\mbox{si } 0&lt;x\\leq 2\\\\\n0 & \\mbox{si } 2\\leq x\n\\end{array}\\right.\n\\]\nEfectivamente\n\n\\(f_{X}(x)\\geq 0,\\) y tiene un conjunto finito de discontinuidades: en \\(0\\) y en \\(2\\)\n\\(F_X(x)=\\displaystyle\\int_{-\\infty}^x f_X(t) dt,\\) para todo \\(x\\in \\mathbb{R}\\) (Ejercicio: resolverlo gráficamente.)\n\\(\\displaystyle\\int_{-\\infty}^{+\\infty}f_{X}(x)dx=\n\\int_0^2\\frac12dx=\\left[\\frac{x}2\\right]_0^2\n=\\frac22-\\frac02=1.\\)\n\n\n\n \n\n\n Ejercicio: Tiempo de un proceso \n\n\nCalcular la probabilidad de que uno de nuestros procesos tarde más de una unidad de tiempo en ser procesado. Calcular también la probabilidad de que dure entre \\(0.5\\) y \\(1.5\\) unidades de tiempo.",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#esperanza-y-varianza-para-variables-aleatorias-continuas",
    "href": "variables_aleatorias.html#esperanza-y-varianza-para-variables-aleatorias-continuas",
    "title": "3  Variables aleatorias",
    "section": "3.16 Esperanza y varianza para variables aleatorias continuas",
    "text": "3.16 Esperanza y varianza para variables aleatorias continuas\nAlgunas de estas propiedades ya han sido estudiadas en el caso de variables aleatorias discretas. Por ello, en esta sección nos centraremos en presentar sus definiciones, métodos de cálculo y algunos ejemplos en el contexto continuo.\nA partir de ahora, salvo indicación en contrario, consideraremos que \\(X\\) es una variable aleatoria continua con función de densidad \\(f_{X}(x)\\)\n\n\n Definición: Esperanza y Varianza v.a. continuas\n\n\n\nSu esperanza es: \\[E(X)=\\displaystyle\\int\\limits_{-\\infty}^{+\\infty} x\\cdot f_{X}(x)dx.\\]\nSi \\(g(x)\\) es una función de la variable \\(X\\) entonces: \\[E(g(X))=\\displaystyle\\int\\limits_{-\\infty}^{+\\infty} g(x)\\cdot f_{X}(x)dx.\\]\nVarianza \\[\\sigma_{X}^2=E((X-\\mu_{X})^2)=\n  \\displaystyle\\int\\limits_{-\\infty}^{+\\infty} (x-\\mu_{X})^2 \\cdot f_{X}(x)dx.\n  \\]\nSu desviación típica es: \\[\\sigma_{X}=+\\sqrt{\\sigma_{X}^2}.\\]\n\n\n\n \n\n\n Propiedades \n\n\n\n\\(\\sigma_{X}^2\\geq 0\\).\n\\(Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0\\).\n\\(\\displaystyle Var(x)=E(X^2)-\\mu_{X}^2=\\int_{-\\infty}^{+\\infty}x^2\\cdot  f_{X}(x)dx - \\mu_{X}^2.\\)\nEl mínimo de \\(E((X-C)^2)\\) se alcanza cuando \\(C=E(X)\\) y es \\(Var(X)\\).\n\n\n\n \n\n\n Ejemplo: diana (continuación) \n\n\n\\[\\mu_{X}=  \\int_0^1 x  dx=\\left[\\frac{x}{2}\\right]_0^1=\\frac12,\\] \\[E(X^2)=\\int_0^1 x^2 dx=\\left[\\frac{x^3}{3}\\right]_0^1=\\frac13,\\]\n\\[Var(X)=E(X^2)-E(X)^2=\\frac13-\\left(\\frac12\\right)^2=\\frac1{12}.\\] Podemos comprobar que con la definición directa el resultado es el mismo\n\\[\nVar(X)=E\\left(\\left(X-E(X)\\right)^2\\right)=\n\\int_0^1 \\left(x-\\frac12\\right)^2 dx=\n\\left[\\frac13 \\left(x-\\frac12\\right)^3\\right]_0^1=\n\\frac13\\cdot \\left(\\left(1-\\frac12\\right)^3-\\left(0-\\frac12\\right)^3\\right)\n= \\frac13\\left(\\frac18-\\left(-\\frac18\\right)\\right)=\\frac13\\cdot \\frac28=\\frac1{12}.\n\\]",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#esperanza-de-transformaciones-lineales-de-v.a.-continuas",
    "href": "variables_aleatorias.html#esperanza-de-transformaciones-lineales-de-v.a.-continuas",
    "title": "3  Variables aleatorias",
    "section": "3.17 Esperanza de transformaciones lineales de v.a. continuas",
    "text": "3.17 Esperanza de transformaciones lineales de v.a. continuas\n\n\n Propiedad\n\n\nSea \\(X\\) una v.a. continua con \\(E(X)=\\mu_{X}\\) y \\(Var(X)=\\sigma_{X}^2\\) sea \\(Y=a+b X\\), donde \\(a,b\\in\\mathbb{R}\\), es una nueva v.a. continua obtenida mediante una transformación lineal de \\(X\\). Se verifican las mismas propiedades que en el caso discreto:\n\n\\(E(Y)=E(a+b\\cdot  X)=a+b\\cdot  E(X)\\).\n\\(Var(Y)=Var(a+b\\cdot  X)=b^2 \\cdot  Var(X)\\).\n\\(\\sigma_{Y}=|b|\\cdot  \\sigma_{X}\\).\n\\(Z=\\frac{X-\\mu_{X}}{\\sigma_{X}}\\) es una transformación lineal de \\(X\\) de forma que \\[E(Z)=0 \\mbox{ y } Var(Z)=1\\]\n\n\n\n \n\n\n Ejemplo \n\n\nEn una empresa de venta de vinos por internet, sea \\(X=\\) número de litros de vino del país vendidos en un año. Supongamos que sabemos que \\(E(X)=10000\\) y que \\(Var(X)=100.\\) Supongamos que los gastos fijos de distribución son 50.000 € y el beneficio por litro es de 10 € por botella. Definimos \\(T=10\\cdot X-50000,\\) que será el beneficio después de gastos.\nEntonces la esperanza del beneficio es \\[E(T)=10 E(X)-50000 = 50000,\\] y \\[Var(T)=10^2 Var(X)= 10000.\\]",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#transformaciones-de-variables-aleatorias",
    "href": "variables_aleatorias.html#transformaciones-de-variables-aleatorias",
    "title": "3  Variables aleatorias",
    "section": "3.18 Transformaciones de variables aleatorias",
    "text": "3.18 Transformaciones de variables aleatorias\nMuchas variables aleatorias son funciones de otras v.a. En lo que sigue resumiremos diversas técnicas para dada una v.a. \\(X\\) y una transformación \\(Y=h(X)\\) encontrar \\(F_{Y}\\) a partir de \\(F_{X}\\).\n\n\nPropiedad: Transformaciones de v.a. discretas \n\n\nSea \\(X\\) una v.a. discreta con \\(X(\\Omega)=\\{x_1,x_2,\\ldots,x_{n},..\\}\\) y sea \\(h:\\mathbb{R}\\to\\mathbb{R}\\) una aplicación. Entonces \\(Y=h(X)\\) es también una v.a. discreta. Además si \\(P_X\\) y \\(F_{X}\\) son las funciones de probabilidad y de distribución de \\(X\\) entonces\n\n\\(\\displaystyle P_{Y}(y)=\\sum_{x_{i}|h(x_{i})=y}P_X(x_{i}).\\)\n\\(\\displaystyle F_{Y}(y)=\\sum_{x_{i}|h(x_{i})\\leq y} P_X(x_{i}).\\)\n\n\n\nDesafortunadamente para variables no discretas el resultado no es tan sencillo como el anterior, pues la transformación de, por ejemplo, una v.a. continua puede ser continua, discreta, mixta,\\(\\ldots\\)\n\n\nPropiedad: Transformación de v.a. continuas en continuas** \n\n\nSea \\(X\\) una v.a. continua cuya función de densidad es \\(f_{X}\\). Sea \\(h:\\mathbb{R}\\to\\mathbb{R}\\), una aplicación estrictamente monótona y derivable, por lo tanto \\(h'(x)\\not=0\\) para todo \\(x\\in\\mathbb{R}\\). Sea \\(Y=h(X)\\) la transformación de \\(X\\) por \\(h\\). Entonces \\(Y\\) es una v.a. continua con función de densidad\n\\[f_{Y}(y)=\\left.\\frac{f_{X}(x)}\n{\\left|h'(x)\\right|}\\right|_{x=h^{-1}(y)}\\]\n\n\n\n\n Densidad de una transformación de una v.a. continua \n\n\nSea \\(X\\) una v.a. continua cuya función de densidad es \\(f_{X}\\). Sea \\[h:\\mathbb{R}\\to\\mathbb{R}\\] una aplicación, no necesariamente monótona tal que :\n\nsea derivable con derivada no nula\nla ecuación \\(h(x)=y\\) tiene un número finito de soluciones \\(x_1,x_2,..,x_{n}\\)\n\nentonces:\n\\[\n\\displaystyle f_{Y}(y)=\\left.\\sum_{k=1}^{n} \\frac{f_{X}(x)}\n{\\left|h'(x)\\right|}\\right|_{x=x_{k}}.\n\\]",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#método-general-de-transformación-de-v.a.",
    "href": "variables_aleatorias.html#método-general-de-transformación-de-v.a.",
    "title": "3  Variables aleatorias",
    "section": "3.19 Método general de transformación de v.a.",
    "text": "3.19 Método general de transformación de v.a.\nCuando no podamos aplicar las propiedades anteriores intentaremos calcular primero la función de distribución de la transformación y luego su densidad.\nNotemos que en general si \\(Y=g(X)\\) es una v.a. transformación de la v.a. \\(X\\) entonces\n\\[\nF_{Y}(y)=P(Y\\leq y)=P(g(X)\\leq y).\n\\]\nPor ejemplo, si \\(g\\) es estrictamente creciente y continua,\n\\[\nF_{Y}(y)=P(g(X)\\leq y)=P(X\\leq g^{-1}(y))=F_{X}(g^{-1}(y)),\n\\]\ny si \\(g\\) es estrictamente decreciente y continua, \\[\nF_{Y}(y)=P(g(X)\\leq y)=P(X\\geq g^{-1}(y))=1-F_{X}(g^{-1}(y)).\n\\]",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#desigualdades-de-markov-y-de-chebychev",
    "href": "variables_aleatorias.html#desigualdades-de-markov-y-de-chebychev",
    "title": "3  Variables aleatorias",
    "section": "3.20 Desigualdades de Markov y de Chebychev",
    "text": "3.20 Desigualdades de Markov y de Chebychev\nEn esta sección distintas desigualdades que acotan determinadas probabilidades de una variable aleatoria.\nEstas desigualdades sirven en algunos casos para acotar probabilidades de determinados sucesos.\nTambién son útiles desde el punto de vista teórico, por ejemplo para justificar que la varianza es una medida de la dispersión de los datos.\n\n3.20.1 Desigualdad de Markov\n\n\n Propiedad: Desigualdad de Markov\n\n\nSea \\(X\\) una v.a. positiva con \\(E(X)\\) finita. Entonces\n\\[P(X\\geq a)\\leq \\frac{E(X)}{a}\\mbox{ para todo }a&gt;0.\\]\n\n\nDemostración:\nSi \\(X\\) es continua y solo toma valores positivos\n\\[\\begin{eqnarray*}\nE(X) &=& \\int_{-\\infty}^{+\\infty} x\\cdot f_{X}(x) dx=  \\int_0^{+\\infty} x\\cdot f_{X}(x) dx=  \\int_0^{a} x\\cdot f_{X}(x) dx +\\int_{a}^{+\\infty} x\\cdot f_{X}(x) dx \\\\\n& &\\geq   \\int_{a}^{+\\infty} x\\cdot\nf_{X}(x) dx \\geq a \\int_{a}^{+\\infty}\nf_{X}(x) dx = a \\cdot  P(X\\geq a),\n\\end{eqnarray*}\\]\nde donde se sigue que\n\\[P(X\\geq a)\\leq \\frac{E(X)}{a}.\\]\n\n\n3.20.2 Desigualdad de Markov\nSea \\(X\\) una v.a. con \\(E(X)\\) finita entonces para todo \\(a&gt;0\\)\n\\[P(|X|\\geq a )\\leq \\frac{E(|X|)}{a}.\\]\n\nEjercicio\nDemuestra el corolario anterior a partir de la desigualdad de Markov.",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#desigualdad-de-chebychev",
    "href": "variables_aleatorias.html#desigualdad-de-chebychev",
    "title": "3  Variables aleatorias",
    "section": "3.21 Desigualdad de Chebychev",
    "text": "3.21 Desigualdad de Chebychev\n\n\n Propiedad: Desigualdad de Chebychev\n\n\nLa desigualdad de Chebychev también se denomina de Chebyshov y en inglés Chebyshev.\n Desigualdad de Chebychev\nSea \\(X\\) una v.a.con \\(E(X)=\\mu\\) y \\(Var(X)=\\sigma^2\\) entonces para todo \\(a&gt;0\\),\n\\[P(|X-\\mu|\\geq a)\\leq \\frac{\\sigma^2}{a^2}.\\]\n\n\nDemostración\nApliquemos la consecuencia de la desigualdad de Markov a la v.a. no negativa\n\\[Y^2=(X-\\mu)^2\\]\nentonces\n\\[\nP(Y^2\\geq a^2) \\leq\n\\frac{E(Y^2)}{a^2}=\\frac{E((X-\\mu)^2)}{a^2}\n= \\frac{Var(X)}{a^2}=\\frac{\\sigma^2}{a^2}\n.\n\\]\nPor otra parte\n\\[\nP(Y^2\\geq a^2)=P(|Y|\\geq a)= P(|X-\\mu|\\geq a),\n\\]\nhecho que, junto con la desigualdad anterior, demuestra el resultado.\n\n3.21.1 Uso de la desigualdad de Chebychev\n\n\n Utilidad básica de la desigualdad de Chebychev \n\n\nSupongamos que \\(X\\) es una v.a. con \\(Var(X)=0\\), entonces, aplicando la desigualdad anterior\n\\[P(|X-E(X)|\\geq a )=0\\mbox{ para todo }a&gt;0,\\]\nlo que implica que\n\\[P(X=E(X))=1,\\]\nPor lo que la probabilidad de que \\(X\\) sea constantemente \\(E(X)\\) es 1, hecho que nos confirma la utilidad de la varianza como una medida de la dispersión de los datos.\n\n\nEjemplo: tiempo de respuesta\n\n\nSe sabe que el tiempo de respuesta medio y la desviación típica de un sistema multiusuario son 15 y 3 unidades de tiempo respectivamente. Entonces:\n\\[\nP(|X-15|\\geq 5)\\leq \\frac9{25}=0.36.\n\\]\n\n\nSi substituimos \\(a\\) por \\(a\\cdot \\sigma\\) en la desigualdad de Chebychev, nos queda:\n\\[\nP(|X-\\mu|\\geq a\\cdot \\sigma)\\leq\n\\frac{\\sigma^2}{(a\\cdot \\sigma)^2}=\\frac1{a^2},\n\\]\nque es otra manera de expresar la desigualdad de Chebychev.\n\n3.22 Más formas de la desgualdad de Chebychev\nLa desigualdad de Chebychev también se puede escribir de al menos dos maneras más:\n\\[\nP(\\mu-a\\leq X\\leq \\mu+a)\\geq 1-\\frac{\\sigma^2}{a^2},\n\\]\ny tomado como \\(a=k\\cdot \\sigma\\),\n\\[\nP(\\mu-k\\cdot \\sigma\\leq X\\leq \\mu+ k \\cdot \\sigma)\\geq 1-\\frac1{k^2}.\n\\]\n\n3.22.1 La varianza como medida de dispersión\nTomando la segunda expresión que hemos visto para la desigualdad de Chebychev para distintos valores de \\(k&gt;0\\) obtenemos la siguiente tabla:\nPor ejemplo para \\(k=2\\), esta desigualdad se puede interpretar como que, dada una v.a. \\(X\\) con cualquier distribución que tenga \\(E(X)\\) y \\(Var(X)\\) finitos, la probabilidad de que un valor se aleje de la media \\(\\mu\\) más de \\(a=2\\) desviaciones típicas es menor o igual que \\(0.25\\).\nEs decir sólo el 25% de los valores estarán alejados de la media más de \\(2\\cdot \\sigma\\) ¡Sea cual sea la distribución de la v.a.!",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "variables_aleatorias.html#más-formas-de-la-desgualdad-de-chebychev",
    "href": "variables_aleatorias.html#más-formas-de-la-desgualdad-de-chebychev",
    "title": "3  Variables aleatorias",
    "section": "3.22 Más formas de la desgualdad de Chebychev",
    "text": "3.22 Más formas de la desgualdad de Chebychev\nLa desigualdad de Chebychev también se puede escribir de al menos dos maneras más:\n\\[\nP(\\mu-a\\leq X\\leq \\mu+a)\\geq 1-\\frac{\\sigma^2}{a^2},\n\\]\ny tomado como \\(a=k\\cdot \\sigma\\),\n\\[\nP(\\mu-k\\cdot \\sigma\\leq X\\leq \\mu+ k \\cdot \\sigma)\\geq 1-\\frac1{k^2}.\n\\]\n\n3.22.1 La varianza como medida de dispersión\nTomando la segunda expresión que hemos visto para la desigualdad de Chebychev para distintos valores de \\(k&gt;0\\) obtenemos la siguiente tabla:\nPor ejemplo para \\(k=2\\), esta desigualdad se puede interpretar como que, dada una v.a. \\(X\\) con cualquier distribución que tenga \\(E(X)\\) y \\(Var(X)\\) finitos, la probabilidad de que un valor se aleje de la media \\(\\mu\\) más de \\(a=2\\) desviaciones típicas es menor o igual que \\(0.25\\).\nEs decir sólo el 25% de los valores estarán alejados de la media más de \\(2\\cdot \\sigma\\) ¡Sea cual sea la distribución de la v.a.!",
    "crumbs": [
      "Parte 1: Probabilidad y variables aleatorias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  }
]